Script started on 2019-02-16 00:29:28-05:00 [TERM="xterm-256color" TTY="/dev/pts/2" COLUMNS="106" LINES="59"]
[1m[7m%[27m[1m[0m                                                                                                          ]2;arthur@DESKTOP-42069: ~/git/IFT6135_assignment_1]1;.._assignment_1[0m[27m[24m[J[01;32marthur@DESKTOP-42069 [01;34m~/git/IFT6135_assignment_1 (master*) $[00m [K[?1h=[?2004hddl[?1l>[?2004l
]2;source /home/arthur/.pyvenvs/dl/bin/activate]1;dl[1m[7m%[27m[1m[0m                                                                                                          ]2;arthur@DESKTOP-42069: ~/git/IFT6135_assignment_1]1;.._assignment_1[0m[27m[24m[J(dl) [01;32marthur@DESKTOP-42069 [01;34m~/git/IFT6135_assignment_1 (master*) $[00m [K[?1h=[?2004hdlscript output.txt[17Dpython fine_tuning.py[?1l>[?2004l
]2;python fine_tuning.py]1;pythonNet(
  (model): Sequential(
    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): ReLU(inplace)
    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): ReLU(inplace)
    (6): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))
    (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (10): ReLU(inplace)
    (11): Flatten()
    (12): Linear(in_features=4608, out_features=128, bias=True)
    (13): ReLU(inplace)
    (14): Linear(in_features=128, out_features=2, bias=True)
  )
) 0.05 64
epoch: 1
 [LOSS] TRAIN 0.6919939003298917 / TEST 0.6919862079620361
 [ACC] TRAIN 0.5576322040180517 / TEST 0.556
epoch: 2
 [LOSS] TRAIN 0.6903707614644258 / TEST 0.6919033241271972
 [ACC] TRAIN 0.5160645080076216 / TEST 0.5015
epoch: 3
 [LOSS] TRAIN 0.6870242966638682 / TEST 0.6850474944114685
 [ACC] TRAIN 0.5467558444731085 / TEST 0.5525
epoch: 4
 [LOSS] TRAIN 0.6794726596517643 / TEST 0.6790950384140014
 [ACC] TRAIN 0.575634454418561 / TEST 0.5895
epoch: 5
 [LOSS] TRAIN 0.6754717783848038 / TEST 0.6740150628089905
 [ACC] TRAIN 0.5889486185214359 / TEST 0.597
epoch: 6
 [LOSS] TRAIN 0.6952219181380311 / TEST 0.7005683279037476
 [ACC] TRAIN 0.5332541568217568 / TEST 0.532
epoch: 7
 [LOSS] TRAIN 0.6787596874675805 / TEST 0.6809808673858643
 [ACC] TRAIN 0.5600075008780051 / TEST 0.5545
epoch: 8
 [LOSS] TRAIN 0.6645889130960868 / TEST 0.6577623023986816
 [ACC] TRAIN 0.5946993375214983 / TEST 0.6065
epoch: 9
 [LOSS] TRAIN 0.6646398305669399 / TEST 0.6619619545936585
 [ACC] TRAIN 0.602700337646514 / TEST 0.6065
epoch: 10
 [LOSS] TRAIN 0.6608306290447928 / TEST 0.6533933091163635
 [ACC] TRAIN 0.6052006501855813 / TEST 0.6125
epoch: 11
 [LOSS] TRAIN 0.6718525622826633 / TEST 0.6731186151504517
 [ACC] TRAIN 0.5733841730737883 / TEST 0.5715
epoch: 12
 [LOSS] TRAIN 0.652881209277141 / TEST 0.6460018153190613
 [ACC] TRAIN 0.6166395798655268 / TEST 0.6195
epoch: 13
 [LOSS] TRAIN 0.6528788351732457 / TEST 0.6495034484863281
 [ACC] TRAIN 0.6189523690312277 / TEST 0.624
epoch: 14
 [LOSS] TRAIN 0.6586015425498581 / TEST 0.648296012878418
 [ACC] TRAIN 0.6045755719539448 / TEST 0.6195
epoch: 15
 [LOSS] TRAIN 0.6521339579244929 / TEST 0.648941457748413
 [ACC] TRAIN 0.6245155644902648 / TEST 0.631
epoch: 16
 [LOSS] TRAIN 0.6812643346629719 / TEST 0.6863680644035339
 [ACC] TRAIN 0.5699462433921827 / TEST 0.5705
epoch: 17
 [LOSS] TRAIN 0.6426206137302712 / TEST 0.6398226017951966
 [ACC] TRAIN 0.6325165645631198 / TEST 0.6445
epoch: 18
 [LOSS] TRAIN 0.6444390114731663 / TEST 0.6419480528831482
 [ACC] TRAIN 0.6333291661830258 / TEST 0.6385
epoch: 19
 [LOSS] TRAIN 0.6382848527270834 / TEST 0.6338309106826783
 [ACC] TRAIN 0.6385798225150673 / TEST 0.651
epoch: 20
 [LOSS] TRAIN 0.6370020662863444 / TEST 0.6382146291732788
 [ACC] TRAIN 0.6377672208877098 / TEST 0.6415
epoch: 21
 [LOSS] TRAIN 0.632414362738767 / TEST 0.6257529501914978
 [ACC] TRAIN 0.639642455344171 / TEST 0.6415
epoch: 22
 [LOSS] TRAIN 0.6187932064032791 / TEST 0.6163492722511291
 [ACC] TRAIN 0.6648956120558152 / TEST 0.6625
epoch: 23
 [LOSS] TRAIN 0.613931277861132 / TEST 0.6130370931625366
 [ACC] TRAIN 0.6714589324783184 / TEST 0.678
epoch: 24
 [LOSS] TRAIN 0.60895578863323 / TEST 0.6053711471557617
 [ACC] TRAIN 0.6714589324112549 / TEST 0.676
epoch: 25
 [LOSS] TRAIN 0.6022801485966557 / TEST 0.5978110036849975
 [ACC] TRAIN 0.6817102137543676 / TEST 0.697
epoch: 26
 [LOSS] TRAIN 0.5953515346519112 / TEST 0.5898278465270996
 [ACC] TRAIN 0.6847730967339493 / TEST 0.6915
epoch: 27
 [LOSS] TRAIN 0.5895996254330085 / TEST 0.5864708380699157
 [ACC] TRAIN 0.6898987373198132 / TEST 0.6865
epoch: 28
 [LOSS] TRAIN 0.5830457756662089 / TEST 0.5792759864330291
 [ACC] TRAIN 0.6997124640878133 / TEST 0.7005
epoch: 29
 [LOSS] TRAIN 0.6171014520999476 / TEST 0.6046990389823914
 [ACC] TRAIN 0.649831228933419 / TEST 0.6635
epoch: 30
 [LOSS] TRAIN 0.5731488734144675 / TEST 0.5667644076347351
 [ACC] TRAIN 0.7069633703914966 / TEST 0.713
epoch: 31
 [LOSS] TRAIN 0.6596363902255913 / TEST 0.644983033657074
 [ACC] TRAIN 0.6327040880631619 / TEST 0.6445
epoch: 32
 [LOSS] TRAIN 0.5592631814121857 / TEST 0.5597439093589782
 [ACC] TRAIN 0.718714839451789 / TEST 0.7195
epoch: 33
 [LOSS] TRAIN 0.5452508157172015 / TEST 0.5497800722122193
 [ACC] TRAIN 0.7270908864427618 / TEST 0.7265
epoch: 34
 [LOSS] TRAIN 0.5372923725261467 / TEST 0.5438329167366028
 [ACC] TRAIN 0.7357169647099957 / TEST 0.7305
epoch: 35
 [LOSS] TRAIN 0.5475690897397212 / TEST 0.5599294438362121
 [ACC] TRAIN 0.7179647456900689 / TEST 0.708
epoch: 36
 [LOSS] TRAIN 0.5125410121103304 / TEST 0.5198744668960571
 [ACC] TRAIN 0.7539067383273897 / TEST 0.746
epoch: 37
 [LOSS] TRAIN 0.5200760232193617 / TEST 0.5403971495628357
 [ACC] TRAIN 0.7419052380653512 / TEST 0.727
epoch: 38
 [LOSS] TRAIN 0.481778720596132 / TEST 0.49911582517623904
 [ACC] TRAIN 0.7780972621875758 / TEST 0.7685
epoch: 39
 [LOSS] TRAIN 0.5128578587291628 / TEST 0.5259415972232818
 [ACC] TRAIN 0.7393424177798708 / TEST 0.7275
epoch: 40
 [LOSS] TRAIN 0.5240538523694637 / TEST 0.5359163703918457
 [ACC] TRAIN 0.7287785973097626 / TEST 0.725
epoch: 41
 [LOSS] TRAIN 0.4105669666318718 / TEST 0.44883904385566714
 [ACC] TRAIN 0.8273534191401396 / TEST 0.8075
epoch: 42
 [LOSS] TRAIN 0.385257784635339 / TEST 0.4391818888187408
 [ACC] TRAIN 0.840542567724108 / TEST 0.808
epoch: 43
 [LOSS] TRAIN 0.3650794861234416 / TEST 0.40778921604156493
 [ACC] TRAIN 0.8497937242229785 / TEST 0.8315
epoch: 44
 [LOSS] TRAIN 0.3587161387588281 / TEST 0.43434459924697877
 [ACC] TRAIN 0.8504813100743523 / TEST 0.8075
epoch: 45
 [LOSS] TRAIN 0.40490245139141323 / TEST 0.46490737557411194
 [ACC] TRAIN 0.8099137392919173 / TEST 0.766
epoch: 46
 [LOSS] TRAIN 0.25354679358059173 / TEST 0.3441303715705872
 [ACC] TRAIN 0.9143642954847815 / TEST 0.862
epoch: 47
 [LOSS] TRAIN 0.24683058842344124 / TEST 0.34476526761054993
 [ACC] TRAIN 0.9138642330887408 / TEST 0.8645
epoch: 48
 [LOSS] TRAIN 0.2228816169707503 / TEST 0.34345920169353483
 [ACC] TRAIN 0.9121140142070724 / TEST 0.8595
epoch: 49
 [LOSS] TRAIN 0.17194224977876293 / TEST 0.3163844890594482
 [ACC] TRAIN 0.940367546002855 / TEST 0.8765
epoch: 50
 [LOSS] TRAIN 0.13558028429161684 / TEST 0.30470937848091123
 [ACC] TRAIN 0.9489311163970002 / TEST 0.8995
epoch: 51
 [LOSS] TRAIN 0.12720277631807392 / TEST 0.311848215341568
 [ACC] TRAIN 0.9538692336094977 / TEST 0.8945
epoch: 52
 [LOSS] TRAIN 0.12215677343457025 / TEST 0.2935712962150574
 [ACC] TRAIN 0.9539317414155228 / TEST 0.902
epoch: 53
 [LOSS] TRAIN 0.03894893663822077 / TEST 0.27318887639045714
 [ACC] TRAIN 0.9899987499033426 / TEST 0.932
epoch: 54
 [LOSS] TRAIN 0.048034400615949664 / TEST 0.28788050591945646
 [ACC] TRAIN 0.9879359918872272 / TEST 0.915
epoch: 55
 [LOSS] TRAIN 0.09948920289871618 / TEST 0.39252055549621584
 [ACC] TRAIN 0.9635579446313202 / TEST 0.8995
epoch: 56
 [LOSS] TRAIN 0.1189387723745771 / TEST 0.3508646289110184
 [ACC] TRAIN 0.9543067882963829 / TEST 0.886
epoch: 57
 [LOSS] TRAIN 0.009139132076070543 / TEST 0.3259209589958191
 [ACC] TRAIN 0.9984373046630829 / TEST 0.933
epoch: 58
 [LOSS] TRAIN 0.0019275804641235683 / TEST 0.34944576294720175
 [ACC] TRAIN 0.9996874609326166 / TEST 0.9335
epoch: 59
 [LOSS] TRAIN 0.001245733502689213 / TEST 0.3734663262963295
 [ACC] TRAIN 0.9997499687460932 / TEST 0.934
epoch: 60
 [LOSS] TRAIN 0.0010570223583660939 / TEST 0.38452811348438265
 [ACC] TRAIN 0.9997499687460932 / TEST 0.935
epoch: 61
 [LOSS] TRAIN 0.0009022942706108339 / TEST 0.39410935416817666
 [ACC] TRAIN 0.9996874609326166 / TEST 0.9355
epoch: 62
 [LOSS] TRAIN 0.0009516730675772627 / TEST 0.40522654059529306
 [ACC] TRAIN 0.9997499687460932 / TEST 0.9345
epoch: 63
 [LOSS] TRAIN 0.0009538082424211564 / TEST 0.41030467554926875
 [ACC] TRAIN 0.9996874609326166 / TEST 0.936
epoch: 64
 [LOSS] TRAIN 0.0007493372879313491 / TEST 0.41871665489673615
 [ACC] TRAIN 0.9997499687460932 / TEST 0.935
epoch: 65
 [LOSS] TRAIN 0.0006522306473194385 / TEST 0.4223016977608204
 [ACC] TRAIN 0.9997499687460932 / TEST 0.9355
epoch: 66
 [LOSS] TRAIN 0.0006653436878042621 / TEST 0.42696329808235167
 [ACC] TRAIN 0.9996874609326166 / TEST 0.9345
epoch: 67
 [LOSS] TRAIN 0.000642956271898709 / TEST 0.4301965534687042
 [ACC] TRAIN 0.9996874609326166 / TEST 0.9345
epoch: 68
 [LOSS] TRAIN 0.000689902187409312 / TEST 0.4353357771635056
 [ACC] TRAIN 0.9997499687460932 / TEST 0.936
epoch: 69
 [LOSS] TRAIN 0.0007533758025346028 / TEST 0.44250005155801775
 [ACC] TRAIN 0.9996874609326166 / TEST 0.9335
epoch: 70
 [LOSS] TRAIN 0.0006325186186158991 / TEST 0.4431166176795959
 [ACC] TRAIN 0.9996874609326166 / TEST 0.9335
epoch: 71
 [LOSS] TRAIN 0.0007667909161946715 / TEST 0.4484124255180359
 [ACC] TRAIN 0.9996874609326166 / TEST 0.9345
epoch: 72
 [LOSS] TRAIN 0.0006220089694305067 / TEST 0.4482821657061577
 [ACC] TRAIN 0.9997499688057053 / TEST 0.934
epoch: 73
 [LOSS] TRAIN 0.0005783816511328397 / TEST 0.45183201360702513
 [ACC] TRAIN 0.9996874609326166 / TEST 0.9335
epoch: 74
 [LOSS] TRAIN 0.0006534341186501753 / TEST 0.45712626254558564
 [ACC] TRAIN 0.9996874609326166 / TEST 0.934
epoch: 75
 [LOSS] TRAIN 0.0005686211241675007 / TEST 0.45782998359203336
 [ACC] TRAIN 0.9996874609326166 / TEST 0.9335
epoch: 76
 [LOSS] TRAIN 0.0005220324266887497 / TEST 0.45873280358314517
 [ACC] TRAIN 0.9996874609326166 / TEST 0.9335
epoch: 77
 [LOSS] TRAIN 0.0005260914683193153 / TEST 0.4607904803752899
 [ACC] TRAIN 0.9997499687460932 / TEST 0.9335
epoch: 78
 [LOSS] TRAIN 0.0005247641584253448 / TEST 0.46463858294487
 [ACC] TRAIN 0.9996874609326166 / TEST 0.9335
epoch: 79
 [LOSS] TRAIN 0.0005906322871355138 / TEST 0.4647162863016129
 [ACC] TRAIN 0.9997499687460932 / TEST 0.933
epoch: 80
 [LOSS] TRAIN 0.0005442010140276092 / TEST 0.4684126015901566
 [ACC] TRAIN 0.9997499687460932 / TEST 0.933
epoch: 81
 [LOSS] TRAIN 0.0005794216177498698 / TEST 0.47363708761334417
 [ACC] TRAIN 0.9996874609326166 / TEST 0.9345
epoch: 82
 [LOSS] TRAIN 0.0004917835053841507 / TEST 0.4715376769900322
 [ACC] TRAIN 0.9997499687460932 / TEST 0.933
epoch: 83
 [LOSS] TRAIN 0.0005241934191989927 / TEST 0.4736190391778946
 [ACC] TRAIN 0.9997499687460932 / TEST 0.933
Best test accurcy is (0.4867963126897812, 0.932)
Net(
  (model): Sequential(
    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): ReLU(inplace)
    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): ReLU(inplace)
    (6): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))
    (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (10): ReLU(inplace)
    (11): Flatten()
    (12): Linear(in_features=4608, out_features=128, bias=True)
    (13): ReLU(inplace)
    (14): Linear(in_features=128, out_features=2, bias=True)
  )
) 0.05 128
epoch: 1
 [LOSS] TRAIN 0.6930467793607372 / TEST 0.6919733304977417
 [ACC] TRAIN 0.5026253283821146 / TEST 0.5335000009536743
epoch: 2
 [LOSS] TRAIN 0.6927876198630077 / TEST 0.6920794057846069
 [ACC] TRAIN 0.5025628203711728 / TEST 0.5334999997615815
epoch: 3
 [LOSS] TRAIN 0.6925028224023585 / TEST 0.6919160985946655
 [ACC] TRAIN 0.5191273911399593 / TEST 0.5405000004768371
epoch: 4
 [LOSS] TRAIN 0.6920124954440502 / TEST 0.6917579312324524
 [ACC] TRAIN 0.5475059384434711 / TEST 0.5540000009536743
epoch: 5
 [LOSS] TRAIN 0.6920017500134733 / TEST 0.6901363987922668
 [ACC] TRAIN 0.5106263282984879 / TEST 0.5324999995231628
epoch: 6
 [LOSS] TRAIN 0.6894511587769706 / TEST 0.6890476493835449
 [ACC] TRAIN 0.5490686337803882 / TEST 0.5549999995231628
epoch: 7
 [LOSS] TRAIN 0.6905895861957592 / TEST 0.6876738905906677
 [ACC] TRAIN 0.5288161020202031 / TEST 0.5420000009536743
epoch: 8
 [LOSS] TRAIN 0.6854095155707836 / TEST 0.6883939270973205
 [ACC] TRAIN 0.5628828603426417 / TEST 0.5719999995231628
epoch: 9
 [LOSS] TRAIN 0.6820266082415298 / TEST 0.6833015604019165
 [ACC] TRAIN 0.5702587825489843 / TEST 0.5774999995231629
epoch: 10
 [LOSS] TRAIN 0.6814544729581996 / TEST 0.6825948562622071
 [ACC] TRAIN 0.5637579699623121 / TEST 0.575
epoch: 11
 [LOSS] TRAIN 0.6741990352633715 / TEST 0.6761789350509644
 [ACC] TRAIN 0.5873234156132162 / TEST 0.5899999997615815
epoch: 12
 [LOSS] TRAIN 0.6799177800003984 / TEST 0.6756752996444703
 [ACC] TRAIN 0.563382923081452 / TEST 0.5870000004768372
epoch: 13
 [LOSS] TRAIN 0.6690082896693168 / TEST 0.6707716279029846
 [ACC] TRAIN 0.5931991498564791 / TEST 0.5925000004768372
epoch: 14
 [LOSS] TRAIN 0.6913045019429241 / TEST 0.6815638017654418
 [ACC] TRAIN 0.5430678834705327 / TEST 0.5625000004768371
epoch: 15
 [LOSS] TRAIN 0.6728143726666133 / TEST 0.6779687128067017
 [ACC] TRAIN 0.5827603450207759 / TEST 0.5779999990463257
epoch: 16
 [LOSS] TRAIN 0.6759441110592721 / TEST 0.6861278681755066
 [ACC] TRAIN 0.5680710088463035 / TEST 0.5499999995231628
epoch: 17
 [LOSS] TRAIN 0.6890738458838489 / TEST 0.6998564701080322
 [ACC] TRAIN 0.5418177272084505 / TEST 0.5294999990463257
epoch: 18
 [LOSS] TRAIN 0.6681941077476413 / TEST 0.6646437001228332
 [ACC] TRAIN 0.5856357043959943 / TEST 0.594
epoch: 19
 [LOSS] TRAIN 0.6655472068730586 / TEST 0.660242518901825
 [ACC] TRAIN 0.5934491810805799 / TEST 0.6069999995231629
epoch: 20
 [LOSS] TRAIN 0.6641936278116675 / TEST 0.6589276733398437
 [ACC] TRAIN 0.5946368298048913 / TEST 0.6104999995231628
epoch: 21
 [LOSS] TRAIN 0.6603004905727151 / TEST 0.6563940725326538
 [ACC] TRAIN 0.6072009003211564 / TEST 0.616
epoch: 22
 [LOSS] TRAIN 0.6584310498531497 / TEST 0.6633668785095215
 [ACC] TRAIN 0.6048881112076161 / TEST 0.6125
epoch: 23
 [LOSS] TRAIN 0.6559231988056434 / TEST 0.658280255317688
 [ACC] TRAIN 0.6132016501168577 / TEST 0.6160000009536744
epoch: 24
 [LOSS] TRAIN 0.6580501013225966 / TEST 0.6615671968460083
 [ACC] TRAIN 0.6080760094788331 / TEST 0.6075000009536743
epoch: 25
 [LOSS] TRAIN 0.6544003065399325 / TEST 0.6593946866989135
 [ACC] TRAIN 0.6128266034893489 / TEST 0.6090000004768371
epoch: 26
 [LOSS] TRAIN 0.6808904536382334 / TEST 0.6949401001930237
 [ACC] TRAIN 0.554569321373788 / TEST 0.5385
epoch: 27
 [LOSS] TRAIN 0.6602984874647011 / TEST 0.6702485165596008
 [ACC] TRAIN 0.6003875484062979 / TEST 0.5915000004768372
epoch: 28
 [LOSS] TRAIN 0.6558665023071794 / TEST 0.6641197004318238
 [ACC] TRAIN 0.6118264782576281 / TEST 0.6084999995231628
epoch: 29
 [LOSS] TRAIN 0.6498763972423214 / TEST 0.648377137184143
 [ACC] TRAIN 0.6203900486964824 / TEST 0.6220000004768371
epoch: 30
 [LOSS] TRAIN 0.6521982378193044 / TEST 0.6596098504066468
 [ACC] TRAIN 0.6175146892840064 / TEST 0.6170000009536744
epoch: 31
 [LOSS] TRAIN 0.6540987834153674 / TEST 0.6638725333213806
 [ACC] TRAIN 0.6095136892111513 / TEST 0.6000000004768371
epoch: 32
 [LOSS] TRAIN 0.6454608386748283 / TEST 0.6447967672348023
 [ACC] TRAIN 0.6277034631117029 / TEST 0.6305
epoch: 33
 [LOSS] TRAIN 0.6616495606496582 / TEST 0.6786983880996704
 [ACC] TRAIN 0.5988873611138543 / TEST 0.5860000009536743
epoch: 34
 [LOSS] TRAIN 0.6628686458427528 / TEST 0.6518072152137756
 [ACC] TRAIN 0.5968871108367005 / TEST 0.6009999990463257
epoch: 35
 [LOSS] TRAIN 0.639117428639156 / TEST 0.6388528571128845
 [ACC] TRAIN 0.6365795726402951 / TEST 0.6380000004768371
epoch: 36
 [LOSS] TRAIN 0.6668604465630192 / TEST 0.6806532430648804
 [ACC] TRAIN 0.5861357669485168 / TEST 0.5699999995231628
epoch: 37
 [LOSS] TRAIN 0.639312909735577 / TEST 0.6477483024597168
 [ACC] TRAIN 0.6396424554857496 / TEST 0.6365000009536743
epoch: 38
 [LOSS] TRAIN 0.6453132855696951 / TEST 0.6543320379257203
 [ACC] TRAIN 0.6276409553354838 / TEST 0.6280000009536744
epoch: 39
 [LOSS] TRAIN 0.6310456968841143 / TEST 0.6288080234527588
 [ACC] TRAIN 0.6432054006005693 / TEST 0.6509999990463257
epoch: 40
 [LOSS] TRAIN 0.6443087710248097 / TEST 0.6355651082992554
 [ACC] TRAIN 0.6233904237135572 / TEST 0.62
epoch: 41
 [LOSS] TRAIN 0.6247466979272396 / TEST 0.6357017102241516
 [ACC] TRAIN 0.6524565572186639 / TEST 0.6585000009536743
epoch: 42
 [LOSS] TRAIN 0.6207208398104102 / TEST 0.6295412869453431
 [ACC] TRAIN 0.6626453308451696 / TEST 0.6619999995231628
epoch: 43
 [LOSS] TRAIN 0.6307080790525318 / TEST 0.625383174419403
 [ACC] TRAIN 0.6422052758084876 / TEST 0.6385
epoch: 44
 [LOSS] TRAIN 0.6104135755181744 / TEST 0.6141205720901489
 [ACC] TRAIN 0.666645830654326 / TEST 0.667
epoch: 45
 [LOSS] TRAIN 0.6276815856139442 / TEST 0.6465304651260376
 [ACC] TRAIN 0.6487060882014205 / TEST 0.6404999990463257
epoch: 46
 [LOSS] TRAIN 0.6105418329477936 / TEST 0.6238890419006348
 [ACC] TRAIN 0.6700212528354184 / TEST 0.6665
epoch: 47
 [LOSS] TRAIN 0.5991108529209151 / TEST 0.6039198942184448
 [ACC] TRAIN 0.6835229402557733 / TEST 0.6835
epoch: 48
 [LOSS] TRAIN 0.6042433131604005 / TEST 0.6054209399223328
 [ACC] TRAIN 0.6733341669273281 / TEST 0.6670000004768372
epoch: 49
 [LOSS] TRAIN 0.619620692843213 / TEST 0.6150498290061951
 [ACC] TRAIN 0.6481435178801304 / TEST 0.6519999995231628
epoch: 50
 [LOSS] TRAIN 0.5875260788346099 / TEST 0.5955150113105774
 [ACC] TRAIN 0.6957744717419125 / TEST 0.6865000004768371
epoch: 51
 [LOSS] TRAIN 0.5886920930475187 / TEST 0.6024166440963745
 [ACC] TRAIN 0.692586573232247 / TEST 0.6895000004768371
epoch: 52
 [LOSS] TRAIN 0.5829963559567265 / TEST 0.5869369034767151
 [ACC] TRAIN 0.6997124639611376 / TEST 0.6844999995231629
epoch: 53
 [LOSS] TRAIN 0.5726425912562333 / TEST 0.583813053369522
 [ACC] TRAIN 0.7055881984204945 / TEST 0.6935000009536744
epoch: 54
 [LOSS] TRAIN 0.5747907254633001 / TEST 0.5829780359268188
 [ACC] TRAIN 0.701087636110976 / TEST 0.7010000009536743
epoch: 55
 [LOSS] TRAIN 0.5685397131411131 / TEST 0.5861217975616455
 [ACC] TRAIN 0.7094011752810205 / TEST 0.6935
epoch: 56
 [LOSS] TRAIN 0.569430058293677 / TEST 0.5757234613895417
 [ACC] TRAIN 0.706838354950831 / TEST 0.6949999990463257
epoch: 57
 [LOSS] TRAIN 0.6073086439840405 / TEST 0.633361349105835
 [ACC] TRAIN 0.6664583074299898 / TEST 0.6560000009536743
epoch: 58
 [LOSS] TRAIN 0.5530548399575785 / TEST 0.5663123631477356
 [ACC] TRAIN 0.7177772222794448 / TEST 0.7024999995231629
epoch: 59
 [LOSS] TRAIN 0.5515652061149559 / TEST 0.568743058681488
 [ACC] TRAIN 0.719464933034673 / TEST 0.6995000009536743
epoch: 60
 [LOSS] TRAIN 0.5467088244932713 / TEST 0.5648427038192749
 [ACC] TRAIN 0.7267783474275389 / TEST 0.7190000004768372
epoch: 61
 [LOSS] TRAIN 0.5390703483646639 / TEST 0.5610964622497558
 [ACC] TRAIN 0.7335916988729522 / TEST 0.7120000004768372
epoch: 62
 [LOSS] TRAIN 0.5421221051786613 / TEST 0.565742196559906
 [ACC] TRAIN 0.7293411677875344 / TEST 0.717
epoch: 63
 [LOSS] TRAIN 0.5497154726887036 / TEST 0.5572736597061158
 [ACC] TRAIN 0.7172771597492767 / TEST 0.7119999995231628
epoch: 64
 [LOSS] TRAIN 0.5256890867975208 / TEST 0.5618172821998596
 [ACC] TRAIN 0.7390923867271548 / TEST 0.7120000009536743
epoch: 65
 [LOSS] TRAIN 0.5195801730214961 / TEST 0.5369473719596862
 [ACC] TRAIN 0.7484685584580485 / TEST 0.7339999995231629
epoch: 66
 [LOSS] TRAIN 0.5067314922638216 / TEST 0.5451967997550964
 [ACC] TRAIN 0.7598449804959021 / TEST 0.7360000009536743
epoch: 67
 [LOSS] TRAIN 0.5027578116387245 / TEST 0.5444785170555114
 [ACC] TRAIN 0.7590323789430597 / TEST 0.7335
epoch: 68
 [LOSS] TRAIN 0.48994465617332356 / TEST 0.5212344121932984
 [ACC] TRAIN 0.7740967622219376 / TEST 0.7524999990463257
epoch: 69
 [LOSS] TRAIN 0.47681434111813337 / TEST 0.520837632894516
 [ACC] TRAIN 0.7765970747088444 / TEST 0.7554999995231628
epoch: 70
 [LOSS] TRAIN 0.48024037070148573 / TEST 0.5258098335266114
 [ACC] TRAIN 0.7725340666540236 / TEST 0.7445
epoch: 71
 [LOSS] TRAIN 0.5494165408311746 / TEST 0.6184595222473145
 [ACC] TRAIN 0.7108388547450845 / TEST 0.6680000009536743
epoch: 72
 [LOSS] TRAIN 0.4858168022962552 / TEST 0.5126747617721558
 [ACC] TRAIN 0.766595824582381 / TEST 0.7534999990463257
epoch: 73
 [LOSS] TRAIN 0.43571445515027923 / TEST 0.4841440100669861
 [ACC] TRAIN 0.8047880984005413 / TEST 0.7795
epoch: 74
 [LOSS] TRAIN 0.4237518050824423 / TEST 0.46913431882858275
 [ACC] TRAIN 0.8159144891472306 / TEST 0.7864999990463257
epoch: 75
 [LOSS] TRAIN 0.4958823695378328 / TEST 0.5728376932144165
 [ACC] TRAIN 0.7455931992914725 / TEST 0.6880000009536743
epoch: 76
 [LOSS] TRAIN 0.41118439765241177 / TEST 0.4750032820701599
 [ACC] TRAIN 0.8240405049141026 / TEST 0.7755000009536743
epoch: 77
 [LOSS] TRAIN 0.4177579492319374 / TEST 0.4952755722999573
 [ACC] TRAIN 0.8132891612643673 / TEST 0.7590000004768371
epoch: 78
 [LOSS] TRAIN 0.40363518155460165 / TEST 0.4698446295261383
 [ACC] TRAIN 0.8287285909174025 / TEST 0.7894999990463257
epoch: 79
 [LOSS] TRAIN 0.42601067085223787 / TEST 0.5067903459072113
 [ACC] TRAIN 0.7992874107624325 / TEST 0.7485000004768372
epoch: 80
 [LOSS] TRAIN 0.3377880869708757 / TEST 0.4215150933265686
 [ACC] TRAIN 0.8713589196712438 / TEST 0.8190000004768372
epoch: 81
 [LOSS] TRAIN 0.31315427451882455 / TEST 0.4029588205814362
 [ACC] TRAIN 0.883110388627215 / TEST 0.826
epoch: 82
 [LOSS] TRAIN 0.2932076880463601 / TEST 0.39414314103126524
 [ACC] TRAIN 0.891923990319976 / TEST 0.8354999995231629
epoch: 83
 [LOSS] TRAIN 0.25945071496208216 / TEST 0.36430439138412474
 [ACC] TRAIN 0.914614326589658 / TEST 0.8575000009536743
epoch: 84
 [LOSS] TRAIN 0.3030243340485214 / TEST 0.4174952630996704
 [ACC] TRAIN 0.8795474434825894 / TEST 0.8165
epoch: 85
 [LOSS] TRAIN 0.3378379989309689 / TEST 0.5022526025772095
 [ACC] TRAIN 0.8416052004935995 / TEST 0.7765000009536743
epoch: 86
 [LOSS] TRAIN 0.2432762707568121 / TEST 0.3905549852848053
 [ACC] TRAIN 0.9008626076322389 / TEST 0.8339999990463257
epoch: 87
 [LOSS] TRAIN 0.35051148408933763 / TEST 0.42339584612846376
 [ACC] TRAIN 0.8347918488171894 / TEST 0.8060000004768372
epoch: 88
 [LOSS] TRAIN 0.13639950286911373 / TEST 0.29692296409606933
 [ACC] TRAIN 0.9576197024777109 / TEST 0.9025000004768372
epoch: 89
 [LOSS] TRAIN 0.10579714599583712 / TEST 0.3028955088853836
 [ACC] TRAIN 0.9728091011450937 / TEST 0.8995
epoch: 90
 [LOSS] TRAIN 0.16174857344015908 / TEST 0.3578641219139099
 [ACC] TRAIN 0.9398674834503324 / TEST 0.8755
epoch: 91
 [LOSS] TRAIN 0.09335239708296938 / TEST 0.3043767399787903
 [ACC] TRAIN 0.9776222025518015 / TEST 0.9049999990463257
epoch: 92
 [LOSS] TRAIN 0.0512212493687082 / TEST 0.27613821959495544
 [ACC] TRAIN 0.9916239530015758 / TEST 0.9200000009536743
epoch: 93
 [LOSS] TRAIN 0.021966435882837 / TEST 0.2909703640937805
 [ACC] TRAIN 0.9983747968496062 / TEST 0.9260000009536743
Best test accurcy is (0.2645698838233948, 0.9285000004768371)
Net(
  (model): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): ReLU(inplace)
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): ReLU(inplace)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
    (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (10): ReLU(inplace)
    (11): Flatten()
    (12): Linear(in_features=2304, out_features=128, bias=True)
    (13): ReLU(inplace)
    (14): Linear(in_features=128, out_features=2, bias=True)
  )
) 0.05 64
epoch: 1
 [LOSS] TRAIN 0.69276975204623 / TEST 0.6928775959014892
 [ACC] TRAIN 0.5085010626365548 / TEST 0.492
epoch: 2
 [LOSS] TRAIN 0.6922652470661649 / TEST 0.6923859567642212
 [ACC] TRAIN 0.5032504062933361 / TEST 0.5045
epoch: 3
 [LOSS] TRAIN 0.6896195795509514 / TEST 0.6909968128204346
 [ACC] TRAIN 0.5420052505892684 / TEST 0.526
epoch: 4
 [LOSS] TRAIN 0.68591719373254 / TEST 0.688535325050354
 [ACC] TRAIN 0.5491311414299317 / TEST 0.541
epoch: 5
 [LOSS] TRAIN 0.69652248764205 / TEST 0.6977045917510987
 [ACC] TRAIN 0.5251281409617409 / TEST 0.5185
epoch: 6
 [LOSS] TRAIN 0.6770544355847654 / TEST 0.6803972096443176
 [ACC] TRAIN 0.5723840479389372 / TEST 0.563
epoch: 7
 [LOSS] TRAIN 0.6860013756994635 / TEST 0.6903486533164978
 [ACC] TRAIN 0.5461932741629957 / TEST 0.53
epoch: 8
 [LOSS] TRAIN 0.6680731793272002 / TEST 0.6709698386192322
 [ACC] TRAIN 0.5946368297154732 / TEST 0.5815
epoch: 9
 [LOSS] TRAIN 0.688300452056207 / TEST 0.6886946978569031
 [ACC] TRAIN 0.554881860172917 / TEST 0.5575
epoch: 10
 [LOSS] TRAIN 0.6709691093838026 / TEST 0.6722156143188477
 [ACC] TRAIN 0.5863857981502629 / TEST 0.574
epoch: 11
 [LOSS] TRAIN 0.6962206813749305 / TEST 0.6927928814888
 [ACC] TRAIN 0.5496937118257369 / TEST 0.552
epoch: 12
 [LOSS] TRAIN 0.6587850184258199 / TEST 0.6598535008430481
 [ACC] TRAIN 0.6089511188227976 / TEST 0.596
epoch: 13
 [LOSS] TRAIN 0.6582327077859401 / TEST 0.6580747113227844
 [ACC] TRAIN 0.6094511813380626 / TEST 0.6205
epoch: 14
 [LOSS] TRAIN 0.6643159758643756 / TEST 0.6627585654258727
 [ACC] TRAIN 0.5981372672031039 / TEST 0.5925
epoch: 15
 [LOSS] TRAIN 0.665637450190481 / TEST 0.6670112524032593
 [ACC] TRAIN 0.5910113763624406 / TEST 0.5915
epoch: 16
 [LOSS] TRAIN 0.6730309211175015 / TEST 0.6718571701049805
 [ACC] TRAIN 0.5841355169396174 / TEST 0.583
epoch: 17
 [LOSS] TRAIN 0.7005366894927288 / TEST 0.7022627687454224
 [ACC] TRAIN 0.5480685086678916 / TEST 0.546
epoch: 18
 [LOSS] TRAIN 0.7112853015969881 / TEST 0.7065395722389222
 [ACC] TRAIN 0.5469433679135386 / TEST 0.5485
epoch: 19
 [LOSS] TRAIN 0.6479296017578355 / TEST 0.6493830423355103
 [ACC] TRAIN 0.6242655331171338 / TEST 0.6235
epoch: 20
 [LOSS] TRAIN 0.6483254159356762 / TEST 0.6469494295120239
 [ACC] TRAIN 0.6226403299741915 / TEST 0.6245
epoch: 21
 [LOSS] TRAIN 0.6516403326512515 / TEST 0.6515883178710937
 [ACC] TRAIN 0.6210776347490471 / TEST 0.623
epoch: 22
 [LOSS] TRAIN 0.657080295987838 / TEST 0.6581680445671082
 [ACC] TRAIN 0.6033879235947575 / TEST 0.6135
epoch: 23
 [LOSS] TRAIN 0.6433662268605467 / TEST 0.6471537418365478
 [ACC] TRAIN 0.6307663458304817 / TEST 0.633
epoch: 24
 [LOSS] TRAIN 0.6363405450193088 / TEST 0.6334699506759643
 [ACC] TRAIN 0.6356419553412752 / TEST 0.6425
epoch: 25
 [LOSS] TRAIN 0.6386634070719164 / TEST 0.6375155625343323
 [ACC] TRAIN 0.6372671584991205 / TEST 0.64
epoch: 26
 [LOSS] TRAIN 0.6271800936006102 / TEST 0.623243426322937
 [ACC] TRAIN 0.6514564320912644 / TEST 0.662
epoch: 27
 [LOSS] TRAIN 0.6268212128421756 / TEST 0.626704984664917
 [ACC] TRAIN 0.6493936743135973 / TEST 0.6525
epoch: 28
 [LOSS] TRAIN 0.6228096189983547 / TEST 0.627998283624649
 [ACC] TRAIN 0.654081760257285 / TEST 0.646
epoch: 29
 [LOSS] TRAIN 0.6379625635201341 / TEST 0.6452567687034607
 [ACC] TRAIN 0.6297037128747024 / TEST 0.6225
epoch: 30
 [LOSS] TRAIN 0.6111635444670681 / TEST 0.6119253950119019
 [ACC] TRAIN 0.6700837603880921 / TEST 0.665
epoch: 31
 [LOSS] TRAIN 0.5991630175811438 / TEST 0.6024322271347046
 [ACC] TRAIN 0.6767720964375489 / TEST 0.6755
epoch: 32
 [LOSS] TRAIN 0.6167668314975029 / TEST 0.6171254653930665
 [ACC] TRAIN 0.6507063383369956 / TEST 0.662
epoch: 33
 [LOSS] TRAIN 0.5958163859635863 / TEST 0.5972468497753143
 [ACC] TRAIN 0.6843355419203883 / TEST 0.686
epoch: 34
 [LOSS] TRAIN 0.6026679557671412 / TEST 0.6068776636123657
 [ACC] TRAIN 0.6740217526520262 / TEST 0.668
epoch: 35
 [LOSS] TRAIN 0.6392462071604633 / TEST 0.643802056312561
 [ACC] TRAIN 0.6167645956117044 / TEST 0.602
epoch: 36
 [LOSS] TRAIN 0.5772027180170712 / TEST 0.5816880793571472
 [ACC] TRAIN 0.7007125891108917 / TEST 0.705
epoch: 37
 [LOSS] TRAIN 0.5811810622007821 / TEST 0.5909842104911804
 [ACC] TRAIN 0.6923990498067201 / TEST 0.682
epoch: 38
 [LOSS] TRAIN 0.5681316498548243 / TEST 0.5773006420135498
 [ACC] TRAIN 0.7071508938393781 / TEST 0.6945
epoch: 39
 [LOSS] TRAIN 0.5605298524045068 / TEST 0.5677527785301208
 [ACC] TRAIN 0.7115264407678431 / TEST 0.715
epoch: 40
 [LOSS] TRAIN 0.5500574636375893 / TEST 0.5628692655563354
 [ACC] TRAIN 0.7235904487762947 / TEST 0.7125
epoch: 41
 [LOSS] TRAIN 0.5507196991618596 / TEST 0.5656786170005799
 [ACC] TRAIN 0.7265283160096989 / TEST 0.718
epoch: 42
 [LOSS] TRAIN 0.547450297146175 / TEST 0.5704471979141236
 [ACC] TRAIN 0.7202150269752294 / TEST 0.6965
epoch: 43
 [LOSS] TRAIN 0.5729111825798374 / TEST 0.593899733543396
 [ACC] TRAIN 0.6987123391317984 / TEST 0.6935
epoch: 44
 [LOSS] TRAIN 0.5297202653535561 / TEST 0.5604288725852966
 [ACC] TRAIN 0.7364045506507877 / TEST 0.7055
epoch: 45
 [LOSS] TRAIN 0.5311508875539086 / TEST 0.5616235795021057
 [ACC] TRAIN 0.7323415427077397 / TEST 0.714
epoch: 46
 [LOSS] TRAIN 0.4986342241919358 / TEST 0.5304861319065094
 [ACC] TRAIN 0.7629078634456778 / TEST 0.74
epoch: 47
 [LOSS] TRAIN 0.4904740911667787 / TEST 0.5255215773582459
 [ACC] TRAIN 0.7722215276537038 / TEST 0.7455
epoch: 48
 [LOSS] TRAIN 0.5158069768701885 / TEST 0.5506681914329529
 [ACC] TRAIN 0.7398424803398448 / TEST 0.722
epoch: 49
 [LOSS] TRAIN 0.5174245192402824 / TEST 0.5558381547927856
 [ACC] TRAIN 0.7363420427255384 / TEST 0.71
epoch: 50
 [LOSS] TRAIN 0.44929481975166985 / TEST 0.5047435946464539
 [ACC] TRAIN 0.7942242780049483 / TEST 0.7475
epoch: 51
 [LOSS] TRAIN 0.44266034930791687 / TEST 0.5019877095222474
 [ACC] TRAIN 0.8021627703015842 / TEST 0.768
epoch: 52
 [LOSS] TRAIN 0.48135237711148643 / TEST 0.5407981414794922
 [ACC] TRAIN 0.767033379135139 / TEST 0.74
epoch: 53
 [LOSS] TRAIN 0.40748092944226516 / TEST 0.4747168915271759
 [ACC] TRAIN 0.8296037004253003 / TEST 0.7905
epoch: 54
 [LOSS] TRAIN 0.3637989354902602 / TEST 0.4519276871681213
 [ACC] TRAIN 0.843042880374948 / TEST 0.788
epoch: 55
 [LOSS] TRAIN 0.3183656469265034 / TEST 0.4223409547805786
 [ACC] TRAIN 0.8762970371370927 / TEST 0.813
epoch: 56
 [LOSS] TRAIN 0.32859732665737235 / TEST 0.423976984500885
 [ACC] TRAIN 0.8618577322910422 / TEST 0.8145
epoch: 57
 [LOSS] TRAIN 0.29827651985437664 / TEST 0.3949546513557434
 [ACC] TRAIN 0.8867983498607879 / TEST 0.831
epoch: 58
 [LOSS] TRAIN 0.34716289346554025 / TEST 0.4682944340705872
 [ACC] TRAIN 0.8375421927889998 / TEST 0.787
epoch: 59
 [LOSS] TRAIN 0.28165536206474096 / TEST 0.4198509094715118
 [ACC] TRAIN 0.8758594823384348 / TEST 0.814
epoch: 60
 [LOSS] TRAIN 0.18764328711449257 / TEST 0.32104217481613156
 [ACC] TRAIN 0.940617577085377 / TEST 0.8785
epoch: 61
 [LOSS] TRAIN 0.27066888280444806 / TEST 0.4263076195716858
 [ACC] TRAIN 0.8814851856631091 / TEST 0.8305
epoch: 62
 [LOSS] TRAIN 0.18515822076956948 / TEST 0.3547693164348602
 [ACC] TRAIN 0.9316164520639586 / TEST 0.8685
epoch: 63
 [LOSS] TRAIN 0.22711591426283587 / TEST 0.40063903617858887
 [ACC] TRAIN 0.9012376546025171 / TEST 0.8505
epoch: 64
 [LOSS] TRAIN 0.1412900756569054 / TEST 0.30557220077514646
 [ACC] TRAIN 0.9573071634028759 / TEST 0.8825
epoch: 65
 [LOSS] TRAIN 0.13805578978587157 / TEST 0.3372618155479431
 [ACC] TRAIN 0.9472434053735176 / TEST 0.8835
epoch: 66
 [LOSS] TRAIN 0.13257001385564043 / TEST 0.32804363608360293
 [ACC] TRAIN 0.951681460242135 / TEST 0.8845
epoch: 67
 [LOSS] TRAIN 0.11852057822489234 / TEST 0.3511371591091156
 [ACC] TRAIN 0.9554319289389633 / TEST 0.895
epoch: 68
 [LOSS] TRAIN 0.11714749415638537 / TEST 0.30279651886224745
 [ACC] TRAIN 0.9643080384526526 / TEST 0.9015
epoch: 69
 [LOSS] TRAIN 0.07497364034845257 / TEST 0.330801087975502
 [ACC] TRAIN 0.9760595074458813 / TEST 0.9
epoch: 70
 [LOSS] TRAIN 0.27714700577355633 / TEST 0.5576393084526062
 [ACC] TRAIN 0.8944868107991958 / TEST 0.837
epoch: 71
 [LOSS] TRAIN 0.09021165818516233 / TEST 0.3285394277572632
 [ACC] TRAIN 0.9701837728598488 / TEST 0.886
epoch: 72
 [LOSS] TRAIN 0.08970057937103647 / TEST 0.3792496764659882
 [ACC] TRAIN 0.9654331791473935 / TEST 0.8925
epoch: 73
 [LOSS] TRAIN 0.3263314005836485 / TEST 0.421332049369812
 [ACC] TRAIN 0.865295661860875 / TEST 0.8195
epoch: 74
 [LOSS] TRAIN 0.05240620806177999 / TEST 0.3706885596513748
 [ACC] TRAIN 0.9817477185244202 / TEST 0.911
epoch: 75
 [LOSS] TRAIN 0.10595735222108663 / TEST 0.3094009207487106
 [ACC] TRAIN 0.9640580073105185 / TEST 0.9
epoch: 76
 [LOSS] TRAIN 0.04131403329345227 / TEST 0.38070150661468505
 [ACC] TRAIN 0.9857482185273159 / TEST 0.9085
epoch: 77
 [LOSS] TRAIN 0.0661298373281203 / TEST 0.41990520948171617
 [ACC] TRAIN 0.9753719214380256 / TEST 0.9055
epoch: 78
 [LOSS] TRAIN 0.032084521083183354 / TEST 0.4338985919952393
 [ACC] TRAIN 0.9893111638954869 / TEST 0.9125
epoch: 79
 [LOSS] TRAIN 0.06415945025034465 / TEST 0.4254394735097885
 [ACC] TRAIN 0.977247155954099 / TEST 0.901
epoch: 80
 [LOSS] TRAIN 0.061726308036430255 / TEST 0.4217440377473831
 [ACC] TRAIN 0.9763095385805639 / TEST 0.9055
epoch: 81
 [LOSS] TRAIN 0.011902283623782914 / TEST 0.4236051179766655
 [ACC] TRAIN 0.9969371171992546 / TEST 0.925
Best test accurcy is (0.4675396990776062, 0.915)
Net(
  (model): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): ReLU(inplace)
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): ReLU(inplace)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
    (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (10): ReLU(inplace)
    (11): Flatten()
    (12): Linear(in_features=2304, out_features=128, bias=True)
    (13): ReLU(inplace)
    (14): Linear(in_features=128, out_features=2, bias=True)
  )
) 0.05 128
epoch: 1
 [LOSS] TRAIN 0.6929679055827337 / TEST 0.6926577401161194
 [ACC] TRAIN 0.5006875859333405 / TEST 0.5129999990463256
epoch: 2
 [LOSS] TRAIN 0.6926970583734728 / TEST 0.6927035608291626
 [ACC] TRAIN 0.5261907740628247 / TEST 0.5245
epoch: 3
 [LOSS] TRAIN 0.6922894786903151 / TEST 0.6919969549179077
 [ACC] TRAIN 0.5415676959470922 / TEST 0.5505000002384186
epoch: 4
 [LOSS] TRAIN 0.6917697931993215 / TEST 0.6910738258361816
 [ACC] TRAIN 0.5295036879311891 / TEST 0.5394999990463257
epoch: 5
 [LOSS] TRAIN 0.6907470384036352 / TEST 0.6907593212127685
 [ACC] TRAIN 0.5239404924945066 / TEST 0.5270000009536743
epoch: 6
 [LOSS] TRAIN 0.6884620621109295 / TEST 0.687573305606842
 [ACC] TRAIN 0.5533191650968028 / TEST 0.5624999990463256
epoch: 7
 [LOSS] TRAIN 0.6858816827695241 / TEST 0.6850760135650634
 [ACC] TRAIN 0.5528191023579925 / TEST 0.556
epoch: 8
 [LOSS] TRAIN 0.6869095821859896 / TEST 0.6853690314292907
 [ACC] TRAIN 0.5475684462494963 / TEST 0.5585000009536744
epoch: 9
 [LOSS] TRAIN 0.6809551235153789 / TEST 0.6807047562599182
 [ACC] TRAIN 0.570258782310536 / TEST 0.5640000009536743
epoch: 10
 [LOSS] TRAIN 0.6780403480483288 / TEST 0.6791630907058716
 [ACC] TRAIN 0.5727590948421518 / TEST 0.575
epoch: 11
 [LOSS] TRAIN 0.6745919467866651 / TEST 0.6750445494651794
 [ACC] TRAIN 0.5842605327752132 / TEST 0.5815
epoch: 12
 [LOSS] TRAIN 0.6795448167560428 / TEST 0.6830137033462524
 [ACC] TRAIN 0.5635704462461761 / TEST 0.561
epoch: 13
 [LOSS] TRAIN 0.6711149300198389 / TEST 0.67283393907547
 [ACC] TRAIN 0.5846355796560733 / TEST 0.583
epoch: 14
 [LOSS] TRAIN 0.6806882145569046 / TEST 0.678095739364624
 [ACC] TRAIN 0.5633829228504551 / TEST 0.5680000004768372
epoch: 15
 [LOSS] TRAIN 0.673955870972736 / TEST 0.6775522136688232
 [ACC] TRAIN 0.5741967747756609 / TEST 0.5754999995231629
epoch: 16
 [LOSS] TRAIN 0.6668741314064519 / TEST 0.6666460886001587
 [ACC] TRAIN 0.591573946743343 / TEST 0.5949999990463257
epoch: 17
 [LOSS] TRAIN 0.669580364818945 / TEST 0.673567024230957
 [ACC] TRAIN 0.5871358921876891 / TEST 0.5844999990463257
epoch: 18
 [LOSS] TRAIN 0.6658979917275993 / TEST 0.6645256395339966
 [ACC] TRAIN 0.5918239781760859 / TEST 0.5945
epoch: 19
 [LOSS] TRAIN 0.658969926437686 / TEST 0.6595542073249817
 [ACC] TRAIN 0.6087010878371453 / TEST 0.6029999995231629
epoch: 20
 [LOSS] TRAIN 0.6695730165997689 / TEST 0.6666859483718872
 [ACC] TRAIN 0.5838854856335501 / TEST 0.5865000009536743
epoch: 21
 [LOSS] TRAIN 0.6644503802027549 / TEST 0.6672208528518677
 [ACC] TRAIN 0.6002000251894132 / TEST 0.6024999990463257
epoch: 22
 [LOSS] TRAIN 0.6606620759468613 / TEST 0.6595020108222961
 [ACC] TRAIN 0.6015126890563297 / TEST 0.6070000009536743
epoch: 23
 [LOSS] TRAIN 0.6647608415650373 / TEST 0.667749819278717
 [ACC] TRAIN 0.5953869233058086 / TEST 0.5929999990463257
epoch: 24
 [LOSS] TRAIN 0.6586263387303662 / TEST 0.6619697885513306
 [ACC] TRAIN 0.6073259158735946 / TEST 0.6089999990463257
epoch: 25
 [LOSS] TRAIN 0.6540402969519397 / TEST 0.6544737763404846
 [ACC] TRAIN 0.6167645957309286 / TEST 0.6155000004768372
epoch: 26
 [LOSS] TRAIN 0.6588715024703233 / TEST 0.6624933190345764
 [ACC] TRAIN 0.6043880484464511 / TEST 0.6009999990463257
epoch: 27
 [LOSS] TRAIN 0.65348620370919 / TEST 0.6549681758880616
 [ACC] TRAIN 0.6174521815003358 / TEST 0.6299999995231629
epoch: 28
 [LOSS] TRAIN 0.6520068553898212 / TEST 0.6539313135147095
 [ACC] TRAIN 0.6202650330471745 / TEST 0.6259999990463256
epoch: 29
 [LOSS] TRAIN 0.6510634216491483 / TEST 0.653089322566986
 [ACC] TRAIN 0.6200775098675474 / TEST 0.6244999995231628
epoch: 30
 [LOSS] TRAIN 0.6491806713144903 / TEST 0.6510095224380493
 [ACC] TRAIN 0.6220777598540922 / TEST 0.6125000009536743
epoch: 31
 [LOSS] TRAIN 0.6493477119939269 / TEST 0.649281533241272
 [ACC] TRAIN 0.6215776973984393 / TEST 0.6165000004768372
epoch: 32
 [LOSS] TRAIN 0.652247370101613 / TEST 0.6554101357460022
 [ACC] TRAIN 0.611638955063098 / TEST 0.613
epoch: 33
 [LOSS] TRAIN 0.6477090667852656 / TEST 0.6477423567771912
 [ACC] TRAIN 0.6243280409306106 / TEST 0.6189999995231629
epoch: 34
 [LOSS] TRAIN 0.6464055289788788 / TEST 0.6500676970481872
 [ACC] TRAIN 0.6248281036843238 / TEST 0.6235000009536743
epoch: 35
 [LOSS] TRAIN 0.6400148307238389 / TEST 0.6418102307319641
 [ACC] TRAIN 0.6350168772512175 / TEST 0.6324999995231628
epoch: 36
 [LOSS] TRAIN 0.6446170059274563 / TEST 0.6451895656585693
 [ACC] TRAIN 0.6258907362898821 / TEST 0.6245
epoch: 37
 [LOSS] TRAIN 0.6581549618240893 / TEST 0.664968523979187
 [ACC] TRAIN 0.6016377046981861 / TEST 0.6009999990463257
epoch: 38
 [LOSS] TRAIN 0.6691339275571373 / TEST 0.6754773387908936
 [ACC] TRAIN 0.5956369546118759 / TEST 0.6039999995231629
epoch: 39
 [LOSS] TRAIN 0.6397264149952329 / TEST 0.640049497127533
 [ACC] TRAIN 0.6366420804090628 / TEST 0.6325
epoch: 40
 [LOSS] TRAIN 0.6409725906297794 / TEST 0.645212420463562
 [ACC] TRAIN 0.6250781349456821 / TEST 0.6304999990463257
epoch: 41
 [LOSS] TRAIN 0.6364914154779883 / TEST 0.6376904540061951
 [ACC] TRAIN 0.6401425179786601 / TEST 0.6344999995231628
epoch: 42
 [LOSS] TRAIN 0.6634123338164502 / TEST 0.6621004753112792
 [ACC] TRAIN 0.5858857359032524 / TEST 0.5885000004768371
epoch: 43
 [LOSS] TRAIN 0.6665830828947102 / TEST 0.6646504487991333
 [ACC] TRAIN 0.599637454868123 / TEST 0.6045000009536743
epoch: 44
 [LOSS] TRAIN 0.6363369280255605 / TEST 0.6380419454574585
 [ACC] TRAIN 0.6299537441435121 / TEST 0.6300000004768371
epoch: 45
 [LOSS] TRAIN 0.6292811479996496 / TEST 0.6354198265075683
 [ACC] TRAIN 0.6476434553350593 / TEST 0.6360000004768371
epoch: 46
 [LOSS] TRAIN 0.6219001080799377 / TEST 0.6281231737136841
 [ACC] TRAIN 0.6559569948106159 / TEST 0.6455000004768372
epoch: 47
 [LOSS] TRAIN 0.7323653781200918 / TEST 0.7448638887405395
 [ACC] TRAIN 0.541192649282326 / TEST 0.537
epoch: 48
 [LOSS] TRAIN 0.6283844711482786 / TEST 0.6288556642532349
 [ACC] TRAIN 0.6419552445769354 / TEST 0.6379999995231629
epoch: 49
 [LOSS] TRAIN 0.6172598273415225 / TEST 0.6218107581138611
 [ACC] TRAIN 0.66195774486712 / TEST 0.6564999995231628
epoch: 50
 [LOSS] TRAIN 0.6230068575189864 / TEST 0.6329480276107788
 [ACC] TRAIN 0.6594574321119587 / TEST 0.6505
epoch: 51
 [LOSS] TRAIN 0.6603360452537522 / TEST 0.6593608083724976
 [ACC] TRAIN 0.5991999001737862 / TEST 0.605
epoch: 52
 [LOSS] TRAIN 0.6242081901925491 / TEST 0.6263165946006775
 [ACC] TRAIN 0.6445805724970564 / TEST 0.6425000009536743
epoch: 53
 [LOSS] TRAIN 0.625137932435589 / TEST 0.6260693521499634
 [ACC] TRAIN 0.6441430180635225 / TEST 0.639
epoch: 54
 [LOSS] TRAIN 0.6079079263030566 / TEST 0.6146218256950379
 [ACC] TRAIN 0.6715214400757014 / TEST 0.6590000004768372
epoch: 55
 [LOSS] TRAIN 0.60456787847641 / TEST 0.6120531930923462
 [ACC] TRAIN 0.673771721390668 / TEST 0.6659999995231628
epoch: 56
 [LOSS] TRAIN 0.6264826893538203 / TEST 0.6289962816238404
 [ACC] TRAIN 0.6429553693764686 / TEST 0.647
epoch: 57
 [LOSS] TRAIN 0.6075507707261402 / TEST 0.610986982345581
 [ACC] TRAIN 0.6602700336871556 / TEST 0.6580000004768372
epoch: 58
 [LOSS] TRAIN 0.5976662016284512 / TEST 0.6047281184196472
 [ACC] TRAIN 0.6717714713519626 / TEST 0.6710000009536743
epoch: 59
 [LOSS] TRAIN 0.5878159363190224 / TEST 0.5959547214508056
 [ACC] TRAIN 0.6901487686929442 / TEST 0.6894999990463256
epoch: 60
 [LOSS] TRAIN 0.5942084480932555 / TEST 0.6071668806076049
 [ACC] TRAIN 0.6838979871515364 / TEST 0.6799999995231628
epoch: 61
 [LOSS] TRAIN 0.6379709365755666 / TEST 0.6430151524543762
 [ACC] TRAIN 0.6308288537855371 / TEST 0.6245000009536743
epoch: 62
 [LOSS] TRAIN 0.5872032528132822 / TEST 0.600431788444519
 [ACC] TRAIN 0.6848981121895179 / TEST 0.6789999990463257
epoch: 63
 [LOSS] TRAIN 0.5752549244547087 / TEST 0.5850566120147705
 [ACC] TRAIN 0.6975246904745506 / TEST 0.6964999995231629
epoch: 64
 [LOSS] TRAIN 0.581269117873495 / TEST 0.5891432909965515
 [ACC] TRAIN 0.6908363546784453 / TEST 0.6915
epoch: 65
 [LOSS] TRAIN 0.5706974285619678 / TEST 0.5808344016075134
 [ACC] TRAIN 0.7047755970837459 / TEST 0.7030000004768372
epoch: 66
 [LOSS] TRAIN 0.6307366074122612 / TEST 0.6348093981742859
 [ACC] TRAIN 0.6385173148506208 / TEST 0.6365000004768372
epoch: 67
 [LOSS] TRAIN 0.5703949849670239 / TEST 0.5870791268348694
 [ACC] TRAIN 0.7026503314031841 / TEST 0.6954999995231629
epoch: 68
 [LOSS] TRAIN 0.5590957086940812 / TEST 0.5703119039535522
 [ACC] TRAIN 0.7126515815818082 / TEST 0.7015
epoch: 69
 [LOSS] TRAIN 0.5745135899453867 / TEST 0.5883334302902221
 [ACC] TRAIN 0.6955244404656512 / TEST 0.6924999990463256
epoch: 70
 [LOSS] TRAIN 0.5548514227730614 / TEST 0.569334659576416
 [ACC] TRAIN 0.7196524567359059 / TEST 0.7110000009536743
epoch: 71
 [LOSS] TRAIN 0.555767954334734 / TEST 0.5737353277206421
 [ACC] TRAIN 0.7169021129205773 / TEST 0.7034999995231629
epoch: 72
 [LOSS] TRAIN 0.6496272237543196 / TEST 0.672206983089447
 [ACC] TRAIN 0.6250781349307791 / TEST 0.6139999990463256
epoch: 73
 [LOSS] TRAIN 0.5421678879765037 / TEST 0.5598886942863465
 [ACC] TRAIN 0.7278409800107426 / TEST 0.7204999990463257
epoch: 74
 [LOSS] TRAIN 0.5625388823996367 / TEST 0.5778258423805237
 [ACC] TRAIN 0.7058382299203011 / TEST 0.6894999990463256
epoch: 75
 [LOSS] TRAIN 0.5576155708572063 / TEST 0.578496675491333
 [ACC] TRAIN 0.7145268157327573 / TEST 0.7024999995231629
epoch: 76
 [LOSS] TRAIN 0.5414277335780459 / TEST 0.5640136041641235
 [ACC] TRAIN 0.7255281909046538 / TEST 0.7119999995231628
epoch: 77
 [LOSS] TRAIN 0.5756637388608622 / TEST 0.5840489854812622
 [ACC] TRAIN 0.7002125267372055 / TEST 0.6895000004768371
epoch: 78
 [LOSS] TRAIN 0.5189977720880944 / TEST 0.5415957522392273
 [ACC] TRAIN 0.7475934493078233 / TEST 0.7204999995231628
epoch: 79
 [LOSS] TRAIN 0.514467257732957 / TEST 0.5420973320007324
 [ACC] TRAIN 0.7429053632896205 / TEST 0.7240000004768372
epoch: 80
 [LOSS] TRAIN 0.5154103130560426 / TEST 0.5457154347896576
 [ACC] TRAIN 0.744093011738226 / TEST 0.717
epoch: 81
 [LOSS] TRAIN 0.4956515662848078 / TEST 0.5305389213562012
 [ACC] TRAIN 0.7608451055264321 / TEST 0.7280000004768371
epoch: 82
 [LOSS] TRAIN 0.506254715354819 / TEST 0.5398561329841614
 [ACC] TRAIN 0.7525940741326067 / TEST 0.7199999995231628
epoch: 83
 [LOSS] TRAIN 0.4921257608286186 / TEST 0.5235623745918274
 [ACC] TRAIN 0.7680335040613478 / TEST 0.7380000004768371
epoch: 84
 [LOSS] TRAIN 0.47839470048787697 / TEST 0.518075208902359
 [ACC] TRAIN 0.7766595825297726 / TEST 0.7524999995231628
epoch: 85
 [LOSS] TRAIN 0.47234322519462724 / TEST 0.5059306395053863
 [ACC] TRAIN 0.7857857230738232 / TEST 0.7565
epoch: 86
 [LOSS] TRAIN 0.45461677791088995 / TEST 0.49865776824951175
 [ACC] TRAIN 0.7955994500579171 / TEST 0.7550000009536744
epoch: 87
 [LOSS] TRAIN 0.4497893902231327 / TEST 0.4931754894256592
 [ACC] TRAIN 0.7965995747754836 / TEST 0.7665000004768372
epoch: 88
 [LOSS] TRAIN 0.434880345146989 / TEST 0.48017697858810426
 [ACC] TRAIN 0.8036629577505096 / TEST 0.774
epoch: 89
 [LOSS] TRAIN 0.4051371086372526 / TEST 0.47121147966384885
 [ACC] TRAIN 0.8224153018009664 / TEST 0.7755
epoch: 90
 [LOSS] TRAIN 0.4048780783561933 / TEST 0.46003317046165465
 [ACC] TRAIN 0.8266033252666467 / TEST 0.7804999995231628
epoch: 91
 [LOSS] TRAIN 0.42031605016560775 / TEST 0.48114077425003055
 [ACC] TRAIN 0.8061007626847425 / TEST 0.766
epoch: 92
 [LOSS] TRAIN 0.4064549829217997 / TEST 0.4784844720363617
 [ACC] TRAIN 0.8188523563955379 / TEST 0.7740000004768371
epoch: 93
 [LOSS] TRAIN 0.34894225790077693 / TEST 0.4264974112510681
 [ACC] TRAIN 0.862295287000282 / TEST 0.8119999995231628
epoch: 94
 [LOSS] TRAIN 0.34177226407898414 / TEST 0.4205538430213928
 [ACC] TRAIN 0.8573571694897241 / TEST 0.8079999990463257
epoch: 95
 [LOSS] TRAIN 0.3169056052624516 / TEST 0.41309980154037473
 [ACC] TRAIN 0.8703587946779714 / TEST 0.8269999990463257
epoch: 96
 [LOSS] TRAIN 0.3302025191373178 / TEST 0.41530436944961546
 [ACC] TRAIN 0.8683585448702629 / TEST 0.8220000009536743
epoch: 97
 [LOSS] TRAIN 0.2923324080460041 / TEST 0.39087115073204043
 [ACC] TRAIN 0.895486935658341 / TEST 0.8349999990463257
epoch: 98
 [LOSS] TRAIN 0.2953440282274476 / TEST 0.4167816314697266
 [ACC] TRAIN 0.8652331542187831 / TEST 0.8155000009536744
epoch: 99
 [LOSS] TRAIN 0.22658544235049763 / TEST 0.36159864616394044
 [ACC] TRAIN 0.9268658582695366 / TEST 0.8555000009536743
epoch: 100
 [LOSS] TRAIN 0.23631731270514275 / TEST 0.38254688096046446
 [ACC] TRAIN 0.9085510686898711 / TEST 0.8429999995231628
epoch: 101
 [LOSS] TRAIN 0.25447466194719087 / TEST 0.416142436504364
 [ACC] TRAIN 0.8919239905435214 / TEST 0.8334999990463257
Best test accurcy is (0.41635047364234923, 0.8285000004768371)
Net(
  (model): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): ReLU(inplace)
    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): ReLU(inplace)
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))
    (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (10): ReLU(inplace)
    (11): Flatten()
    (12): Linear(in_features=1152, out_features=128, bias=True)
    (13): ReLU(inplace)
    (14): Linear(in_features=128, out_features=2, bias=True)
  )
) 0.05 64
epoch: 1
 [LOSS] TRAIN 0.6929523023624303 / TEST 0.6924515409469605
 [ACC] TRAIN 0.500875109381222 / TEST 0.5195
epoch: 2
 [LOSS] TRAIN 0.6925823403114169 / TEST 0.6925406804084778
 [ACC] TRAIN 0.5461932742635911 / TEST 0.556
epoch: 3
 [LOSS] TRAIN 0.6921548127144452 / TEST 0.6912905082702637
 [ACC] TRAIN 0.511626453418436 / TEST 0.53
epoch: 4
 [LOSS] TRAIN 0.6902300817681217 / TEST 0.6904289951324463
 [ACC] TRAIN 0.5426303288432595 / TEST 0.548
epoch: 5
 [LOSS] TRAIN 0.6871337677735301 / TEST 0.6871207756996155
 [ACC] TRAIN 0.5533191649999332 / TEST 0.548
epoch: 6
 [LOSS] TRAIN 0.6826142206879344 / TEST 0.6822192659378051
 [ACC] TRAIN 0.5662582822852856 / TEST 0.576
epoch: 7
 [LOSS] TRAIN 0.6766893422026861 / TEST 0.6797309956550598
 [ACC] TRAIN 0.5772596575018912 / TEST 0.5695
epoch: 8
 [LOSS] TRAIN 0.6953894773979964 / TEST 0.7026612825393677
 [ACC] TRAIN 0.5261282661450268 / TEST 0.513
epoch: 9
 [LOSS] TRAIN 0.667103533044966 / TEST 0.6662947130203247
 [ACC] TRAIN 0.5935741968863695 / TEST 0.6015
epoch: 10
 [LOSS] TRAIN 0.6668323797648482 / TEST 0.665504364490509
 [ACC] TRAIN 0.5970746343143881 / TEST 0.598
epoch: 11
 [LOSS] TRAIN 0.663654541213716 / TEST 0.6669255857467651
 [ACC] TRAIN 0.6020127516312068 / TEST 0.5985
epoch: 12
 [LOSS] TRAIN 0.6652935790723525 / TEST 0.6628816828727723
 [ACC] TRAIN 0.5938867357600136 / TEST 0.5965
epoch: 13
 [LOSS] TRAIN 0.6583832837385093 / TEST 0.6612083411216736
 [ACC] TRAIN 0.6123890485565637 / TEST 0.6085
epoch: 14
 [LOSS] TRAIN 0.6569137170711508 / TEST 0.66025386095047
 [ACC] TRAIN 0.6185148143890515 / TEST 0.619
epoch: 15
 [LOSS] TRAIN 0.6572159719789068 / TEST 0.6608371458053589
 [ACC] TRAIN 0.6095136891962484 / TEST 0.6105
epoch: 16
 [LOSS] TRAIN 0.655815559858858 / TEST 0.6548334994316101
 [ACC] TRAIN 0.6089511188824097 / TEST 0.5975
epoch: 17
 [LOSS] TRAIN 0.6755480948187795 / TEST 0.6690778288841247
 [ACC] TRAIN 0.5836354544243525 / TEST 0.595
epoch: 18
 [LOSS] TRAIN 0.6653078479354926 / TEST 0.6752628231048584
 [ACC] TRAIN 0.5904488062050838 / TEST 0.5825
epoch: 19
 [LOSS] TRAIN 0.6830585643356629 / TEST 0.6981258225440979
 [ACC] TRAIN 0.5706963371389999 / TEST 0.5585
epoch: 20
 [LOSS] TRAIN 0.6452634352969444 / TEST 0.6498286027908325
 [ACC] TRAIN 0.6290786349336749 / TEST 0.631
epoch: 21
 [LOSS] TRAIN 0.6427405534766438 / TEST 0.6494511046409607
 [ACC] TRAIN 0.6349543693334195 / TEST 0.6285
epoch: 22
 [LOSS] TRAIN 0.6499902000724115 / TEST 0.6537115535736084
 [ACC] TRAIN 0.6133266659450018 / TEST 0.6125
epoch: 23
 [LOSS] TRAIN 0.7045854722086914 / TEST 0.7234302453994751
 [ACC] TRAIN 0.536067008420756 / TEST 0.5035
epoch: 24
 [LOSS] TRAIN 0.6342878667603941 / TEST 0.6435422415733337
 [ACC] TRAIN 0.6425178147193893 / TEST 0.6305
epoch: 25
 [LOSS] TRAIN 0.634008711927428 / TEST 0.6381176190376282
 [ACC] TRAIN 0.6392049005380614 / TEST 0.6385
epoch: 26
 [LOSS] TRAIN 0.6415026074633745 / TEST 0.6532148513793945
 [ACC] TRAIN 0.6238904863107888 / TEST 0.6055
epoch: 27
 [LOSS] TRAIN 0.6211946946350481 / TEST 0.6241138553619385
 [ACC] TRAIN 0.6556444556538142 / TEST 0.6525
epoch: 28
 [LOSS] TRAIN 0.6113729216051275 / TEST 0.6179420332908631
 [ACC] TRAIN 0.6653956743698892 / TEST 0.663
epoch: 29
 [LOSS] TRAIN 0.6172256666222935 / TEST 0.6268262205123901
 [ACC] TRAIN 0.6650206276678654 / TEST 0.6485
epoch: 30
 [LOSS] TRAIN 0.6169442688693015 / TEST 0.6253640937805176
 [ACC] TRAIN 0.6555194400417639 / TEST 0.651
epoch: 31
 [LOSS] TRAIN 0.6219812051208783 / TEST 0.6368119931221008
 [ACC] TRAIN 0.6499562445156633 / TEST 0.6345
epoch: 32
 [LOSS] TRAIN 0.6189796739197445 / TEST 0.6197669339179993
 [ACC] TRAIN 0.6570196274534317 / TEST 0.6595
epoch: 33
 [LOSS] TRAIN 0.639279669054539 / TEST 0.658992356300354
 [ACC] TRAIN 0.6278284786119805 / TEST 0.6155
epoch: 34
 [LOSS] TRAIN 0.5973037242710568 / TEST 0.5966129646301269
 [ACC] TRAIN 0.6742092762563896 / TEST 0.6815
epoch: 35
 [LOSS] TRAIN 0.5918575060458493 / TEST 0.6042097601890564
 [ACC] TRAIN 0.6847730967414009 / TEST 0.6765
epoch: 36
 [LOSS] TRAIN 0.5860430927913864 / TEST 0.5925161733627319
 [ACC] TRAIN 0.6918364795301389 / TEST 0.6775
epoch: 37
 [LOSS] TRAIN 0.585512954744045 / TEST 0.5932677764892578
 [ACC] TRAIN 0.6912739092684609 / TEST 0.6915
epoch: 38
 [LOSS] TRAIN 0.599523902490804 / TEST 0.6049663615226746
 [ACC] TRAIN 0.669458682380001 / TEST 0.6765
epoch: 39
 [LOSS] TRAIN 0.5849127198013757 / TEST 0.6043429987430573
 [ACC] TRAIN 0.690461307648555 / TEST 0.677
epoch: 40
 [LOSS] TRAIN 0.5694124096705774 / TEST 0.5880612103939057
 [ACC] TRAIN 0.7019002374477246 / TEST 0.6835
epoch: 41
 [LOSS] TRAIN 0.5716911328481218 / TEST 0.5814056010246277
 [ACC] TRAIN 0.6968996125484261 / TEST 0.7015
epoch: 42
 [LOSS] TRAIN 0.5579950899493025 / TEST 0.5761950039863586
 [ACC] TRAIN 0.7109013626330762 / TEST 0.706
epoch: 43
 [LOSS] TRAIN 0.5487905048790508 / TEST 0.5648677332401275
 [ACC] TRAIN 0.7217152143347366 / TEST 0.7115
epoch: 44
 [LOSS] TRAIN 0.5476015952694847 / TEST 0.5704232621192932
 [ACC] TRAIN 0.7255281910462326 / TEST 0.707
epoch: 45
 [LOSS] TRAIN 0.534047975869816 / TEST 0.5549477667808532
 [ACC] TRAIN 0.7344668083286894 / TEST 0.715
epoch: 46
 [LOSS] TRAIN 0.5607537542794523 / TEST 0.5755368909835815
 [ACC] TRAIN 0.7034629328517052 / TEST 0.6975
epoch: 47
 [LOSS] TRAIN 0.5280115576010374 / TEST 0.5592631554603577
 [ACC] TRAIN 0.7389048631898552 / TEST 0.714
epoch: 48
 [LOSS] TRAIN 0.5078719796791928 / TEST 0.5390839385986328
 [ACC] TRAIN 0.7574696836135941 / TEST 0.734
epoch: 49
 [LOSS] TRAIN 0.5113960576737012 / TEST 0.5450260095596313
 [ACC] TRAIN 0.7510313789447198 / TEST 0.72
epoch: 50
 [LOSS] TRAIN 0.5140828005983495 / TEST 0.5408591742515564
 [ACC] TRAIN 0.7433429177827665 / TEST 0.7245
epoch: 51
 [LOSS] TRAIN 0.48696171068254 / TEST 0.535134444475174
 [ACC] TRAIN 0.7674709337773152 / TEST 0.738
epoch: 52
 [LOSS] TRAIN 0.4948714669085485 / TEST 0.5321317021846771
 [ACC] TRAIN 0.7594699338311358 / TEST 0.7345
epoch: 53
 [LOSS] TRAIN 0.47299878683175456 / TEST 0.5219918394088745
 [ACC] TRAIN 0.7873484186268341 / TEST 0.7475
epoch: 54
 [LOSS] TRAIN 0.46318695366062185 / TEST 0.5259901432991028
 [ACC] TRAIN 0.7780347543740991 / TEST 0.7485
epoch: 55
 [LOSS] TRAIN 0.4693091459565795 / TEST 0.5118362128734588
 [ACC] TRAIN 0.7742217777520213 / TEST 0.7515
epoch: 56
 [LOSS] TRAIN 0.4178080507212392 / TEST 0.4830120911598206
 [ACC] TRAIN 0.8192899112538079 / TEST 0.7705
epoch: 57
 [LOSS] TRAIN 0.4161107292628643 / TEST 0.5037780036926269
 [ACC] TRAIN 0.8177272159168908 / TEST 0.759
epoch: 58
 [LOSS] TRAIN 0.366155579240937 / TEST 0.46521647691726686
 [ACC] TRAIN 0.8443555443461858 / TEST 0.783
epoch: 59
 [LOSS] TRAIN 0.3435481572422419 / TEST 0.44728106451034544
 [ACC] TRAIN 0.8576072008554034 / TEST 0.7915
epoch: 60
 [LOSS] TRAIN 0.3912279626729712 / TEST 0.4849782772064209
 [ACC] TRAIN 0.8176647081704776 / TEST 0.771
epoch: 61
 [LOSS] TRAIN 0.38539759620068476 / TEST 0.5107856709957123
 [ACC] TRAIN 0.8219152393676681 / TEST 0.77
epoch: 62
 [LOSS] TRAIN 0.3425685178974238 / TEST 0.4586466374397278
 [ACC] TRAIN 0.8517939742616839 / TEST 0.796
epoch: 63
 [LOSS] TRAIN 0.29015697674283925 / TEST 0.4108057076931
 [ACC] TRAIN 0.8902362796020055 / TEST 0.827
epoch: 64
 [LOSS] TRAIN 0.27887124767645044 / TEST 0.4167181839942932
 [ACC] TRAIN 0.877922240235326 / TEST 0.8265
epoch: 65
 [LOSS] TRAIN 0.22750676272883835 / TEST 0.3821476664543152
 [ACC] TRAIN 0.9144268033131613 / TEST 0.8535
epoch: 66
 [LOSS] TRAIN 0.40746836562293187 / TEST 0.5908073282241821
 [ACC] TRAIN 0.8085385673358182 / TEST 0.7585
epoch: 67
 [LOSS] TRAIN 0.2495888087738751 / TEST 0.42403570890426634
 [ACC] TRAIN 0.8917989747749894 / TEST 0.8235
epoch: 68
 [LOSS] TRAIN 0.2272297893912215 / TEST 0.4016590695381165
 [ACC] TRAIN 0.9104888111684513 / TEST 0.849
epoch: 69
 [LOSS] TRAIN 0.16494835191502363 / TEST 0.36046150779724123
 [ACC] TRAIN 0.94399299907273 / TEST 0.865
epoch: 70
 [LOSS] TRAIN 0.3273128363538912 / TEST 0.526412317276001
 [ACC] TRAIN 0.8524190522772265 / TEST 0.798
epoch: 71
 [LOSS] TRAIN 0.15234025649550348 / TEST 0.3930940561294556
 [ACC] TRAIN 0.9409926241376219 / TEST 0.8735
epoch: 72
 [LOSS] TRAIN 0.1749928880984492 / TEST 0.39736874675750733
 [ACC] TRAIN 0.9279909988301502 / TEST 0.858
epoch: 73
 [LOSS] TRAIN 0.15207366106219256 / TEST 0.3554339294433594
 [ACC] TRAIN 0.9513689211747515 / TEST 0.8685
epoch: 74
 [LOSS] TRAIN 0.1349044514558944 / TEST 0.3841749277114868
 [ACC] TRAIN 0.944930616386653 / TEST 0.8715
epoch: 75
 [LOSS] TRAIN 0.15663315749776438 / TEST 0.419961715221405
 [ACC] TRAIN 0.933866733229895 / TEST 0.863
epoch: 76
 [LOSS] TRAIN 0.10050578830256762 / TEST 0.437047198176384
 [ACC] TRAIN 0.9602450305170559 / TEST 0.8835
epoch: 77
 [LOSS] TRAIN 0.1273493478932758 / TEST 0.39243518447875975
 [ACC] TRAIN 0.9499937492857159 / TEST 0.883
epoch: 78
 [LOSS] TRAIN 0.18935909982971408 / TEST 0.42864203071594237
 [ACC] TRAIN 0.921427678467259 / TEST 0.8635
epoch: 79
 [LOSS] TRAIN 0.06356859001677875 / TEST 0.4068824789524078
 [ACC] TRAIN 0.980247530829595 / TEST 0.8925
epoch: 80
 [LOSS] TRAIN 0.10052327158010808 / TEST 0.43506752705574037
 [ACC] TRAIN 0.9626203275409426 / TEST 0.8805
epoch: 81
 [LOSS] TRAIN 0.05194859911030658 / TEST 0.4404443485736847
 [ACC] TRAIN 0.9814351794570367 / TEST 0.9005
epoch: 82
 [LOSS] TRAIN 0.04265283429274478 / TEST 0.4246980955600739
 [ACC] TRAIN 0.9854981872734092 / TEST 0.8935
epoch: 83
 [LOSS] TRAIN 0.052336833391681825 / TEST 0.4117307377755642
 [ACC] TRAIN 0.9815601949126054 / TEST 0.898
epoch: 84
 [LOSS] TRAIN 0.0488121934814451 / TEST 0.44756921935081484
 [ACC] TRAIN 0.9831228903612952 / TEST 0.9055
epoch: 85
 [LOSS] TRAIN 0.05793228393632712 / TEST 0.4933302104473114
 [ACC] TRAIN 0.9783097886118177 / TEST 0.8925
epoch: 86
 [LOSS] TRAIN 0.05271621882460954 / TEST 0.3856585848927498
 [ACC] TRAIN 0.9816227027856942 / TEST 0.8995
epoch: 87
 [LOSS] TRAIN 0.05139045120342767 / TEST 0.4642079828977585
 [ACC] TRAIN 0.9811851482031301 / TEST 0.8965
Best test accurcy is (0.45964873242378235, 0.8955)
Net(
  (model): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): ReLU(inplace)
    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): ReLU(inplace)
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))
    (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (10): ReLU(inplace)
    (11): Flatten()
    (12): Linear(in_features=1152, out_features=128, bias=True)
    (13): ReLU(inplace)
    (14): Linear(in_features=128, out_features=2, bias=True)
  )
) 0.05 128
epoch: 1
 [LOSS] TRAIN 0.6930702223913686 / TEST 0.6939892911911011
 [ACC] TRAIN 0.5043130391373427 / TEST 0.481
epoch: 2
 [LOSS] TRAIN 0.6928924112666293 / TEST 0.6935001883506775
 [ACC] TRAIN 0.50431303914852 / TEST 0.48100000047683716
epoch: 3
 [LOSS] TRAIN 0.6928080226096649 / TEST 0.6937912020683289
 [ACC] TRAIN 0.504313039133617 / TEST 0.48100000047683716
epoch: 4
 [LOSS] TRAIN 0.6925090033645287 / TEST 0.6926827836036682
 [ACC] TRAIN 0.545068133710429 / TEST 0.5275000009536743
epoch: 5
 [LOSS] TRAIN 0.6921620966568784 / TEST 0.6931891322135926
 [ACC] TRAIN 0.5042505313238661 / TEST 0.481
epoch: 6
 [LOSS] TRAIN 0.6915087914270138 / TEST 0.6912200899124146
 [ACC] TRAIN 0.5418177271562898 / TEST 0.5505000004768371
epoch: 7
 [LOSS] TRAIN 0.6902182794821413 / TEST 0.6904111614227295
 [ACC] TRAIN 0.546943368107278 / TEST 0.5535000002384186
epoch: 8
 [LOSS] TRAIN 0.6896961428758756 / TEST 0.6919934644699096
 [ACC] TRAIN 0.5230028755904168 / TEST 0.5099999995231629
epoch: 9
 [LOSS] TRAIN 0.6872099857208713 / TEST 0.6867747945785523
 [ACC] TRAIN 0.5457557196586724 / TEST 0.5585
epoch: 10
 [LOSS] TRAIN 0.685069830466217 / TEST 0.6850672636032105
 [ACC] TRAIN 0.5518814851632937 / TEST 0.5649999997615814
epoch: 11
 [LOSS] TRAIN 0.6819449697662732 / TEST 0.6829515810012817
 [ACC] TRAIN 0.5570071258832848 / TEST 0.5585
epoch: 12
 [LOSS] TRAIN 0.6802993253300019 / TEST 0.6799364795684815
 [ACC] TRAIN 0.5660707590385949 / TEST 0.5739999995231628
epoch: 13
 [LOSS] TRAIN 0.6750589121742716 / TEST 0.6800421023368836
 [ACC] TRAIN 0.5906988372950572 / TEST 0.581
epoch: 14
 [LOSS] TRAIN 0.672963325940664 / TEST 0.6734792332649231
 [ACC] TRAIN 0.5868233531203058 / TEST 0.5844999990463257
epoch: 15
 [LOSS] TRAIN 0.6679686237490315 / TEST 0.670995509147644
 [ACC] TRAIN 0.5961370170824318 / TEST 0.5824999990463257
epoch: 16
 [LOSS] TRAIN 0.676715378650115 / TEST 0.6863306398391724
 [ACC] TRAIN 0.567945993204447 / TEST 0.5534999990463256
epoch: 17
 [LOSS] TRAIN 0.6654317290548355 / TEST 0.6668181405067444
 [ACC] TRAIN 0.5968246031014647 / TEST 0.5924999990463257
epoch: 18
 [LOSS] TRAIN 0.6613805250072944 / TEST 0.6660622458457947
 [ACC] TRAIN 0.6078259781876688 / TEST 0.5835000004768371
epoch: 19
 [LOSS] TRAIN 0.6792289328539367 / TEST 0.6750247297286988
 [ACC] TRAIN 0.5710713841390842 / TEST 0.5815
epoch: 20
 [LOSS] TRAIN 0.6578205614734373 / TEST 0.6612552685737609
 [ACC] TRAIN 0.6131391423480901 / TEST 0.5999999995231629
epoch: 21
 [LOSS] TRAIN 0.6638119824157087 / TEST 0.6645440173149109
 [ACC] TRAIN 0.6004500564358685 / TEST 0.6005
epoch: 22
 [LOSS] TRAIN 0.6627513829403064 / TEST 0.6630724821090698
 [ACC] TRAIN 0.5976372048592237 / TEST 0.5990000004768372
epoch: 23
 [LOSS] TRAIN 0.6701449674358217 / TEST 0.6810717215538025
 [ACC] TRAIN 0.5933866735279061 / TEST 0.5754999990463256
epoch: 24
 [LOSS] TRAIN 0.6557719053171742 / TEST 0.6626167387962342
 [ACC] TRAIN 0.6132641582283948 / TEST 0.6015000009536743
epoch: 25
 [LOSS] TRAIN 0.6690424513348878 / TEST 0.6810533757209778
 [ACC] TRAIN 0.5833854231257366 / TEST 0.5674999995231629
epoch: 26
 [LOSS] TRAIN 0.7148126568596338 / TEST 0.7347582626342773
 [ACC] TRAIN 0.5325665710523495 / TEST 0.505
epoch: 27
 [LOSS] TRAIN 0.6585907846454502 / TEST 0.6679891357421875
 [ACC] TRAIN 0.6076384547546902 / TEST 0.6
epoch: 28
 [LOSS] TRAIN 0.6534321209850542 / TEST 0.6578123655319214
 [ACC] TRAIN 0.6150768845584157 / TEST 0.6035000004768372
epoch: 29
 [LOSS] TRAIN 0.6515823367357642 / TEST 0.658355263710022
 [ACC] TRAIN 0.6237654708701232 / TEST 0.6060000009536743
epoch: 30
 [LOSS] TRAIN 0.6486907904558531 / TEST 0.6564389529228211
 [ACC] TRAIN 0.6241405177584349 / TEST 0.6030000009536743
epoch: 31
 [LOSS] TRAIN 0.6744208701596676 / TEST 0.6710475878715515
 [ACC] TRAIN 0.5823852981548188 / TEST 0.5909999990463257
epoch: 32
 [LOSS] TRAIN 0.6559410879486486 / TEST 0.6688784413337707
 [ACC] TRAIN 0.6117639706825998 / TEST 0.5980000009536743
epoch: 33
 [LOSS] TRAIN 0.6473034138395751 / TEST 0.6535010256767273
 [ACC] TRAIN 0.6213901739282032 / TEST 0.6150000009536744
epoch: 34
 [LOSS] TRAIN 0.652841662992491 / TEST 0.6550095257759094
 [ACC] TRAIN 0.6114514315854104 / TEST 0.6134999995231628
epoch: 35
 [LOSS] TRAIN 0.6453337306632952 / TEST 0.6579410901069641
 [ACC] TRAIN 0.628266033432993 / TEST 0.6054999995231628
epoch: 36
 [LOSS] TRAIN 0.6606318771369697 / TEST 0.6754555978775024
 [ACC] TRAIN 0.6095761970097251 / TEST 0.59
epoch: 37
 [LOSS] TRAIN 0.6746167194502013 / TEST 0.6716423673629761
 [ACC] TRAIN 0.5855106890298438 / TEST 0.5914999995231628
epoch: 38
 [LOSS] TRAIN 0.640082819415027 / TEST 0.6516250696182251
 [ACC] TRAIN 0.6351418926695285 / TEST 0.6110000009536743
epoch: 39
 [LOSS] TRAIN 0.6677155568608941 / TEST 0.6866807942390442
 [ACC] TRAIN 0.5876984622481763 / TEST 0.5650000009536743
epoch: 40
 [LOSS] TRAIN 0.646245260621059 / TEST 0.6618380990028382
 [ACC] TRAIN 0.6223277909217112 / TEST 0.6004999995231628
epoch: 41
 [LOSS] TRAIN 0.661274270126709 / TEST 0.6609994106292725
 [ACC] TRAIN 0.6016377049142799 / TEST 0.6069999990463257
epoch: 42
 [LOSS] TRAIN 0.6410722546405174 / TEST 0.6511483297348023
 [ACC] TRAIN 0.6408926117403804 / TEST 0.6340000004768371
epoch: 43
 [LOSS] TRAIN 0.6583796223635554 / TEST 0.6774893736839295
 [ACC] TRAIN 0.6057007127604584 / TEST 0.5914999990463257
epoch: 44
 [LOSS] TRAIN 0.6340492475046219 / TEST 0.6418899393081665
 [ACC] TRAIN 0.6423927992414662 / TEST 0.632
epoch: 45
 [LOSS] TRAIN 0.6455449260746126 / TEST 0.6642918877601623
 [ACC] TRAIN 0.6217027130030381 / TEST 0.5965
epoch: 46
 [LOSS] TRAIN 0.6326276373901968 / TEST 0.6490150637626648
 [ACC] TRAIN 0.6459557443860918 / TEST 0.6254999990463257
epoch: 47
 [LOSS] TRAIN 0.6943572873114824 / TEST 0.7200549631118774
 [ACC] TRAIN 0.5544443055158378 / TEST 0.5249999990463257
epoch: 48
 [LOSS] TRAIN 0.6233701523370573 / TEST 0.6325900044441223
 [ACC] TRAIN 0.6546443306977994 / TEST 0.648
epoch: 49
 [LOSS] TRAIN 0.6289203592815583 / TEST 0.6401223320960998
 [ACC] TRAIN 0.6472684087075506 / TEST 0.6439999995231629
epoch: 50
 [LOSS] TRAIN 0.6243613077217467 / TEST 0.635865264415741
 [ACC] TRAIN 0.6531441431892621 / TEST 0.6465000009536743
epoch: 51
 [LOSS] TRAIN 0.6274802948567462 / TEST 0.6450210390090942
 [ACC] TRAIN 0.6516439554050186 / TEST 0.6385
epoch: 52
 [LOSS] TRAIN 0.62304789990332 / TEST 0.6387284574508667
 [ACC] TRAIN 0.6680210027743584 / TEST 0.6575000004768372
epoch: 53
 [LOSS] TRAIN 0.6476931068759841 / TEST 0.6709377932548523
 [ACC] TRAIN 0.6225778221756179 / TEST 0.598
epoch: 54
 [LOSS] TRAIN 0.6115324919202026 / TEST 0.6275237131118775
 [ACC] TRAIN 0.6675834478713792 / TEST 0.6444999995231628
epoch: 55
 [LOSS] TRAIN 0.6156436186952134 / TEST 0.6301152544021607
 [ACC] TRAIN 0.6684585572078923 / TEST 0.6580000009536743
epoch: 56
 [LOSS] TRAIN 0.6061785085109759 / TEST 0.6206539392471313
 [ACC] TRAIN 0.6768346044969255 / TEST 0.6655
epoch: 57
 [LOSS] TRAIN 0.7547516504486347 / TEST 0.7907758255004883
 [ACC] TRAIN 0.5428803602610994 / TEST 0.5079999997615814
epoch: 58
 [LOSS] TRAIN 0.5953891835207938 / TEST 0.6137004995346069
 [ACC] TRAIN 0.682960370195286 / TEST 0.6644999995231629
epoch: 59
 [LOSS] TRAIN 0.5993741980074704 / TEST 0.6184051370620728
 [ACC] TRAIN 0.6793349168124475 / TEST 0.6594999995231628
epoch: 60
 [LOSS] TRAIN 0.6099862208260881 / TEST 0.6317894325256348
 [ACC] TRAIN 0.6670208775128316 / TEST 0.645
epoch: 61
 [LOSS] TRAIN 0.5892700096088166 / TEST 0.6037552771568299
 [ACC] TRAIN 0.693586698493774 / TEST 0.6780000009536743
epoch: 62
 [LOSS] TRAIN 0.5908184909182708 / TEST 0.6080977759361267
 [ACC] TRAIN 0.6864608077499803 / TEST 0.6689999990463257
epoch: 63
 [LOSS] TRAIN 0.5911438189859554 / TEST 0.6092306728363037
 [ACC] TRAIN 0.6893986749535785 / TEST 0.6760000004768372
epoch: 64
 [LOSS] TRAIN 0.595731830795134 / TEST 0.6163747529983521
 [ACC] TRAIN 0.6792099011780426 / TEST 0.6605
epoch: 65
 [LOSS] TRAIN 0.5872141843602753 / TEST 0.5987151074409485
 [ACC] TRAIN 0.688023502848449 / TEST 0.6854999990463256
epoch: 66
 [LOSS] TRAIN 0.5861409594527124 / TEST 0.6068879570960999
 [ACC] TRAIN 0.6933991750384408 / TEST 0.6765000009536744
epoch: 67
 [LOSS] TRAIN 0.582455894361065 / TEST 0.6005906629562378
 [ACC] TRAIN 0.7020877610893455 / TEST 0.6815000009536744
epoch: 68
 [LOSS] TRAIN 0.5864134232824125 / TEST 0.6008852672576904
 [ACC] TRAIN 0.6904613078348427 / TEST 0.6840000004768372
epoch: 69
 [LOSS] TRAIN 0.5836233100469059 / TEST 0.6035265545845032
 [ACC] TRAIN 0.6958994875626052 / TEST 0.6770000004768372
epoch: 70
 [LOSS] TRAIN 0.5697941170854708 / TEST 0.5864495868682862
 [ACC] TRAIN 0.7030878861124239 / TEST 0.6935
epoch: 71
 [LOSS] TRAIN 0.5662020705300341 / TEST 0.5851670179367066
 [ACC] TRAIN 0.7082760346384402 / TEST 0.6900000009536743
epoch: 72
 [LOSS] TRAIN 0.6377002104533763 / TEST 0.6712122449874878
 [ACC] TRAIN 0.6373296663871123 / TEST 0.6145
epoch: 73
 [LOSS] TRAIN 0.5639593149963238 / TEST 0.5835623450279236
 [ACC] TRAIN 0.7117764721931346 / TEST 0.6904999995231629
epoch: 74
 [LOSS] TRAIN 0.6138720259560333 / TEST 0.6440698857307434
 [ACC] TRAIN 0.6596449555449373 / TEST 0.6405
epoch: 75
 [LOSS] TRAIN 0.5860365334861442 / TEST 0.5992407665252686
 [ACC] TRAIN 0.6816477058812788 / TEST 0.6844999990463256
epoch: 76
 [LOSS] TRAIN 0.5587406873568875 / TEST 0.5823050694465637
 [ACC] TRAIN 0.7155894488301153 / TEST 0.6975
epoch: 77
 [LOSS] TRAIN 0.5567397358402906 / TEST 0.5750136480331421
 [ACC] TRAIN 0.714089261291772 / TEST 0.7039999990463257
epoch: 78
 [LOSS] TRAIN 0.5578330506725838 / TEST 0.5806492300033569
 [ACC] TRAIN 0.7177147142424227 / TEST 0.6980000009536743
epoch: 79
 [LOSS] TRAIN 0.5466142455135707 / TEST 0.5724809813499451
 [ACC] TRAIN 0.7254031755310518 / TEST 0.7065
epoch: 80
 [LOSS] TRAIN 0.5534150555053642 / TEST 0.5817122602462769
 [ACC] TRAIN 0.7188398548626486 / TEST 0.7045000009536743
epoch: 81
 [LOSS] TRAIN 0.5612465528819484 / TEST 0.5897777500152588
 [ACC] TRAIN 0.7109013625809156 / TEST 0.6950000004768372
epoch: 82
 [LOSS] TRAIN 0.5464801209645653 / TEST 0.5651297588348388
 [ACC] TRAIN 0.7206525814832785 / TEST 0.6974999995231629
epoch: 83
 [LOSS] TRAIN 0.543634839006656 / TEST 0.5636315093040466
 [ACC] TRAIN 0.7250906362475745 / TEST 0.7075000004768371
epoch: 84
 [LOSS] TRAIN 0.5493372585463783 / TEST 0.5760864300727844
 [ACC] TRAIN 0.7211526439910919 / TEST 0.7054999995231629
Best test accurcy is (0.5666899981498719, 0.7065000004768371)
Net(
  (model): Sequential(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): ReLU(inplace)
    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): ReLU(inplace)
    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
    (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (10): ReLU(inplace)
    (11): Flatten()
    (12): Linear(in_features=576, out_features=128, bias=True)
    (13): ReLU(inplace)
    (14): Linear(in_features=128, out_features=2, bias=True)
  )
) 0.05 64
epoch: 1
 [LOSS] TRAIN 0.693089178643058 / TEST 0.6929664912223816
 [ACC] TRAIN 0.5003750468249738 / TEST 0.5095
epoch: 2
 [LOSS] TRAIN 0.693009809033992 / TEST 0.6929058332443238
 [ACC] TRAIN 0.5003750469851813 / TEST 0.5095
epoch: 3
 [LOSS] TRAIN 0.692807609721383 / TEST 0.6928858532905579
 [ACC] TRAIN 0.516689586302596 / TEST 0.519
epoch: 4
 [LOSS] TRAIN 0.6928795713501463 / TEST 0.6937659749984741
 [ACC] TRAIN 0.4996249530669793 / TEST 0.4905
epoch: 5
 [LOSS] TRAIN 0.6914644370169651 / TEST 0.6922230701446533
 [ACC] TRAIN 0.5423177897684245 / TEST 0.5285
epoch: 6
 [LOSS] TRAIN 0.689240684463376 / TEST 0.6914587650299072
 [ACC] TRAIN 0.536004500506684 / TEST 0.512
epoch: 7
 [LOSS] TRAIN 0.6864855405479271 / TEST 0.6890822305679322
 [ACC] TRAIN 0.5544443055829014 / TEST 0.5485
epoch: 8
 [LOSS] TRAIN 0.6851074549463008 / TEST 0.6872131552696228
 [ACC] TRAIN 0.5542567820903107 / TEST 0.5535
epoch: 9
 [LOSS] TRAIN 0.6782424694255734 / TEST 0.6824512548446655
 [ACC] TRAIN 0.5696962120190519 / TEST 0.564
epoch: 10
 [LOSS] TRAIN 0.6784180388895925 / TEST 0.6814531049728394
 [ACC] TRAIN 0.5669458681739171 / TEST 0.568
epoch: 11
 [LOSS] TRAIN 0.6759673974144115 / TEST 0.6826149697303772
 [ACC] TRAIN 0.5718214777368712 / TEST 0.5625
epoch: 12
 [LOSS] TRAIN 0.6711359492375383 / TEST 0.6761344647407532
 [ACC] TRAIN 0.5881360170468344 / TEST 0.5815
epoch: 13
 [LOSS] TRAIN 0.6674639010059787 / TEST 0.6708651447296142
 [ACC] TRAIN 0.596449556306297 / TEST 0.5905
epoch: 14
 [LOSS] TRAIN 0.666440653769668 / TEST 0.6720670828819275
 [ACC] TRAIN 0.5916989624150054 / TEST 0.588
epoch: 15
 [LOSS] TRAIN 0.6634478722457394 / TEST 0.6676853313446045
 [ACC] TRAIN 0.6028253531020825 / TEST 0.596
epoch: 16
 [LOSS] TRAIN 0.6620201371523541 / TEST 0.6659961647987366
 [ACC] TRAIN 0.6023877985195184 / TEST 0.5915
epoch: 17
 [LOSS] TRAIN 0.6616766111361025 / TEST 0.6657968573570251
 [ACC] TRAIN 0.6045755718719782 / TEST 0.5965
epoch: 18
 [LOSS] TRAIN 0.6676945795803044 / TEST 0.674572163105011
 [ACC] TRAIN 0.5947618452679114 / TEST 0.5915
epoch: 19
 [LOSS] TRAIN 0.6594002498270706 / TEST 0.6644477820396424
 [ACC] TRAIN 0.6055756970142808 / TEST 0.5945
epoch: 20
 [LOSS] TRAIN 0.6734482019018242 / TEST 0.6742365970611572
 [ACC] TRAIN 0.5855731967539024 / TEST 0.58
epoch: 21
 [LOSS] TRAIN 0.6592500407571479 / TEST 0.6623936862945556
 [ACC] TRAIN 0.6060132515893935 / TEST 0.5965
epoch: 22
 [LOSS] TRAIN 0.6571546190007654 / TEST 0.6644281826019287
 [ACC] TRAIN 0.6120140018023794 / TEST 0.6045
epoch: 23
 [LOSS] TRAIN 0.6615566381112771 / TEST 0.6683733086585999
 [ACC] TRAIN 0.6025753220195605 / TEST 0.5995
epoch: 24
 [LOSS] TRAIN 0.6549860117047679 / TEST 0.6608005661964417
 [ACC] TRAIN 0.6175146893808761 / TEST 0.602
epoch: 25
 [LOSS] TRAIN 0.6513636822491262 / TEST 0.658393964767456
 [ACC] TRAIN 0.6208276034429798 / TEST 0.613
epoch: 26
 [LOSS] TRAIN 0.6620435353844952 / TEST 0.6721471180915832
 [ACC] TRAIN 0.6034504314156857 / TEST 0.598
epoch: 27
 [LOSS] TRAIN 0.6490921044829547 / TEST 0.6576267156600952
 [ACC] TRAIN 0.6250156270055297 / TEST 0.617
epoch: 28
 [LOSS] TRAIN 0.6657745981308829 / TEST 0.6714027237892151
 [ACC] TRAIN 0.5870108763520935 / TEST 0.578
epoch: 29
 [LOSS] TRAIN 0.6677601796073427 / TEST 0.6739175577163696
 [ACC] TRAIN 0.5953244156562651 / TEST 0.5815
epoch: 30
 [LOSS] TRAIN 0.653640303802216 / TEST 0.6607417244911193
 [ACC] TRAIN 0.6071383923437464 / TEST 0.596
epoch: 31
 [LOSS] TRAIN 0.6424059887605393 / TEST 0.6537179341316223
 [ACC] TRAIN 0.626765845782877 / TEST 0.6135
epoch: 32
 [LOSS] TRAIN 0.6612769080737424 / TEST 0.6771565885543823
 [ACC] TRAIN 0.5945118139692955 / TEST 0.582
epoch: 33
 [LOSS] TRAIN 0.6298284879221382 / TEST 0.6398579578399658
 [ACC] TRAIN 0.6452056508106595 / TEST 0.645
epoch: 34
 [LOSS] TRAIN 0.6185111066433382 / TEST 0.6323736038208008
 [ACC] TRAIN 0.6566445806619897 / TEST 0.649
epoch: 35
 [LOSS] TRAIN 0.6155946032749681 / TEST 0.6302750506401062
 [ACC] TRAIN 0.6614576821432127 / TEST 0.6505
epoch: 36
 [LOSS] TRAIN 0.6268621234763249 / TEST 0.6424426021575927
 [ACC] TRAIN 0.6450806350048698 / TEST 0.6355
epoch: 37
 [LOSS] TRAIN 0.6350290330816379 / TEST 0.651954379081726
 [ACC] TRAIN 0.639017377164695 / TEST 0.629
epoch: 38
 [LOSS] TRAIN 0.6152277685564925 / TEST 0.6266106977462769
 [ACC] TRAIN 0.6650206274890291 / TEST 0.658
epoch: 39
 [LOSS] TRAIN 0.6073132416042243 / TEST 0.6202745113372803
 [ACC] TRAIN 0.6760845105489175 / TEST 0.6645
epoch: 40
 [LOSS] TRAIN 0.6162342615523387 / TEST 0.6263971495628357
 [ACC] TRAIN 0.6567070883636937 / TEST 0.647
epoch: 41
 [LOSS] TRAIN 0.6029141342242013 / TEST 0.6173460183143615
 [ACC] TRAIN 0.6732716589350152 / TEST 0.6665
epoch: 42
 [LOSS] TRAIN 0.6073446469554932 / TEST 0.6181955833435059
 [ACC] TRAIN 0.6708338542690365 / TEST 0.6625
epoch: 43
 [LOSS] TRAIN 0.5914672650774057 / TEST 0.6053465485572815
 [ACC] TRAIN 0.6882735342886436 / TEST 0.6865
epoch: 44
 [LOSS] TRAIN 0.5987081546934861 / TEST 0.6108606519699097
 [ACC] TRAIN 0.6769596199301395 / TEST 0.668
epoch: 45
 [LOSS] TRAIN 0.5872524488358248 / TEST 0.5998680319786072
 [ACC] TRAIN 0.6918989874702913 / TEST 0.6905
epoch: 46
 [LOSS] TRAIN 0.5904099567485819 / TEST 0.6038272390365601
 [ACC] TRAIN 0.6855856981973735 / TEST 0.6745
epoch: 47
 [LOSS] TRAIN 0.5945650636292887 / TEST 0.6069785618782043
 [ACC] TRAIN 0.6841480185395703 / TEST 0.6665
epoch: 48
 [LOSS] TRAIN 0.59287471671539 / TEST 0.6054643850326538
 [ACC] TRAIN 0.6840855107260937 / TEST 0.6705
epoch: 49
 [LOSS] TRAIN 0.5808507956583987 / TEST 0.5947478709220886
 [ACC] TRAIN 0.7017752218803833 / TEST 0.6875
epoch: 50
 [LOSS] TRAIN 0.5726309996915617 / TEST 0.587428768157959
 [ACC] TRAIN 0.7045255657851301 / TEST 0.692
epoch: 51
 [LOSS] TRAIN 0.6263409764159544 / TEST 0.6458872814178467
 [ACC] TRAIN 0.6505188148816625 / TEST 0.6465
epoch: 52
 [LOSS] TRAIN 0.5882044941622818 / TEST 0.6153619112968445
 [ACC] TRAIN 0.6882735341098073 / TEST 0.6825
epoch: 53
 [LOSS] TRAIN 0.5586373613080109 / TEST 0.5773633170127869
 [ACC] TRAIN 0.7154644329647136 / TEST 0.706
epoch: 54
 [LOSS] TRAIN 0.5799255762372647 / TEST 0.5939858717918396
 [ACC] TRAIN 0.6898362296181092 / TEST 0.6815
epoch: 55
 [LOSS] TRAIN 0.553708027669647 / TEST 0.5734344186782837
 [ACC] TRAIN 0.7177772220857055 / TEST 0.7045
epoch: 56
 [LOSS] TRAIN 0.5578937237673155 / TEST 0.5885490493774415
 [ACC] TRAIN 0.7102762845057609 / TEST 0.69
epoch: 57
 [LOSS] TRAIN 0.5401300725034959 / TEST 0.5686264228820801
 [ACC] TRAIN 0.7270908862788285 / TEST 0.712
epoch: 58
 [LOSS] TRAIN 0.5387871880347408 / TEST 0.5571332201957703
 [ACC] TRAIN 0.7279659958314353 / TEST 0.715
epoch: 59
 [LOSS] TRAIN 0.5265661797190863 / TEST 0.5557552700042725
 [ACC] TRAIN 0.745155644485363 / TEST 0.723
epoch: 60
 [LOSS] TRAIN 0.5158043925367842 / TEST 0.5435708494186401
 [ACC] TRAIN 0.7469683710761869 / TEST 0.727
epoch: 61
 [LOSS] TRAIN 0.5101525847845367 / TEST 0.5429199829101562
 [ACC] TRAIN 0.7578447306285815 / TEST 0.744
epoch: 62
 [LOSS] TRAIN 0.4900329343481859 / TEST 0.532298282623291
 [ACC] TRAIN 0.7622202774527252 / TEST 0.737
epoch: 63
 [LOSS] TRAIN 0.526876199758117 / TEST 0.5617114777565002
 [ACC] TRAIN 0.7302162770048233 / TEST 0.704
epoch: 64
 [LOSS] TRAIN 0.5896636768868154 / TEST 0.6209561820030213
 [ACC] TRAIN 0.6697712213877723 / TEST 0.6585
epoch: 65
 [LOSS] TRAIN 0.5012892676913927 / TEST 0.5597799484729766
 [ACC] TRAIN 0.7539692461259634 / TEST 0.718
epoch: 66
 [LOSS] TRAIN 0.5071444831642304 / TEST 0.5747302341461181
 [ACC] TRAIN 0.7363420427255384 / TEST 0.697
epoch: 67
 [LOSS] TRAIN 0.44321664279960876 / TEST 0.5070114364624023
 [ACC] TRAIN 0.7922865358542347 / TEST 0.7515
epoch: 68
 [LOSS] TRAIN 0.4272929915362171 / TEST 0.5004675166606903
 [ACC] TRAIN 0.8126640830327309 / TEST 0.762
epoch: 69
 [LOSS] TRAIN 0.44419074097653155 / TEST 0.5212027859687806
 [ACC] TRAIN 0.7855981996781022 / TEST 0.7415
epoch: 70
 [LOSS] TRAIN 0.3970056933072943 / TEST 0.4892464234828949
 [ACC] TRAIN 0.8226653331219368 / TEST 0.7675
epoch: 71
 [LOSS] TRAIN 0.3777560317854626 / TEST 0.46906545948982237
 [ACC] TRAIN 0.8363545443329428 / TEST 0.783
epoch: 72
 [LOSS] TRAIN 0.3878163123320067 / TEST 0.47508998012542725
 [ACC] TRAIN 0.8241655207646014 / TEST 0.771
epoch: 73
 [LOSS] TRAIN 0.4168278037316949 / TEST 0.5176428217887878
 [ACC] TRAIN 0.8056007001098655 / TEST 0.749
epoch: 74
 [LOSS] TRAIN 0.4233004589172613 / TEST 0.5226382551193237
 [ACC] TRAIN 0.7954119265131658 / TEST 0.7455
epoch: 75
 [LOSS] TRAIN 0.34005312260754006 / TEST 0.453119402885437
 [ACC] TRAIN 0.8569821227951517 / TEST 0.793
epoch: 76
 [LOSS] TRAIN 0.3340417817616883 / TEST 0.4522010416984558
 [ACC] TRAIN 0.8560445055184863 / TEST 0.7945
epoch: 77
 [LOSS] TRAIN 0.2802621653220373 / TEST 0.42489792370796203
 [ACC] TRAIN 0.8879234903319834 / TEST 0.815
epoch: 78
 [LOSS] TRAIN 0.3000726156688389 / TEST 0.44751203060150146
 [ACC] TRAIN 0.8705463183046892 / TEST 0.8095
epoch: 79
 [LOSS] TRAIN 0.23607483021854414 / TEST 0.4165071783065796
 [ACC] TRAIN 0.9073009126215282 / TEST 0.838
epoch: 80
 [LOSS] TRAIN 0.2958879233643567 / TEST 0.504467495083809
 [ACC] TRAIN 0.8672334041829735 / TEST 0.795
epoch: 81
 [LOSS] TRAIN 0.2234587848581423 / TEST 0.4252136731147766
 [ACC] TRAIN 0.9111138891988969 / TEST 0.8375
epoch: 82
 [LOSS] TRAIN 0.24366583342715523 / TEST 0.4112707347869873
 [ACC] TRAIN 0.9055506938441811 / TEST 0.833
epoch: 83
 [LOSS] TRAIN 0.32156497768006154 / TEST 0.5182782642841339
 [ACC] TRAIN 0.8557944742720311 / TEST 0.796
epoch: 84
 [LOSS] TRAIN 0.21889492649930106 / TEST 0.40179929399490355
 [ACC] TRAIN 0.9140517564248496 / TEST 0.836
epoch: 85
 [LOSS] TRAIN 0.1464115930305509 / TEST 0.3958940243721008
 [ACC] TRAIN 0.9434304287514399 / TEST 0.873
epoch: 86
 [LOSS] TRAIN 0.16828620728328386 / TEST 0.3855498764514923
 [ACC] TRAIN 0.9378047255385382 / TEST 0.86
epoch: 87
 [LOSS] TRAIN 0.15456827976864895 / TEST 0.40921776413917543
 [ACC] TRAIN 0.9397424677041549 / TEST 0.859
epoch: 88
 [LOSS] TRAIN 0.18016398716906576 / TEST 0.44142025530338286
 [ACC] TRAIN 0.9249281159623413 / TEST 0.8445
epoch: 89
 [LOSS] TRAIN 0.11221691120496495 / TEST 0.37863287115097044
 [ACC] TRAIN 0.9595574445688124 / TEST 0.885
epoch: 90
 [LOSS] TRAIN 0.12349425746189205 / TEST 0.41056604266166685
 [ACC] TRAIN 0.9521815225860151 / TEST 0.8735
epoch: 91
 [LOSS] TRAIN 0.16890021279903186 / TEST 0.47697760581970217
 [ACC] TRAIN 0.9300537567270415 / TEST 0.855
epoch: 92
 [LOSS] TRAIN 0.17225697097859988 / TEST 0.4389666256904602
 [ACC] TRAIN 0.9289911239053893 / TEST 0.8495
epoch: 93
 [LOSS] TRAIN 0.11750985111038541 / TEST 0.36434589210152624
 [ACC] TRAIN 0.9576822101719634 / TEST 0.883
epoch: 94
 [LOSS] TRAIN 0.09222947941644294 / TEST 0.3994804177284241
 [ACC] TRAIN 0.9722465307045793 / TEST 0.881
epoch: 95
 [LOSS] TRAIN 0.07942839870994307 / TEST 0.4252754535675049
 [ACC] TRAIN 0.973059132451161 / TEST 0.894
epoch: 96
 [LOSS] TRAIN 0.07786198615271503 / TEST 0.43877504563331604
 [ACC] TRAIN 0.9732466557202063 / TEST 0.8885
epoch: 97
 [LOSS] TRAIN 0.10932671916005701 / TEST 0.476859917640686
 [ACC] TRAIN 0.9569946242162684 / TEST 0.879
epoch: 98
 [LOSS] TRAIN 0.08711096239784447 / TEST 0.40488443851470945
 [ACC] TRAIN 0.968746093149885 / TEST 0.8865
epoch: 99
 [LOSS] TRAIN 0.07097140379955148 / TEST 0.423737672328949
 [ACC] TRAIN 0.9749968746763897 / TEST 0.892
epoch: 100
 [LOSS] TRAIN 0.10040699467035007 / TEST 0.4402322750687599
 [ACC] TRAIN 0.9623077883617865 / TEST 0.8875
epoch: 101
 [LOSS] TRAIN 0.04786356445623124 / TEST 0.4757415673732758
 [ACC] TRAIN 0.9828103513535238 / TEST 0.898
epoch: 102
 [LOSS] TRAIN 0.08010068988763537 / TEST 0.4140046760439873
 [ACC] TRAIN 0.9724340543163942 / TEST 0.8935
Best test accurcy is (0.4149749081134796, 0.8985)
Net(
  (model): Sequential(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): ReLU(inplace)
    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): ReLU(inplace)
    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
    (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (10): ReLU(inplace)
    (11): Flatten()
    (12): Linear(in_features=576, out_features=128, bias=True)
    (13): ReLU(inplace)
    (14): Linear(in_features=128, out_features=2, bias=True)
  )
) 0.05 128
epoch: 1
 [LOSS] TRAIN 0.693105436672433 / TEST 0.6922717289924621
 [ACC] TRAIN 0.5015626953629974 / TEST 0.5399999995231628
epoch: 2
 [LOSS] TRAIN 0.6930260872495131 / TEST 0.6929389991760254
 [ACC] TRAIN 0.5290036254531817 / TEST 0.5500000009536743
epoch: 3
 [LOSS] TRAIN 0.6929901121243609 / TEST 0.6932451286315918
 [ACC] TRAIN 0.5027503440090679 / TEST 0.4635
epoch: 4
 [LOSS] TRAIN 0.6929209528975017 / TEST 0.6931994662284852
 [ACC] TRAIN 0.5085010626030231 / TEST 0.4794999990463257
epoch: 5
 [LOSS] TRAIN 0.6928139572472017 / TEST 0.6924675221443176
 [ACC] TRAIN 0.520190023969063 / TEST 0.547
epoch: 6
 [LOSS] TRAIN 0.6927435989677347 / TEST 0.6931250834465027
 [ACC] TRAIN 0.5155644455333399 / TEST 0.49299999952316287
epoch: 7
 [LOSS] TRAIN 0.6926940608760807 / TEST 0.693665581703186
 [ACC] TRAIN 0.4985623202900363 / TEST 0.4619999997615814
epoch: 8
 [LOSS] TRAIN 0.692439998346711 / TEST 0.6913965759277344
 [ACC] TRAIN 0.5121265160305707 / TEST 0.5380000009536743
epoch: 9
 [LOSS] TRAIN 0.6922256784120758 / TEST 0.6932719030380249
 [ACC] TRAIN 0.5106263282761333 / TEST 0.48100000047683716
epoch: 10
 [LOSS] TRAIN 0.6916864750042216 / TEST 0.6921995077133178
 [ACC] TRAIN 0.5404425553045119 / TEST 0.5374999995231629
epoch: 11
 [LOSS] TRAIN 0.6910577168433663 / TEST 0.6916768970489502
 [ACC] TRAIN 0.5425053131492424 / TEST 0.5480000004768372
epoch: 12
 [LOSS] TRAIN 0.6907122198947296 / TEST 0.6883517417907715
 [ACC] TRAIN 0.5341292661918016 / TEST 0.552
epoch: 13
 [LOSS] TRAIN 0.6892120689656648 / TEST 0.6872662897109986
 [ACC] TRAIN 0.5408176024163689 / TEST 0.5574999995231629
epoch: 14
 [LOSS] TRAIN 0.6872971281139146 / TEST 0.6863214592933655
 [ACC] TRAIN 0.5503812976398532 / TEST 0.5669999995231628
epoch: 15
 [LOSS] TRAIN 0.6849070801513167 / TEST 0.6859677901268005
 [ACC] TRAIN 0.5634454308800256 / TEST 0.5689999995231628
epoch: 16
 [LOSS] TRAIN 0.6820021163360642 / TEST 0.6805978441238403
 [ACC] TRAIN 0.56675834499429 / TEST 0.5755000004768371
epoch: 17
 [LOSS] TRAIN 0.6816381564928988 / TEST 0.6770290842056275
 [ACC] TRAIN 0.5635079384401509 / TEST 0.5844999990463257
epoch: 18
 [LOSS] TRAIN 0.6727302195221383 / TEST 0.6752562298774719
 [ACC] TRAIN 0.5875109388226494 / TEST 0.587
epoch: 19
 [LOSS] TRAIN 0.6726894676424531 / TEST 0.6736932840347291
 [ACC] TRAIN 0.583010376237425 / TEST 0.5829999995231628
epoch: 20
 [LOSS] TRAIN 0.6707439922976455 / TEST 0.6695412735939026
 [ACC] TRAIN 0.5841355171408082 / TEST 0.5859999990463257
epoch: 21
 [LOSS] TRAIN 0.6726579076797609 / TEST 0.6815055632591247
 [ACC] TRAIN 0.5855106887988469 / TEST 0.5680000004768372
epoch: 22
 [LOSS] TRAIN 0.66648742189585 / TEST 0.6677520289421082
 [ACC] TRAIN 0.5929491186323784 / TEST 0.5939999995231628
epoch: 23
 [LOSS] TRAIN 0.6733141616517744 / TEST 0.6682455368041992
 [ACC] TRAIN 0.5791348918167736 / TEST 0.5860000009536743
epoch: 24
 [LOSS] TRAIN 0.6725923138523805 / TEST 0.6679206247329712
 [ACC] TRAIN 0.5818227277888195 / TEST 0.5840000004768372
epoch: 25
 [LOSS] TRAIN 0.6629109916008626 / TEST 0.6629774584770203
 [ACC] TRAIN 0.6010751345706352 / TEST 0.5985000004768372
epoch: 26
 [LOSS] TRAIN 0.6683455040595251 / TEST 0.6758726859092712
 [ACC] TRAIN 0.5903862985108312 / TEST 0.5809999990463257
epoch: 27
 [LOSS] TRAIN 0.6612868284952612 / TEST 0.6643017439842224
 [ACC] TRAIN 0.6037629703191358 / TEST 0.5955000009536743
epoch: 28
 [LOSS] TRAIN 0.6632006266129317 / TEST 0.6709466590881348
 [ACC] TRAIN 0.6005125640257998 / TEST 0.596
epoch: 29
 [LOSS] TRAIN 0.6603918850742321 / TEST 0.6632743577957153
 [ACC] TRAIN 0.6087635954196251 / TEST 0.5979999990463257
epoch: 30
 [LOSS] TRAIN 0.6644846895423915 / TEST 0.6719683656692504
 [ACC] TRAIN 0.5988248533003776 / TEST 0.5915000004768372
epoch: 31
 [LOSS] TRAIN 0.6659216174991119 / TEST 0.6760004315376281
 [ACC] TRAIN 0.5940742592526043 / TEST 0.5835000009536743
epoch: 32
 [LOSS] TRAIN 0.6672885657131769 / TEST 0.6776257634162903
 [ACC] TRAIN 0.5915739468998247 / TEST 0.5810000004768372
epoch: 33
 [LOSS] TRAIN 0.6581194962407816 / TEST 0.6587538380622864
 [ACC] TRAIN 0.610763845450879 / TEST 0.6029999990463257
epoch: 34
 [LOSS] TRAIN 0.661237905078835 / TEST 0.669329384803772
 [ACC] TRAIN 0.6094511813157081 / TEST 0.5954999990463257
epoch: 35
 [LOSS] TRAIN 0.6601249003338805 / TEST 0.6596851358413697
 [ACC] TRAIN 0.6037004625056591 / TEST 0.5974999995231628
epoch: 36
 [LOSS] TRAIN 0.676480222492013 / TEST 0.6868615255355836
 [ACC] TRAIN 0.595011876462206 / TEST 0.5830000004768372
epoch: 37
 [LOSS] TRAIN 0.6715765116303872 / TEST 0.6846553754806518
 [ACC] TRAIN 0.5776347045466846 / TEST 0.5604999990463256
epoch: 38
 [LOSS] TRAIN 0.6609917012121189 / TEST 0.6547568578720093
 [ACC] TRAIN 0.6021377674369964 / TEST 0.6105000004768372
epoch: 39
 [LOSS] TRAIN 0.6552250110547175 / TEST 0.663898829460144
 [ACC] TRAIN 0.6144518064087459 / TEST 0.604
epoch: 40
 [LOSS] TRAIN 0.6566882761944411 / TEST 0.6577119436264038
 [ACC] TRAIN 0.6122640329221589 / TEST 0.6030000004768371
epoch: 41
 [LOSS] TRAIN 0.6513847842233184 / TEST 0.6499667654037475
 [ACC] TRAIN 0.6195149393003573 / TEST 0.6144999995231628
epoch: 42
 [LOSS] TRAIN 0.6611734835084252 / TEST 0.6718352746963501
 [ACC] TRAIN 0.6000125015254377 / TEST 0.5929999990463257
epoch: 43
 [LOSS] TRAIN 0.6496100760963741 / TEST 0.6492815580368042
 [ACC] TRAIN 0.6166395798953328 / TEST 0.6190000009536744
epoch: 44
 [LOSS] TRAIN 0.654594791756673 / TEST 0.6505792341232299
 [ACC] TRAIN 0.6085760721654829 / TEST 0.6135000004768372
epoch: 45
 [LOSS] TRAIN 0.6511150389958179 / TEST 0.6533877191543579
 [ACC] TRAIN 0.618264783284175 / TEST 0.6060000009536743
epoch: 46
 [LOSS] TRAIN 0.6554718978152542 / TEST 0.6503711109161376
 [ACC] TRAIN 0.6060132516042964 / TEST 0.6129999990463257
epoch: 47
 [LOSS] TRAIN 0.6599637025415129 / TEST 0.6715742702484131
 [ACC] TRAIN 0.6027628455345058 / TEST 0.5905000009536743
epoch: 48
 [LOSS] TRAIN 0.6444910379972647 / TEST 0.6475772209167481
 [ACC] TRAIN 0.6300162521954372 / TEST 0.6275000009536743
epoch: 49
 [LOSS] TRAIN 0.6429083606260599 / TEST 0.6431092338562012
 [ACC] TRAIN 0.6327665960107659 / TEST 0.6250000009536744
epoch: 50
 [LOSS] TRAIN 0.6416525692772248 / TEST 0.6461579303741455
 [ACC] TRAIN 0.6327040881749346 / TEST 0.6245
epoch: 51
 [LOSS] TRAIN 0.6463406837378491 / TEST 0.6568565492630005
 [ACC] TRAIN 0.6249531190802804 / TEST 0.6169999995231629
epoch: 52
 [LOSS] TRAIN 0.6473192567005055 / TEST 0.6441139121055603
 [ACC] TRAIN 0.6181397675901581 / TEST 0.6205
epoch: 53
 [LOSS] TRAIN 0.6395567121811547 / TEST 0.6409768705368042
 [ACC] TRAIN 0.6357044629982701 / TEST 0.6349999990463256
epoch: 54
 [LOSS] TRAIN 0.6474783834345208 / TEST 0.6424386034011841
 [ACC] TRAIN 0.6181397674560308 / TEST 0.6194999990463257
epoch: 55
 [LOSS] TRAIN 0.6405117750868289 / TEST 0.6499238333702088
 [ACC] TRAIN 0.6324540569359309 / TEST 0.6259999990463256
epoch: 56
 [LOSS] TRAIN 0.6367287294300426 / TEST 0.6429977984428406
 [ACC] TRAIN 0.6364545569835357 / TEST 0.6430000009536743
epoch: 57
 [LOSS] TRAIN 0.6345591868426088 / TEST 0.6368950791358948
 [ACC] TRAIN 0.6408301036586492 / TEST 0.6349999995231629
epoch: 58
 [LOSS] TRAIN 0.6364448044222285 / TEST 0.644339382648468
 [ACC] TRAIN 0.6412051505544123 / TEST 0.6435000004768372
epoch: 59
 [LOSS] TRAIN 0.6448560873632625 / TEST 0.6569827332496643
 [ACC] TRAIN 0.6315789473870498 / TEST 0.6209999995231629
epoch: 60
 [LOSS] TRAIN 0.6366244824785995 / TEST 0.6433266706466675
 [ACC] TRAIN 0.6468933618639481 / TEST 0.6445
epoch: 61
 [LOSS] TRAIN 0.6284145963968434 / TEST 0.6324344792366028
 [ACC] TRAIN 0.6494561821866861 / TEST 0.6439999990463257
epoch: 62
 [LOSS] TRAIN 0.6404278944739551 / TEST 0.6368878955841064
 [ACC] TRAIN 0.6288911113442145 / TEST 0.6320000004768371
epoch: 63
 [LOSS] TRAIN 0.6343446886007421 / TEST 0.6301751961708069
 [ACC] TRAIN 0.6358919866324395 / TEST 0.6380000009536743
epoch: 64
 [LOSS] TRAIN 0.6354746527784481 / TEST 0.6338329672813415
 [ACC] TRAIN 0.6343917991537081 / TEST 0.633
epoch: 65
 [LOSS] TRAIN 0.6233164633657206 / TEST 0.6301046710014343
 [ACC] TRAIN 0.6509563694716781 / TEST 0.6430000009536743
epoch: 66
 [LOSS] TRAIN 0.627208307379856 / TEST 0.6296432600021362
 [ACC] TRAIN 0.6495811975826427 / TEST 0.6500000009536743
epoch: 67
 [LOSS] TRAIN 0.6221631504339133 / TEST 0.6283711156845093
 [ACC] TRAIN 0.6577697214088912 / TEST 0.656
epoch: 68
 [LOSS] TRAIN 0.6400988406800586 / TEST 0.6554360489845276
 [ACC] TRAIN 0.6312039004428519 / TEST 0.6144999995231628
epoch: 69
 [LOSS] TRAIN 0.6347833613572024 / TEST 0.6519134001731872
 [ACC] TRAIN 0.6408926117776379 / TEST 0.6195
epoch: 70
 [LOSS] TRAIN 0.6180800991306336 / TEST 0.6291871643066407
 [ACC] TRAIN 0.6633954243088294 / TEST 0.6550000004768372
epoch: 71
 [LOSS] TRAIN 0.6749395412018127 / TEST 0.6974255757331849
 [ACC] TRAIN 0.6010126267869647 / TEST 0.583
epoch: 72
 [LOSS] TRAIN 0.6091946495489889 / TEST 0.6138769626617432
 [ACC] TRAIN 0.6686460807079344 / TEST 0.667
epoch: 73
 [LOSS] TRAIN 0.6245387581187883 / TEST 0.6199921126365662
 [ACC] TRAIN 0.6480185024543679 / TEST 0.6510000009536743
epoch: 74
 [LOSS] TRAIN 0.6183448574038979 / TEST 0.6134126405715943
 [ACC] TRAIN 0.6543942994364411 / TEST 0.6565000004768372
epoch: 75
 [LOSS] TRAIN 0.6307923804895478 / TEST 0.6486808562278747
 [ACC] TRAIN 0.6392674083887957 / TEST 0.6145000009536743
epoch: 76
 [LOSS] TRAIN 0.6181850448699724 / TEST 0.6128998579978943
 [ACC] TRAIN 0.6533316665924345 / TEST 0.6585000004768372
epoch: 77
 [LOSS] TRAIN 0.5996871559988605 / TEST 0.6043567972183228
 [ACC] TRAIN 0.6795849480365482 / TEST 0.6765000004768371
epoch: 78
 [LOSS] TRAIN 0.618210529473323 / TEST 0.6098847966194153
 [ACC] TRAIN 0.6532691587864093 / TEST 0.664
epoch: 79
 [LOSS] TRAIN 0.6057727229730802 / TEST 0.6032845454216004
 [ACC] TRAIN 0.6653331665266066 / TEST 0.6670000004768372
epoch: 80
 [LOSS] TRAIN 0.6220305649723645 / TEST 0.6125548133850097
 [ACC] TRAIN 0.6476434553499624 / TEST 0.6595
epoch: 81
 [LOSS] TRAIN 0.5931618651355381 / TEST 0.6010984964370728
 [ACC] TRAIN 0.6837729715469376 / TEST 0.6815000004768371
epoch: 82
 [LOSS] TRAIN 0.5939258615781939 / TEST 0.5962841715812683
 [ACC] TRAIN 0.6847105887341848 / TEST 0.675
epoch: 83
 [LOSS] TRAIN 0.5909565740904967 / TEST 0.5967115898132325
 [ACC] TRAIN 0.6865858231161308 / TEST 0.6810000004768372
Best test accurcy is (0.5930374984741211, 0.688)
Net(
  (model): Sequential(
    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): ReLU(inplace)
    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): ReLU(inplace)
    (6): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))
    (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (10): ReLU(inplace)
    (11): Flatten()
    (12): Linear(in_features=4608, out_features=256, bias=True)
    (13): ReLU(inplace)
    (14): Linear(in_features=256, out_features=2, bias=True)
  )
) 0.05 64
epoch: 1
 [LOSS] TRAIN 0.692180459350925 / TEST 0.6923172998428345
 [ACC] TRAIN 0.5296912114088766 / TEST 0.5275
epoch: 2
 [LOSS] TRAIN 0.6895045738009188 / TEST 0.6903281784057618
 [ACC] TRAIN 0.5530691337534779 / TEST 0.5505
epoch: 3
 [LOSS] TRAIN 0.6847904921919276 / TEST 0.6873848800659179
 [ACC] TRAIN 0.5638204775522434 / TEST 0.5525
epoch: 4
 [LOSS] TRAIN 0.6806833551203941 / TEST 0.6881027493476868
 [ACC] TRAIN 0.5716339542480063 / TEST 0.5435
epoch: 5
 [LOSS] TRAIN 0.6731882514782527 / TEST 0.6794636573791504
 [ACC] TRAIN 0.5833229152973569 / TEST 0.566
epoch: 6
 [LOSS] TRAIN 0.6721243514524637 / TEST 0.6751984057426452
 [ACC] TRAIN 0.5821977747740008 / TEST 0.568
epoch: 7
 [LOSS] TRAIN 0.6698922098226914 / TEST 0.6732666454315186
 [ACC] TRAIN 0.5889486185624191 / TEST 0.5765
epoch: 8
 [LOSS] TRAIN 0.6746840238839421 / TEST 0.6825558009147644
 [ACC] TRAIN 0.5688211025707661 / TEST 0.552
epoch: 9
 [LOSS] TRAIN 0.6699108857708523 / TEST 0.6743746914863586
 [ACC] TRAIN 0.5818227278931407 / TEST 0.573
epoch: 10
 [LOSS] TRAIN 0.6607120064127846 / TEST 0.6652670016288758
 [ACC] TRAIN 0.604075509483389 / TEST 0.589
epoch: 11
 [LOSS] TRAIN 0.6583268222532834 / TEST 0.6622491235733032
 [ACC] TRAIN 0.6047005875063831 / TEST 0.5955
epoch: 12
 [LOSS] TRAIN 0.6556834676054392 / TEST 0.6608539752960205
 [ACC] TRAIN 0.6158894861187096 / TEST 0.609
epoch: 13
 [LOSS] TRAIN 0.6529267469723979 / TEST 0.6568747954368591
 [ACC] TRAIN 0.6138267283261396 / TEST 0.6035
epoch: 14
 [LOSS] TRAIN 0.6518735108576442 / TEST 0.6595710563659668
 [ACC] TRAIN 0.6192024002255224 / TEST 0.613
epoch: 15
 [LOSS] TRAIN 0.653255710662611 / TEST 0.6629050641059876
 [ACC] TRAIN 0.6178272285153231 / TEST 0.6065
epoch: 16
 [LOSS] TRAIN 0.6544307534404659 / TEST 0.6592420296669006
 [ACC] TRAIN 0.6121390174740418 / TEST 0.608
epoch: 17
 [LOSS] TRAIN 0.644264377643353 / TEST 0.6507304744720459
 [ACC] TRAIN 0.624765595751623 / TEST 0.605
epoch: 18
 [LOSS] TRAIN 0.6448782023556129 / TEST 0.6501344304084777
 [ACC] TRAIN 0.6340792599000369 / TEST 0.611
epoch: 19
 [LOSS] TRAIN 0.6390671339880334 / TEST 0.6473381781578064
 [ACC] TRAIN 0.6341417678252863 / TEST 0.623
epoch: 20
 [LOSS] TRAIN 0.6335994297451549 / TEST 0.6430383973121643
 [ACC] TRAIN 0.638454806947726 / TEST 0.6155
epoch: 21
 [LOSS] TRAIN 0.6289387009250833 / TEST 0.6370581274032593
 [ACC] TRAIN 0.652269033547237 / TEST 0.638
epoch: 22
 [LOSS] TRAIN 0.6461817232247129 / TEST 0.653187728881836
 [ACC] TRAIN 0.6193274160238605 / TEST 0.6035
epoch: 23
 [LOSS] TRAIN 0.6358873688559157 / TEST 0.6460244841575623
 [ACC] TRAIN 0.6314539316744041 / TEST 0.608
epoch: 24
 [LOSS] TRAIN 0.6362641077963229 / TEST 0.6439458661079407
 [ACC] TRAIN 0.6287660958588399 / TEST 0.6325
epoch: 25
 [LOSS] TRAIN 0.6310057471224421 / TEST 0.6457398099899292
 [ACC] TRAIN 0.6316414552340583 / TEST 0.613
epoch: 26
 [LOSS] TRAIN 0.6311766856356641 / TEST 0.653051260471344
 [ACC] TRAIN 0.6480810101709749 / TEST 0.6145
epoch: 27
 [LOSS] TRAIN 0.6065782758798849 / TEST 0.6240015263557435
 [ACC] TRAIN 0.6768971121688234 / TEST 0.6635
epoch: 28
 [LOSS] TRAIN 0.5918382481047922 / TEST 0.6166351351737976
 [ACC] TRAIN 0.6859607450707821 / TEST 0.6465
epoch: 29
 [LOSS] TRAIN 0.5844836303749328 / TEST 0.606650464296341
 [ACC] TRAIN 0.6972746593696741 / TEST 0.671
epoch: 30
 [LOSS] TRAIN 0.585018580534232 / TEST 0.6089159884452819
 [ACC] TRAIN 0.6965245655557933 / TEST 0.6695
epoch: 31
 [LOSS] TRAIN 0.5754858639586313 / TEST 0.6047394137382507
 [ACC] TRAIN 0.7039629954116794 / TEST 0.679
epoch: 32
 [LOSS] TRAIN 0.5638775863577715 / TEST 0.5947455105781555
 [ACC] TRAIN 0.7147768471953064 / TEST 0.6875
epoch: 33
 [LOSS] TRAIN 0.5620249587083581 / TEST 0.5954966530799866
 [ACC] TRAIN 0.7120890112232604 / TEST 0.6865
epoch: 34
 [LOSS] TRAIN 0.5851054395239179 / TEST 0.6199721384048462
 [ACC] TRAIN 0.6883360419828961 / TEST 0.6575
epoch: 35
 [LOSS] TRAIN 0.5426288540847064 / TEST 0.5805253291130066
 [ACC] TRAIN 0.7320915114240268 / TEST 0.6985
epoch: 36
 [LOSS] TRAIN 0.530317055555355 / TEST 0.5692287240028381
 [ACC] TRAIN 0.743467933573653 / TEST 0.708
epoch: 37
 [LOSS] TRAIN 0.5318068932266381 / TEST 0.5704717626571655
 [ACC] TRAIN 0.7362170271507456 / TEST 0.713
epoch: 38
 [LOSS] TRAIN 0.5381260022534059 / TEST 0.5755252590179444
 [ACC] TRAIN 0.7249656207472969 / TEST 0.6905
epoch: 39
 [LOSS] TRAIN 0.5180443214139189 / TEST 0.5598878402709961
 [ACC] TRAIN 0.7462807850608797 / TEST 0.715
epoch: 40
 [LOSS] TRAIN 0.4841121506737178 / TEST 0.5328622727394104
 [ACC] TRAIN 0.768096011912082 / TEST 0.7475
epoch: 41
 [LOSS] TRAIN 0.572908985143841 / TEST 0.6190259523391723
 [ACC] TRAIN 0.6797099638348864 / TEST 0.6505
epoch: 42
 [LOSS] TRAIN 0.5726025303776137 / TEST 0.6279484000205994
 [ACC] TRAIN 0.6943367920692063 / TEST 0.6645
epoch: 43
 [LOSS] TRAIN 0.4636560670061847 / TEST 0.528804277420044
 [ACC] TRAIN 0.7812226527421858 / TEST 0.734
epoch: 44
 [LOSS] TRAIN 0.47189538060672465 / TEST 0.5359516654014588
 [ACC] TRAIN 0.7713464182203211 / TEST 0.7315
epoch: 45
 [LOSS] TRAIN 0.39822002430903436 / TEST 0.4672684750556946
 [ACC] TRAIN 0.8294786849026681 / TEST 0.7795
epoch: 46
 [LOSS] TRAIN 0.36541362408772604 / TEST 0.44597818422317503
 [ACC] TRAIN 0.8538567321064144 / TEST 0.806
epoch: 47
 [LOSS] TRAIN 0.333344783842124 / TEST 0.42860938811302185
 [ACC] TRAIN 0.865733216599921 / TEST 0.811
epoch: 48
 [LOSS] TRAIN 0.31108379846499074 / TEST 0.3947100203037262
 [ACC] TRAIN 0.8927365919622365 / TEST 0.8425
epoch: 49
 [LOSS] TRAIN 0.2599169581901254 / TEST 0.3713381063938141
 [ACC] TRAIN 0.9027378423047939 / TEST 0.8435
epoch: 50
 [LOSS] TRAIN 0.37202767824169874 / TEST 0.48530111408233645
 [ACC] TRAIN 0.8144768096235547 / TEST 0.767
epoch: 51
 [LOSS] TRAIN 0.1931397214127654 / TEST 0.33835247421264647
 [ACC] TRAIN 0.9331166394681748 / TEST 0.8615
epoch: 52
 [LOSS] TRAIN 0.13161926929586187 / TEST 0.2846108865737915
 [ACC] TRAIN 0.9631203899965955 / TEST 0.8935
epoch: 53
 [LOSS] TRAIN 0.1674066160858266 / TEST 0.3111970853805542
 [ACC] TRAIN 0.9363670457764139 / TEST 0.877
epoch: 54
 [LOSS] TRAIN 0.20467235067662992 / TEST 0.37388996744155883
 [ACC] TRAIN 0.9091761469736682 / TEST 0.8595
epoch: 55
 [LOSS] TRAIN 0.38721178670438594 / TEST 0.5673324160575867
 [ACC] TRAIN 0.8162895362143785 / TEST 0.7685
epoch: 56
 [LOSS] TRAIN 0.05104430353450379 / TEST 0.2677506275177002
 [ACC] TRAIN 0.9886235779472434 / TEST 0.9215
epoch: 57
 [LOSS] TRAIN 0.12242206788976605 / TEST 0.3645067925453186
 [ACC] TRAIN 0.9558069758794355 / TEST 0.8815
epoch: 58
 [LOSS] TRAIN 0.035213239577609697 / TEST 0.2751615196466446
 [ACC] TRAIN 0.9925615701962746 / TEST 0.9265
epoch: 59
 [LOSS] TRAIN 0.10126152299582057 / TEST 0.3541566746234894
 [ACC] TRAIN 0.9645580698183319 / TEST 0.8925
epoch: 60
 [LOSS] TRAIN 0.06464361990782778 / TEST 0.28181263780593874
 [ACC] TRAIN 0.9836854606825853 / TEST 0.911
epoch: 61
 [LOSS] TRAIN 0.0052093083647796155 / TEST 0.3216999840736389
 [ACC] TRAIN 0.9995624453056632 / TEST 0.934
epoch: 62
 [LOSS] TRAIN 0.001516453331844712 / TEST 0.3532404728531838
 [ACC] TRAIN 1.0 / TEST 0.9285
epoch: 63
 [LOSS] TRAIN 0.0008788557741844276 / TEST 0.3741561403274536
 [ACC] TRAIN 1.0 / TEST 0.9305
epoch: 64
 [LOSS] TRAIN 0.0006165456989471121 / TEST 0.386246979534626
 [ACC] TRAIN 1.0 / TEST 0.9315
epoch: 65
 [LOSS] TRAIN 0.0005008008930514178 / TEST 0.3977580564022064
 [ACC] TRAIN 1.0 / TEST 0.9315
epoch: 66
 [LOSS] TRAIN 0.0004230414215510366 / TEST 0.40789818108081816
 [ACC] TRAIN 1.0 / TEST 0.932
epoch: 67
 [LOSS] TRAIN 0.00036916511178662615 / TEST 0.4151232687830925
 [ACC] TRAIN 1.0 / TEST 0.9325
epoch: 68
 [LOSS] TRAIN 0.000326889442580877 / TEST 0.4217378237247467
 [ACC] TRAIN 1.0 / TEST 0.931
epoch: 69
 [LOSS] TRAIN 0.0002954019160044384 / TEST 0.4261544497013092
 [ACC] TRAIN 1.0 / TEST 0.931
epoch: 70
 [LOSS] TRAIN 0.0002675372252745151 / TEST 0.4319000883102417
 [ACC] TRAIN 1.0 / TEST 0.931
epoch: 71
 [LOSS] TRAIN 0.00024563645644367006 / TEST 0.4370465899705887
 [ACC] TRAIN 1.0 / TEST 0.9315
epoch: 72
 [LOSS] TRAIN 0.0002269491074310433 / TEST 0.4409552586376667
 [ACC] TRAIN 1.0 / TEST 0.9315
epoch: 73
 [LOSS] TRAIN 0.00021076925186698707 / TEST 0.44569999200105664
 [ACC] TRAIN 1.0 / TEST 0.9315
epoch: 74
 [LOSS] TRAIN 0.00019690966304553286 / TEST 0.449171722471714
 [ACC] TRAIN 1.0 / TEST 0.932
epoch: 75
 [LOSS] TRAIN 0.0001851106184819225 / TEST 0.45237109339237214
 [ACC] TRAIN 1.0 / TEST 0.932
epoch: 76
 [LOSS] TRAIN 0.00017403288027611311 / TEST 0.4555207829475403
 [ACC] TRAIN 1.0 / TEST 0.9315
epoch: 77
 [LOSS] TRAIN 0.00016454951227821025 / TEST 0.45870352828502653
 [ACC] TRAIN 1.0 / TEST 0.932
epoch: 78
 [LOSS] TRAIN 0.0001559536715261899 / TEST 0.4613130267858505
 [ACC] TRAIN 1.0 / TEST 0.932
epoch: 79
 [LOSS] TRAIN 0.00014841540154290412 / TEST 0.4636514609456062
 [ACC] TRAIN 1.0 / TEST 0.9315
epoch: 80
 [LOSS] TRAIN 0.0001415263445539351 / TEST 0.46687989675998687
 [ACC] TRAIN 1.0 / TEST 0.932
epoch: 81
 [LOSS] TRAIN 0.00013502121926109955 / TEST 0.46905501538515093
 [ACC] TRAIN 1.0 / TEST 0.932
epoch: 82
 [LOSS] TRAIN 0.00012941889678835114 / TEST 0.47135779812932016
 [ACC] TRAIN 1.0 / TEST 0.932
epoch: 83
 [LOSS] TRAIN 0.0001239486151207043 / TEST 0.4736852118968964
 [ACC] TRAIN 1.0 / TEST 0.932
Best test accurcy is (0.5474242205321789, 0.927)
Net(
  (model): Sequential(
    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): ReLU(inplace)
    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): ReLU(inplace)
    (6): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))
    (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (10): ReLU(inplace)
    (11): Flatten()
    (12): Linear(in_features=4608, out_features=256, bias=True)
    (13): ReLU(inplace)
    (14): Linear(in_features=256, out_features=2, bias=True)
  )
) 0.05 128
epoch: 1
 [LOSS] TRAIN 0.6927989730091002 / TEST 0.692477807044983
 [ACC] TRAIN 0.49824978124873315 / TEST 0.5105000004768372
epoch: 2
 [LOSS] TRAIN 0.6921696393083582 / TEST 0.6925064535140991
 [ACC] TRAIN 0.5035004377856912 / TEST 0.4899999990463257
epoch: 3
 [LOSS] TRAIN 0.6911212328240669 / TEST 0.6913116440773011
 [ACC] TRAIN 0.5461307663234387 / TEST 0.5385
epoch: 4
 [LOSS] TRAIN 0.689285907980531 / TEST 0.6891150732040405
 [ACC] TRAIN 0.5525690710966342 / TEST 0.5674999995231629
epoch: 5
 [LOSS] TRAIN 0.6874991977255052 / TEST 0.6879353051185608
 [ACC] TRAIN 0.546943368151987 / TEST 0.5514999990463256
epoch: 6
 [LOSS] TRAIN 0.6888909032604429 / TEST 0.6916950883865356
 [ACC] TRAIN 0.5073759220126033 / TEST 0.4934999990463257
epoch: 7
 [LOSS] TRAIN 0.6780381486227787 / TEST 0.6800566020011902
 [ACC] TRAIN 0.576259532627843 / TEST 0.58
epoch: 8
 [LOSS] TRAIN 0.678514910326971 / TEST 0.6805675239562988
 [ACC] TRAIN 0.5655081885086625 / TEST 0.5530000004768372
epoch: 9
 [LOSS] TRAIN 0.6768270028518251 / TEST 0.6768262877464294
 [ACC] TRAIN 0.5675709465620353 / TEST 0.5685
epoch: 10
 [LOSS] TRAIN 0.6724732339583362 / TEST 0.6741343836784363
 [ACC] TRAIN 0.5863857984036144 / TEST 0.591
epoch: 11
 [LOSS] TRAIN 0.6676340514472878 / TEST 0.6682826762199402
 [ACC] TRAIN 0.5935116889238626 / TEST 0.6039999995231629
epoch: 12
 [LOSS] TRAIN 0.6682962124489862 / TEST 0.6698507409095764
 [ACC] TRAIN 0.5974496811728937 / TEST 0.6084999995231628
epoch: 13
 [LOSS] TRAIN 0.6680698179948299 / TEST 0.6701451573371887
 [ACC] TRAIN 0.590323790689903 / TEST 0.5855000009536743
epoch: 14
 [LOSS] TRAIN 0.677080029449637 / TEST 0.6826033506393433
 [ACC] TRAIN 0.5765095639115558 / TEST 0.5635000009536744
epoch: 15
 [LOSS] TRAIN 0.6637416315728507 / TEST 0.6656405053138733
 [ACC] TRAIN 0.5997624702640795 / TEST 0.6054999995231628
epoch: 16
 [LOSS] TRAIN 0.6636114811089534 / TEST 0.6622782669067383
 [ACC] TRAIN 0.5969496189109801 / TEST 0.5954999995231628
epoch: 17
 [LOSS] TRAIN 0.6606073302244422 / TEST 0.6611214647293091
 [ACC] TRAIN 0.604388048707254 / TEST 0.6019999990463257
epoch: 18
 [LOSS] TRAIN 0.661451111787378 / TEST 0.6652862715721131
 [ACC] TRAIN 0.6005125640257998 / TEST 0.5954999995231628
epoch: 19
 [LOSS] TRAIN 0.6574618228302402 / TEST 0.6581015996932983
 [ACC] TRAIN 0.6072634078663787 / TEST 0.6034999995231628
epoch: 20
 [LOSS] TRAIN 0.6733557100459358 / TEST 0.6707970809936523
 [ACC] TRAIN 0.5813226655269059 / TEST 0.5835000004768371
epoch: 21
 [LOSS] TRAIN 0.6584344453357998 / TEST 0.6578888964653015
 [ACC] TRAIN 0.6016377046460255 / TEST 0.6115000004768372
epoch: 22
 [LOSS] TRAIN 0.6708036562042962 / TEST 0.675827980518341
 [ACC] TRAIN 0.5913864234668461 / TEST 0.5885000004768371
epoch: 23
 [LOSS] TRAIN 0.6519504158791042 / TEST 0.652069591999054
 [ACC] TRAIN 0.6188273533744684 / TEST 0.6230000004768371
epoch: 24
 [LOSS] TRAIN 0.6512859775612005 / TEST 0.652843502998352
 [ACC] TRAIN 0.6160145019841113 / TEST 0.6085000009536743
epoch: 25
 [LOSS] TRAIN 0.6518571345057096 / TEST 0.6541468238830567
 [ACC] TRAIN 0.6172646579928421 / TEST 0.6219999995231629
epoch: 26
 [LOSS] TRAIN 0.6671573093033147 / TEST 0.6714501924514771
 [ACC] TRAIN 0.5826978371551386 / TEST 0.5929999995231628
epoch: 27
 [LOSS] TRAIN 0.6552803982405502 / TEST 0.6595243973731995
 [ACC] TRAIN 0.6117014628616716 / TEST 0.6045
epoch: 28
 [LOSS] TRAIN 0.6469640415941929 / TEST 0.6499966778755188
 [ACC] TRAIN 0.6240780099226036 / TEST 0.6254999995231628
epoch: 29
 [LOSS] TRAIN 0.646986272293622 / TEST 0.6492112493515014
 [ACC] TRAIN 0.6212651583310559 / TEST 0.6235000004768372
epoch: 30
 [LOSS] TRAIN 0.6483117586553865 / TEST 0.6485571031570434
 [ACC] TRAIN 0.6205775721369124 / TEST 0.6169999990463256
epoch: 31
 [LOSS] TRAIN 0.6599532400970087 / TEST 0.660321150302887
 [ACC] TRAIN 0.5969496186352742 / TEST 0.6005000004768372
epoch: 32
 [LOSS] TRAIN 0.6611018415197222 / TEST 0.6642278985977172
 [ACC] TRAIN 0.5969496186799833 / TEST 0.6029999990463257
epoch: 33
 [LOSS] TRAIN 0.6388465486432421 / TEST 0.6425159001350402
 [ACC] TRAIN 0.6347668457812169 / TEST 0.6339999995231629
epoch: 34
 [LOSS] TRAIN 0.6349780864530182 / TEST 0.6380195751190185
 [ACC] TRAIN 0.6457057131396367 / TEST 0.6430000004768371
epoch: 35
 [LOSS] TRAIN 0.640863793069742 / TEST 0.6436620922088623
 [ACC] TRAIN 0.6235154393703166 / TEST 0.6264999995231628
epoch: 36
 [LOSS] TRAIN 0.6337942072921641 / TEST 0.6345116267204285
 [ACC] TRAIN 0.6399549943295877 / TEST 0.625
epoch: 37
 [LOSS] TRAIN 0.6341549854216568 / TEST 0.6428862605094909
 [ACC] TRAIN 0.6459557444158979 / TEST 0.6410000009536743
epoch: 38
 [LOSS] TRAIN 0.6316650354470263 / TEST 0.6376738634109497
 [ACC] TRAIN 0.6427053381151103 / TEST 0.6404999995231628
epoch: 39
 [LOSS] TRAIN 0.6223274969074007 / TEST 0.6275117473602295
 [ACC] TRAIN 0.6570821352072963 / TEST 0.6585
epoch: 40
 [LOSS] TRAIN 0.6445785440464499 / TEST 0.6470529441833496
 [ACC] TRAIN 0.6162645329995697 / TEST 0.6129999995231629
epoch: 41
 [LOSS] TRAIN 0.6143670923666055 / TEST 0.6183052496910095
 [ACC] TRAIN 0.660770096440869 / TEST 0.6585000004768372
epoch: 42
 [LOSS] TRAIN 0.6229942708868491 / TEST 0.6302846240997314
 [ACC] TRAIN 0.6578947367824932 / TEST 0.6505000004768372
epoch: 43
 [LOSS] TRAIN 0.6208969224153541 / TEST 0.627309850692749
 [ACC] TRAIN 0.6451431430866009 / TEST 0.6475000004768372
epoch: 44
 [LOSS] TRAIN 0.6200763279906749 / TEST 0.629865128993988
 [ACC] TRAIN 0.6562695338556447 / TEST 0.6524999995231628
epoch: 45
 [LOSS] TRAIN 0.6147884645824477 / TEST 0.6279653315544128
 [ACC] TRAIN 0.6610201274414244 / TEST 0.6499999995231629
epoch: 46
 [LOSS] TRAIN 0.6262134542121248 / TEST 0.6374697031974792
 [ACC] TRAIN 0.6395174398364417 / TEST 0.6320000004768371
epoch: 47
 [LOSS] TRAIN 0.6007415589682384 / TEST 0.609227692604065
 [ACC] TRAIN 0.6769596200866212 / TEST 0.6730000004768372
epoch: 48
 [LOSS] TRAIN 0.6441011192023955 / TEST 0.6607885484695435
 [ACC] TRAIN 0.6234529317803853 / TEST 0.6119999990463257
epoch: 49
 [LOSS] TRAIN 0.6290739031415654 / TEST 0.6452082204818725
 [ACC] TRAIN 0.6310163770024219 / TEST 0.6160000009536744
epoch: 50
 [LOSS] TRAIN 0.5807664390727422 / TEST 0.5927533612251282
 [ACC] TRAIN 0.7039629952775521 / TEST 0.6995000004768371
epoch: 51
 [LOSS] TRAIN 0.5720643583484435 / TEST 0.5854910607337952
 [ACC] TRAIN 0.7052131518004372 / TEST 0.7029999995231628
epoch: 52
 [LOSS] TRAIN 0.6042463690478409 / TEST 0.6229668560028077
 [ACC] TRAIN 0.666145768139061 / TEST 0.6510000009536743
epoch: 53
 [LOSS] TRAIN 0.5713424617341942 / TEST 0.5881678733825684
 [ACC] TRAIN 0.707150893735057 / TEST 0.6974999990463256
epoch: 54
 [LOSS] TRAIN 0.5710504695406138 / TEST 0.58945561170578
 [ACC] TRAIN 0.699399925124751 / TEST 0.6854999995231629
epoch: 55
 [LOSS] TRAIN 0.5622052396367618 / TEST 0.5804401693344117
 [ACC] TRAIN 0.7167145892342474 / TEST 0.705
epoch: 56
 [LOSS] TRAIN 0.549454995245766 / TEST 0.5735580954551697
 [ACC] TRAIN 0.7222152768201956 / TEST 0.7070000004768372
epoch: 57
 [LOSS] TRAIN 0.5753125511477747 / TEST 0.5954981660842895
 [ACC] TRAIN 0.6927740966950316 / TEST 0.6784999995231629
epoch: 58
 [LOSS] TRAIN 0.5451129406731581 / TEST 0.5664433431625366
 [ACC] TRAIN 0.7290911365112732 / TEST 0.7129999995231628
epoch: 59
 [LOSS] TRAIN 0.5542649280981714 / TEST 0.5738578929901123
 [ACC] TRAIN 0.7160895110771259 / TEST 0.6989999995231628
epoch: 60
 [LOSS] TRAIN 0.54789938099877 / TEST 0.5725221128463746
 [ACC] TRAIN 0.7211526442071857 / TEST 0.6995000004768371
epoch: 61
 [LOSS] TRAIN 0.5456606219419614 / TEST 0.5739775371551513
 [ACC] TRAIN 0.7220902611783392 / TEST 0.6985000009536744
epoch: 62
 [LOSS] TRAIN 0.5315833255222014 / TEST 0.5658927125930786
 [ACC] TRAIN 0.7350293785531099 / TEST 0.6989999995231628
epoch: 63
 [LOSS] TRAIN 0.5051956638080922 / TEST 0.5403527593612671
 [ACC] TRAIN 0.7578447304870027 / TEST 0.7325000009536743
epoch: 64
 [LOSS] TRAIN 0.5074227376198199 / TEST 0.5376163139343262
 [ACC] TRAIN 0.7584698088304119 / TEST 0.7335
epoch: 65
 [LOSS] TRAIN 0.573830635730349 / TEST 0.6195014944076538
 [ACC] TRAIN 0.6946493313228775 / TEST 0.6734999995231629
epoch: 66
 [LOSS] TRAIN 0.487125717069018 / TEST 0.5236523289680481
 [ACC] TRAIN 0.7764720588881517 / TEST 0.7494999990463257
epoch: 67
 [LOSS] TRAIN 0.5376337484980184 / TEST 0.5686753644943238
 [ACC] TRAIN 0.7239029877617115 / TEST 0.7019999990463257
epoch: 68
 [LOSS] TRAIN 0.5644619970161299 / TEST 0.6122354435920715
 [ACC] TRAIN 0.6912114015742084 / TEST 0.6685000009536743
epoch: 69
 [LOSS] TRAIN 0.458424398222183 / TEST 0.5109661960601807
 [ACC] TRAIN 0.7902237781063738 / TEST 0.7494999990463257
epoch: 70
 [LOSS] TRAIN 0.5930803684774586 / TEST 0.6344234600067139
 [ACC] TRAIN 0.6746468307495356 / TEST 0.6580000004768372
epoch: 71
 [LOSS] TRAIN 0.45633425915564635 / TEST 0.5023843100070954
 [ACC] TRAIN 0.8090386299181468 / TEST 0.7655000009536743
epoch: 72
 [LOSS] TRAIN 0.44887753356500093 / TEST 0.5128798570632934
 [ACC] TRAIN 0.7972246529698626 / TEST 0.7475
epoch: 73
 [LOSS] TRAIN 0.41849873069748755 / TEST 0.48148189330101016
 [ACC] TRAIN 0.8177897235589827 / TEST 0.7724999990463257
epoch: 74
 [LOSS] TRAIN 0.4485472651932713 / TEST 0.5120409433841705
 [ACC] TRAIN 0.7863482933951134 / TEST 0.7560000009536744
epoch: 75
 [LOSS] TRAIN 0.4009809664583665 / TEST 0.4780167505741119
 [ACC] TRAIN 0.8179147394392875 / TEST 0.7729999995231629
epoch: 76
 [LOSS] TRAIN 0.347298637045549 / TEST 0.43378981041908266
 [ACC] TRAIN 0.8641705213747765 / TEST 0.8089999990463257
epoch: 77
 [LOSS] TRAIN 0.3279941057746061 / TEST 0.4201870405673981
 [ACC] TRAIN 0.878547318243417 / TEST 0.821
epoch: 78
 [LOSS] TRAIN 0.29690604751475796 / TEST 0.39541704320907595
 [ACC] TRAIN 0.8960495059870827 / TEST 0.8295000009536743
epoch: 79
 [LOSS] TRAIN 0.32736384877191066 / TEST 0.4399173884391785
 [ACC] TRAIN 0.8562320288471437 / TEST 0.7984999995231629
epoch: 80
 [LOSS] TRAIN 0.38677211748702717 / TEST 0.4711195106506348
 [ACC] TRAIN 0.8310413802544881 / TEST 0.7789999995231628
epoch: 81
 [LOSS] TRAIN 0.23105027775031833 / TEST 0.3621814367771149
 [ACC] TRAIN 0.9203650454369645 / TEST 0.8510000004768371
epoch: 82
 [LOSS] TRAIN 0.24607388748610254 / TEST 0.3753736228942871
 [ACC] TRAIN 0.9102387798698355 / TEST 0.8450000009536743
epoch: 83
 [LOSS] TRAIN 0.1749574247450065 / TEST 0.31751842665672303
 [ACC] TRAIN 0.9539942492886117 / TEST 0.8775
epoch: 84
 [LOSS] TRAIN 0.20738003078714462 / TEST 0.3860710277557373
 [ACC] TRAIN 0.9152394049703247 / TEST 0.8519999995231629
epoch: 85
 [LOSS] TRAIN 0.16928617377730665 / TEST 0.35721663856506347
 [ACC] TRAIN 0.9368046006272325 / TEST 0.8674999995231628
epoch: 86
 [LOSS] TRAIN 0.18850479316809785 / TEST 0.3417288839817047
 [ACC] TRAIN 0.9381172646878884 / TEST 0.866
epoch: 87
 [LOSS] TRAIN 0.12025369494195907 / TEST 0.3134933178424835
 [ACC] TRAIN 0.9641205148482892 / TEST 0.8900000004768371
epoch: 88
 [LOSS] TRAIN 0.212747607082557 / TEST 0.3867061667442322
 [ACC] TRAIN 0.9148643580745617 / TEST 0.8475000009536743
epoch: 89
 [LOSS] TRAIN 0.10229084926599978 / TEST 0.33527844047546385
 [ACC] TRAIN 0.962057757242007 / TEST 0.8929999990463257
epoch: 90
 [LOSS] TRAIN 0.04207154138171832 / TEST 0.3310711114406586
 [ACC] TRAIN 0.9897487183588268 / TEST 0.9105000009536743
epoch: 91
 [LOSS] TRAIN 0.01207259684313959 / TEST 0.3126678929328918
 [ACC] TRAIN 0.9995624450746663 / TEST 0.922
epoch: 92
 [LOSS] TRAIN 0.0067710041239995526 / TEST 0.32799894094467164
 [ACC] TRAIN 0.9996249531191399 / TEST 0.9225
epoch: 93
 [LOSS] TRAIN 0.005214920240072602 / TEST 0.340802344083786
 [ACC] TRAIN 0.9996249531191399 / TEST 0.9215
Best test accurcy is (0.2761487538814545, 0.9394999990463256)
Net(
  (model): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): ReLU(inplace)
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): ReLU(inplace)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
    (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (10): ReLU(inplace)
    (11): Flatten()
    (12): Linear(in_features=2304, out_features=256, bias=True)
    (13): ReLU(inplace)
    (14): Linear(in_features=256, out_features=2, bias=True)
  )
) 0.05 64
epoch: 1
 [LOSS] TRAIN 0.6923561097979769 / TEST 0.6923305783271789
 [ACC] TRAIN 0.5349418676738545 / TEST 0.5385
epoch: 2
 [LOSS] TRAIN 0.6916176893812729 / TEST 0.6927182183265687
 [ACC] TRAIN 0.5050006250259742 / TEST 0.492
epoch: 3
 [LOSS] TRAIN 0.6878356211095144 / TEST 0.6894003019332886
 [ACC] TRAIN 0.5433804225379161 / TEST 0.537
epoch: 4
 [LOSS] TRAIN 0.6848578684731474 / TEST 0.6867532978057861
 [ACC] TRAIN 0.5554444304942071 / TEST 0.552
epoch: 5
 [LOSS] TRAIN 0.6795329137032651 / TEST 0.6798489260673523
 [ACC] TRAIN 0.5733841731259489 / TEST 0.572
epoch: 6
 [LOSS] TRAIN 0.6713822846606994 / TEST 0.6690898022651672
 [ACC] TRAIN 0.587010876359545 / TEST 0.601
epoch: 7
 [LOSS] TRAIN 0.6836250825052873 / TEST 0.6855046582221985
 [ACC] TRAIN 0.54888111025054 / TEST 0.5415
epoch: 8
 [LOSS] TRAIN 0.6698250649332746 / TEST 0.6646656184196472
 [ACC] TRAIN 0.5842605325963769 / TEST 0.5895
epoch: 9
 [LOSS] TRAIN 0.6621489455542247 / TEST 0.6619355554580688
 [ACC] TRAIN 0.6065758219032321 / TEST 0.6185
epoch: 10
 [LOSS] TRAIN 0.659697618376003 / TEST 0.6570294790267944
 [ACC] TRAIN 0.6075759469859227 / TEST 0.6155
epoch: 11
 [LOSS] TRAIN 0.6625948116352803 / TEST 0.6588060531616211
 [ACC] TRAIN 0.599512439159203 / TEST 0.608
epoch: 12
 [LOSS] TRAIN 0.6593134613286884 / TEST 0.660159806728363
 [ACC] TRAIN 0.6035754469085118 / TEST 0.612
epoch: 13
 [LOSS] TRAIN 0.6587121679956041 / TEST 0.6585614352226258
 [ACC] TRAIN 0.6087010877328242 / TEST 0.621
epoch: 14
 [LOSS] TRAIN 0.6527300758769563 / TEST 0.6484457588195801
 [ACC] TRAIN 0.617827228425905 / TEST 0.6335
epoch: 15
 [LOSS] TRAIN 0.6498939354265612 / TEST 0.6486710081100464
 [ACC] TRAIN 0.6222652830858799 / TEST 0.621
epoch: 16
 [LOSS] TRAIN 0.6576697372588415 / TEST 0.6520437736511231
 [ACC] TRAIN 0.6057632204472594 / TEST 0.6195
epoch: 17
 [LOSS] TRAIN 0.6493879751438408 / TEST 0.6496055951118469
 [ACC] TRAIN 0.620452556495056 / TEST 0.618
epoch: 18
 [LOSS] TRAIN 0.6612029381581643 / TEST 0.6618010468482971
 [ACC] TRAIN 0.6044505563120884 / TEST 0.6035
epoch: 19
 [LOSS] TRAIN 0.6413147546810155 / TEST 0.6409010338783264
 [ACC] TRAIN 0.637079635066142 / TEST 0.64
epoch: 20
 [LOSS] TRAIN 0.6470238400676993 / TEST 0.6432289471626281
 [ACC] TRAIN 0.6246405800650575 / TEST 0.6285
epoch: 21
 [LOSS] TRAIN 0.6357397614590659 / TEST 0.6341930818557739
 [ACC] TRAIN 0.6380172521937771 / TEST 0.64
epoch: 22
 [LOSS] TRAIN 0.6437742864657885 / TEST 0.6492841653823852
 [ACC] TRAIN 0.6293286660161967 / TEST 0.629
epoch: 23
 [LOSS] TRAIN 0.651313088807274 / TEST 0.6490652318000794
 [ACC] TRAIN 0.6103262907118332 / TEST 0.6035
epoch: 24
 [LOSS] TRAIN 0.6342756076818229 / TEST 0.6353879194259644
 [ACC] TRAIN 0.6372046506111287 / TEST 0.63
epoch: 25
 [LOSS] TRAIN 0.6579896516316472 / TEST 0.6679092593193054
 [ACC] TRAIN 0.5996374547861564 / TEST 0.59
epoch: 26
 [LOSS] TRAIN 0.6161714038233084 / TEST 0.621307550907135
 [ACC] TRAIN 0.6598324789853673 / TEST 0.655
epoch: 27
 [LOSS] TRAIN 0.6210630467600011 / TEST 0.6314737215042114
 [ACC] TRAIN 0.6553944243402955 / TEST 0.652
epoch: 28
 [LOSS] TRAIN 0.6126024536690663 / TEST 0.6201057906150818
 [ACC] TRAIN 0.670833854276488 / TEST 0.6555
epoch: 29
 [LOSS] TRAIN 0.6017124922532769 / TEST 0.6073019180297852
 [ACC] TRAIN 0.6806475808656518 / TEST 0.682
epoch: 30
 [LOSS] TRAIN 0.5949159309273586 / TEST 0.602038589000702
 [ACC] TRAIN 0.6900237529467667 / TEST 0.685
epoch: 31
 [LOSS] TRAIN 0.5900135129030711 / TEST 0.6029738125801086
 [ACC] TRAIN 0.6833979248300107 / TEST 0.675
epoch: 32
 [LOSS] TRAIN 0.5877863664987132 / TEST 0.5977261009216308
 [ACC] TRAIN 0.6950243779652893 / TEST 0.6815
epoch: 33
 [LOSS] TRAIN 0.5916717695525205 / TEST 0.5972803359031678
 [ACC] TRAIN 0.6858982371902418 / TEST 0.688
epoch: 34
 [LOSS] TRAIN 0.6271389079311517 / TEST 0.6475374293327332
 [ACC] TRAIN 0.6401425177402117 / TEST 0.618
epoch: 35
 [LOSS] TRAIN 0.572410331389087 / TEST 0.5864888906478882
 [ACC] TRAIN 0.7095261907514921 / TEST 0.691
epoch: 36
 [LOSS] TRAIN 0.5997703144633483 / TEST 0.6217752685546875
 [ACC] TRAIN 0.6705213150973319 / TEST 0.6445
epoch: 37
 [LOSS] TRAIN 0.5623449320896877 / TEST 0.5768526210784912
 [ACC] TRAIN 0.7135891986125736 / TEST 0.6955
epoch: 38
 [LOSS] TRAIN 0.5612702265294258 / TEST 0.5783899388313294
 [ACC] TRAIN 0.7111513939465951 / TEST 0.7015
epoch: 39
 [LOSS] TRAIN 0.5640149638494532 / TEST 0.5812919170856475
 [ACC] TRAIN 0.708901112728498 / TEST 0.6995
epoch: 40
 [LOSS] TRAIN 0.5576657658667099 / TEST 0.5749171137809753
 [ACC] TRAIN 0.7107138391404856 / TEST 0.69
epoch: 41
 [LOSS] TRAIN 0.5336599442821426 / TEST 0.5507895245552062
 [ACC] TRAIN 0.7373421676890047 / TEST 0.7225
epoch: 42
 [LOSS] TRAIN 0.5557127697257075 / TEST 0.5823576049804687
 [ACC] TRAIN 0.7108388547748905 / TEST 0.6885
epoch: 43
 [LOSS] TRAIN 0.5183104558249745 / TEST 0.5471398820877075
 [ACC] TRAIN 0.7554069258880878 / TEST 0.7305
epoch: 44
 [LOSS] TRAIN 0.5447230017517548 / TEST 0.5849162650108337
 [ACC] TRAIN 0.7188398550116788 / TEST 0.6915
epoch: 45
 [LOSS] TRAIN 0.5718112630998512 / TEST 0.6068496263027191
 [ACC] TRAIN 0.6907738466414232 / TEST 0.6685
epoch: 46
 [LOSS] TRAIN 0.4891930401608383 / TEST 0.5273548774719238
 [ACC] TRAIN 0.767345918269586 / TEST 0.7465
epoch: 47
 [LOSS] TRAIN 0.4894953575979577 / TEST 0.5365971746444702
 [ACC] TRAIN 0.7677834728521501 / TEST 0.7445
epoch: 48
 [LOSS] TRAIN 0.46527984209665135 / TEST 0.5093769392967225
 [ACC] TRAIN 0.7834729341465706 / TEST 0.757
epoch: 49
 [LOSS] TRAIN 0.4453320785200079 / TEST 0.5030440154075623
 [ACC] TRAIN 0.7949118639531918 / TEST 0.7535
epoch: 50
 [LOSS] TRAIN 0.4529900666638782 / TEST 0.5096732721328735
 [ACC] TRAIN 0.786973371701265 / TEST 0.7465
epoch: 51
 [LOSS] TRAIN 0.46634709899135496 / TEST 0.5161328721046448
 [ACC] TRAIN 0.773659207311507 / TEST 0.753
epoch: 52
 [LOSS] TRAIN 0.38490192331899953 / TEST 0.4641771768331528
 [ACC] TRAIN 0.8349793724364557 / TEST 0.7935
epoch: 53
 [LOSS] TRAIN 0.428439746459345 / TEST 0.49262032413482665
 [ACC] TRAIN 0.7950993874532339 / TEST 0.7655
epoch: 54
 [LOSS] TRAIN 0.44904955338948904 / TEST 0.5419773035049439
 [ACC] TRAIN 0.779784973032222 / TEST 0.738
epoch: 55
 [LOSS] TRAIN 0.29948678786329275 / TEST 0.3956509847640991
 [ACC] TRAIN 0.8846105763965554 / TEST 0.838
epoch: 56
 [LOSS] TRAIN 0.2781329070654403 / TEST 0.3857865264415741
 [ACC] TRAIN 0.9006125766391351 / TEST 0.843
epoch: 57
 [LOSS] TRAIN 0.22671908502512267 / TEST 0.36087254095077514
 [ACC] TRAIN 0.9211151394594876 / TEST 0.8555
epoch: 58
 [LOSS] TRAIN 0.29718010884990603 / TEST 0.420410210609436
 [ACC] TRAIN 0.873359169851528 / TEST 0.821
epoch: 59
 [LOSS] TRAIN 0.17960345700750174 / TEST 0.3212980136871338
 [ACC] TRAIN 0.9424303038550371 / TEST 0.8715
epoch: 60
 [LOSS] TRAIN 0.5225624954913584 / TEST 0.6388554430007934
 [ACC] TRAIN 0.7509688710865341 / TEST 0.7195
epoch: 61
 [LOSS] TRAIN 0.4231157185904964 / TEST 0.6274087233543396
 [ACC] TRAIN 0.8029128640782075 / TEST 0.7475
epoch: 62
 [LOSS] TRAIN 0.11323505607336398 / TEST 0.326994987487793
 [ACC] TRAIN 0.9628703588544615 / TEST 0.8895
epoch: 63
 [LOSS] TRAIN 0.11712172416757533 / TEST 0.32202142289280894
 [ACC] TRAIN 0.9603700462036214 / TEST 0.8905
epoch: 64
 [LOSS] TRAIN 0.10129172900853001 / TEST 0.3096002919077873
 [ACC] TRAIN 0.9648706087739427 / TEST 0.9025
epoch: 65
 [LOSS] TRAIN 0.08616801861923686 / TEST 0.32374796843528747
 [ACC] TRAIN 0.9706838354794349 / TEST 0.901
epoch: 66
 [LOSS] TRAIN 0.06795556950675709 / TEST 0.306878408074379
 [ACC] TRAIN 0.9804975620835017 / TEST 0.9095
epoch: 67
 [LOSS] TRAIN 0.33451194989486016 / TEST 0.44758559346199034
 [ACC] TRAIN 0.8686710838407766 / TEST 0.814
epoch: 68
 [LOSS] TRAIN 0.12117866371844557 / TEST 0.3563520486354828
 [ACC] TRAIN 0.9569321164624037 / TEST 0.8835
epoch: 69
 [LOSS] TRAIN 0.052010607666888226 / TEST 0.33419454330205917
 [ACC] TRAIN 0.9836854606825853 / TEST 0.9115
epoch: 70
 [LOSS] TRAIN 1.463193345448422 / TEST 1.752430718421936
 [ACC] TRAIN 0.6442680334296729 / TEST 0.617
epoch: 71
 [LOSS] TRAIN 0.02951671484802377 / TEST 0.38356587672233583
 [ACC] TRAIN 0.9914364295536943 / TEST 0.916
epoch: 72
 [LOSS] TRAIN 0.06955048133906595 / TEST 0.3791797499656677
 [ACC] TRAIN 0.9734341793320211 / TEST 0.898
epoch: 73
 [LOSS] TRAIN 0.054846025164134206 / TEST 0.3973661000728607
 [ACC] TRAIN 0.9805600699565905 / TEST 0.903
epoch: 74
 [LOSS] TRAIN 0.10030394898740809 / TEST 0.3540916749238968
 [ACC] TRAIN 0.9638079760640632 / TEST 0.8965
epoch: 75
 [LOSS] TRAIN 0.033608765445313375 / TEST 0.3667590911388397
 [ACC] TRAIN 0.9881860232529066 / TEST 0.923
epoch: 76
 [LOSS] TRAIN 0.04454023005020054 / TEST 0.41027557849884033
 [ACC] TRAIN 0.9846855855864396 / TEST 0.914
epoch: 77
 [LOSS] TRAIN 0.032812268740647375 / TEST 0.37025018191337583
 [ACC] TRAIN 0.9893736717685757 / TEST 0.918
epoch: 78
 [LOSS] TRAIN 0.05824860543150472 / TEST 0.4008789651989937
 [ACC] TRAIN 0.9778097261040043 / TEST 0.904
epoch: 79
 [LOSS] TRAIN 0.07915308316516376 / TEST 0.49353700518608096
 [ACC] TRAIN 0.9701212651581448 / TEST 0.894
epoch: 80
 [LOSS] TRAIN 0.03842826353080765 / TEST 0.3933956917524338
 [ACC] TRAIN 0.9864358045351715 / TEST 0.9135
epoch: 81
 [LOSS] TRAIN 0.5577107896088273 / TEST 0.9201475625038147
 [ACC] TRAIN 0.8309788723813994 / TEST 0.786
epoch: 82
 [LOSS] TRAIN 0.02034031881293316 / TEST 0.40486907225847246
 [ACC] TRAIN 0.9928741092636579 / TEST 0.917
Best test accurcy is (0.39867392778396604, 0.9225)
Net(
  (model): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): ReLU(inplace)
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): ReLU(inplace)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
    (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (10): ReLU(inplace)
    (11): Flatten()
    (12): Linear(in_features=2304, out_features=256, bias=True)
    (13): ReLU(inplace)
    (14): Linear(in_features=256, out_features=2, bias=True)
  )
) 0.05 128
epoch: 1
 [LOSS] TRAIN 0.6928577136883126 / TEST 0.6927233972549438
 [ACC] TRAIN 0.5018127265386633 / TEST 0.5084999995231628
epoch: 2
 [LOSS] TRAIN 0.692473980505357 / TEST 0.6924974975585938
 [ACC] TRAIN 0.5230653831840739 / TEST 0.5299999995231628
epoch: 3
 [LOSS] TRAIN 0.6920679349245944 / TEST 0.6923056321144104
 [ACC] TRAIN 0.5431303913324441 / TEST 0.5299999990463257
epoch: 4
 [LOSS] TRAIN 0.691529391333228 / TEST 0.6915221729278564
 [ACC] TRAIN 0.5324415551869478 / TEST 0.5374999990463257
epoch: 5
 [LOSS] TRAIN 0.6899295282864634 / TEST 0.6902414255142212
 [ACC] TRAIN 0.5520690088123661 / TEST 0.5420000004768372
epoch: 6
 [LOSS] TRAIN 0.689273582546245 / TEST 0.6904578714370727
 [ACC] TRAIN 0.5208776097086641 / TEST 0.5110000004768371
epoch: 7
 [LOSS] TRAIN 0.686185240738093 / TEST 0.6876025500297547
 [ACC] TRAIN 0.5437554696274185 / TEST 0.5250000004768371
epoch: 8
 [LOSS] TRAIN 0.680312928378187 / TEST 0.6825786390304566
 [ACC] TRAIN 0.5683210403386586 / TEST 0.5645000009536744
epoch: 9
 [LOSS] TRAIN 0.6757198951366261 / TEST 0.6783255772590637
 [ACC] TRAIN 0.5776972123229037 / TEST 0.5684999995231629
epoch: 10
 [LOSS] TRAIN 0.6741252169264512 / TEST 0.6764193229675293
 [ACC] TRAIN 0.581822728042171 / TEST 0.5764999997615814
epoch: 11
 [LOSS] TRAIN 0.6714545599981194 / TEST 0.674142882347107
 [ACC] TRAIN 0.5838229780734249 / TEST 0.5770000004768372
epoch: 12
 [LOSS] TRAIN 0.669052454304257 / TEST 0.6714699606895447
 [ACC] TRAIN 0.5898862359657603 / TEST 0.5825000009536743
epoch: 13
 [LOSS] TRAIN 0.6722911751066123 / TEST 0.6747712659835815
 [ACC] TRAIN 0.5863232906273953 / TEST 0.5944999990463257
epoch: 14
 [LOSS] TRAIN 0.6807615462579285 / TEST 0.6817703976631164
 [ACC] TRAIN 0.5669458682037232 / TEST 0.5675000004768371
epoch: 15
 [LOSS] TRAIN 0.6688173573260636 / TEST 0.6714788799285889
 [ACC] TRAIN 0.5906363295039351 / TEST 0.6005000004768372
epoch: 16
 [LOSS] TRAIN 0.66628290778593 / TEST 0.6685141592025757
 [ACC] TRAIN 0.5902612826715098 / TEST 0.5915000009536743
epoch: 17
 [LOSS] TRAIN 0.6769450684162449 / TEST 0.6776919255256653
 [ACC] TRAIN 0.5675709465769384 / TEST 0.565
epoch: 18
 [LOSS] TRAIN 0.6669253401867166 / TEST 0.6700676674842835
 [ACC] TRAIN 0.5940742592526043 / TEST 0.6054999995231628
epoch: 19
 [LOSS] TRAIN 0.675483454263334 / TEST 0.675231442451477
 [ACC] TRAIN 0.5730091260662524 / TEST 0.57
epoch: 20
 [LOSS] TRAIN 0.6630376719552169 / TEST 0.6654048738479614
 [ACC] TRAIN 0.6005750720628218 / TEST 0.6115000004768372
epoch: 21
 [LOSS] TRAIN 0.6619921629019626 / TEST 0.6622669992446899
 [ACC] TRAIN 0.5982622827629936 / TEST 0.5894999990463257
epoch: 22
 [LOSS] TRAIN 0.6579546530271474 / TEST 0.6589907498359681
 [ACC] TRAIN 0.6065133143729129 / TEST 0.6024999995231628
epoch: 23
 [LOSS] TRAIN 0.6582941028502214 / TEST 0.6616166219711304
 [ACC] TRAIN 0.6110763847641624 / TEST 0.6140000004768371
epoch: 24
 [LOSS] TRAIN 0.6703132145523145 / TEST 0.6701101903915405
 [ACC] TRAIN 0.5822602824757048 / TEST 0.5755000009536743
epoch: 25
 [LOSS] TRAIN 0.6583229854175755 / TEST 0.6592082452774047
 [ACC] TRAIN 0.609263657890181 / TEST 0.6119999995231629
epoch: 26
 [LOSS] TRAIN 0.661342524710201 / TEST 0.6639019608497619
 [ACC] TRAIN 0.6017002127203052 / TEST 0.6060000004768371
epoch: 27
 [LOSS] TRAIN 0.6511347786845796 / TEST 0.6530040001869202
 [ACC] TRAIN 0.6164520564698058 / TEST 0.6159999990463256
epoch: 28
 [LOSS] TRAIN 0.6542723524017563 / TEST 0.6569810662269592
 [ACC] TRAIN 0.6142642832067642 / TEST 0.6169999990463256
epoch: 29
 [LOSS] TRAIN 0.6563137450103745 / TEST 0.6564467916488648
 [ACC] TRAIN 0.6077009625607155 / TEST 0.6035000009536743
epoch: 30
 [LOSS] TRAIN 0.6548125331573806 / TEST 0.6561776227951049
 [ACC] TRAIN 0.610451306592138 / TEST 0.6235000004768372
epoch: 31
 [LOSS] TRAIN 0.6492747887624385 / TEST 0.6490875277519226
 [ACC] TRAIN 0.6220777598913497 / TEST 0.6295000009536743
epoch: 32
 [LOSS] TRAIN 0.6498198677918541 / TEST 0.6493675699234008
 [ACC] TRAIN 0.6194524315017836 / TEST 0.6260000009536744
epoch: 33
 [LOSS] TRAIN 0.648450939547108 / TEST 0.6484632968902588
 [ACC] TRAIN 0.6207650955773425 / TEST 0.6215000009536743
epoch: 34
 [LOSS] TRAIN 0.6564904899131597 / TEST 0.6589931082725525
 [ACC] TRAIN 0.607200900052902 / TEST 0.6125
epoch: 35
 [LOSS] TRAIN 0.6468047167095695 / TEST 0.6484971990585328
 [ACC] TRAIN 0.624328040908256 / TEST 0.6334999995231628
epoch: 36
 [LOSS] TRAIN 0.6442327205278469 / TEST 0.6479849152565003
 [ACC] TRAIN 0.6292661581952687 / TEST 0.6334999995231628
epoch: 37
 [LOSS] TRAIN 0.6507398727640895 / TEST 0.6498125944137573
 [ACC] TRAIN 0.6161395173726163 / TEST 0.6140000004768371
epoch: 38
 [LOSS] TRAIN 0.6372441557261747 / TEST 0.6387149600982666
 [ACC] TRAIN 0.6405175648446172 / TEST 0.6515000004768372
epoch: 39
 [LOSS] TRAIN 0.648742756637607 / TEST 0.6498701877593994
 [ACC] TRAIN 0.6127640954225209 / TEST 0.6094999995231628
epoch: 40
 [LOSS] TRAIN 0.648739224516581 / TEST 0.6530036277770996
 [ACC] TRAIN 0.6188273535756591 / TEST 0.619
epoch: 41
 [LOSS] TRAIN 0.6410182782494586 / TEST 0.6411894955635071
 [ACC] TRAIN 0.628391048806595 / TEST 0.6234999990463257
epoch: 42
 [LOSS] TRAIN 0.6303576397544102 / TEST 0.6333234095573426
 [ACC] TRAIN 0.6485185649770844 / TEST 0.6545000004768372
epoch: 43
 [LOSS] TRAIN 0.6524402062763853 / TEST 0.653995599269867
 [ACC] TRAIN 0.6088886112701238 / TEST 0.6035
epoch: 44
 [LOSS] TRAIN 0.6421972886370575 / TEST 0.6422010660171509
 [ACC] TRAIN 0.6259532441592452 / TEST 0.6279999995231629
epoch: 45
 [LOSS] TRAIN 0.6198369057897717 / TEST 0.6218017168045044
 [ACC] TRAIN 0.662895361845725 / TEST 0.6665
epoch: 46
 [LOSS] TRAIN 0.6395153663488966 / TEST 0.6409626822471619
 [ACC] TRAIN 0.6237654708403172 / TEST 0.6155000004768372
epoch: 47
 [LOSS] TRAIN 0.6161825968215042 / TEST 0.6161197061538697
 [ACC] TRAIN 0.6569571195803429 / TEST 0.6604999995231629
epoch: 48
 [LOSS] TRAIN 0.6163827379370708 / TEST 0.6195821690559388
 [ACC] TRAIN 0.6603950495749119 / TEST 0.6524999990463257
epoch: 49
 [LOSS] TRAIN 0.6196680669338052 / TEST 0.6249920377731323
 [ACC] TRAIN 0.6577697211033792 / TEST 0.6630000009536743
epoch: 50
 [LOSS] TRAIN 0.6063058006493713 / TEST 0.6097367353439331
 [ACC] TRAIN 0.6725840729420626 / TEST 0.6709999990463257
epoch: 51
 [LOSS] TRAIN 0.668508270305758 / TEST 0.6674327721595764
 [ACC] TRAIN 0.6035129392738714 / TEST 0.5965000004768372
epoch: 52
 [LOSS] TRAIN 0.6171597287064419 / TEST 0.617388897895813
 [ACC] TRAIN 0.6542067757948203 / TEST 0.6595000004768372
epoch: 53
 [LOSS] TRAIN 0.6507484713246307 / TEST 0.6495630316734314
 [ACC] TRAIN 0.6196399549720197 / TEST 0.6164999990463257
epoch: 54
 [LOSS] TRAIN 0.5963919139948617 / TEST 0.5995304040908813
 [ACC] TRAIN 0.681710213687304 / TEST 0.6805000009536744
epoch: 55
 [LOSS] TRAIN 0.5937507519171765 / TEST 0.597038161277771
 [ACC] TRAIN 0.6851481434285216 / TEST 0.688
epoch: 56
 [LOSS] TRAIN 0.6330085039988266 / TEST 0.6400765771865845
 [ACC] TRAIN 0.6416427054871975 / TEST 0.6425
epoch: 57
 [LOSS] TRAIN 0.5911999521650125 / TEST 0.5924191193580628
 [ACC] TRAIN 0.6878359796464674 / TEST 0.6929999995231628
epoch: 58
 [LOSS] TRAIN 0.5907759251617196 / TEST 0.5973095526695251
 [ACC] TRAIN 0.6868983622282233 / TEST 0.6955
epoch: 59
 [LOSS] TRAIN 0.5817517422932299 / TEST 0.5873780212402344
 [ACC] TRAIN 0.6967745967351849 / TEST 0.6964999990463256
epoch: 60
 [LOSS] TRAIN 0.5870014009423249 / TEST 0.5882239985466003
 [ACC] TRAIN 0.6873984247285853 / TEST 0.6955000009536744
epoch: 61
 [LOSS] TRAIN 0.5920423617630038 / TEST 0.5952634282112121
 [ACC] TRAIN 0.6852106512196438 / TEST 0.6915000009536744
epoch: 62
 [LOSS] TRAIN 0.5723212161709746 / TEST 0.5741719589233398
 [ACC] TRAIN 0.7062132765403583 / TEST 0.7130000009536743
epoch: 63
 [LOSS] TRAIN 0.5738786028271721 / TEST 0.5788878564834594
 [ACC] TRAIN 0.6992749095201523 / TEST 0.7075000004768371
epoch: 64
 [LOSS] TRAIN 0.5921389210043825 / TEST 0.590660828590393
 [ACC] TRAIN 0.6832729092850239 / TEST 0.6890000009536743
epoch: 65
 [LOSS] TRAIN 0.5797631011812191 / TEST 0.5814120569229126
 [ACC] TRAIN 0.6913364169552618 / TEST 0.7010000009536743
epoch: 66
 [LOSS] TRAIN 0.559052955554357 / TEST 0.5649461002349854
 [ACC] TRAIN 0.7174021751750393 / TEST 0.7164999995231628
epoch: 67
 [LOSS] TRAIN 0.5764052129071986 / TEST 0.5824187128543854
 [ACC] TRAIN 0.6926490810233692 / TEST 0.6964999990463256
epoch: 68
 [LOSS] TRAIN 0.5657910375926536 / TEST 0.5711045503616333
 [ACC] TRAIN 0.7050256283525557 / TEST 0.7050000009536743
epoch: 69
 [LOSS] TRAIN 0.5705662391337474 / TEST 0.5791696457862854
 [ACC] TRAIN 0.7010251282751448 / TEST 0.6935000004768371
epoch: 70
 [LOSS] TRAIN 0.6393104011989531 / TEST 0.6405958242416382
 [ACC] TRAIN 0.6385798226790006 / TEST 0.6320000004768371
epoch: 71
 [LOSS] TRAIN 0.5702208929068447 / TEST 0.5734188380241394
 [ACC] TRAIN 0.6979622454147874 / TEST 0.7065000009536743
epoch: 72
 [LOSS] TRAIN 0.5400236502060638 / TEST 0.5501687073707581
 [ACC] TRAIN 0.7309038628561971 / TEST 0.7244999995231628
epoch: 73
 [LOSS] TRAIN 0.5389381518869463 / TEST 0.5504538278579711
 [ACC] TRAIN 0.7272784099353524 / TEST 0.7204999990463257
epoch: 74
 [LOSS] TRAIN 0.531493671511334 / TEST 0.5438861289024353
 [ACC] TRAIN 0.7344668084628165 / TEST 0.7264999995231628
epoch: 75
 [LOSS] TRAIN 0.5272333920709877 / TEST 0.539962115764618
 [ACC] TRAIN 0.7386548319657544 / TEST 0.7334999990463257
epoch: 76
 [LOSS] TRAIN 0.553863042152618 / TEST 0.5762861790657043
 [ACC] TRAIN 0.7168396048313946 / TEST 0.7115000009536743
epoch: 77
 [LOSS] TRAIN 0.5204187573783322 / TEST 0.533280421257019
 [ACC] TRAIN 0.7440930115295836 / TEST 0.7329999995231629
epoch: 78
 [LOSS] TRAIN 0.5105107908979746 / TEST 0.5270601134300232
 [ACC] TRAIN 0.7532816603342016 / TEST 0.7445000009536743
epoch: 79
 [LOSS] TRAIN 0.5203554960530554 / TEST 0.5406727623939515
 [ACC] TRAIN 0.7479059881293069 / TEST 0.7320000004768371
epoch: 80
 [LOSS] TRAIN 0.5397610347454869 / TEST 0.5601078317165374
 [ACC] TRAIN 0.7224028004767195 / TEST 0.712
epoch: 81
 [LOSS] TRAIN 0.4961076084934692 / TEST 0.5184387693405151
 [ACC] TRAIN 0.7670958870901944 / TEST 0.7529999995231629
epoch: 82
 [LOSS] TRAIN 0.48924427879186017 / TEST 0.5094941430091858
 [ACC] TRAIN 0.7640330040211946 / TEST 0.7554999990463257
epoch: 83
 [LOSS] TRAIN 0.5549023053857413 / TEST 0.5827502446174622
 [ACC] TRAIN 0.7014001749473626 / TEST 0.6915000009536744
epoch: 84
 [LOSS] TRAIN 0.5094600155183949 / TEST 0.5372776098251343
 [ACC] TRAIN 0.7460932615161285 / TEST 0.7360000004768371
epoch: 85
 [LOSS] TRAIN 0.47671436841360615 / TEST 0.5078007757663727
 [ACC] TRAIN 0.7881610199859372 / TEST 0.7645000004768372
epoch: 86
 [LOSS] TRAIN 0.49455294471291367 / TEST 0.5310985994338989
 [ACC] TRAIN 0.7520315040646679 / TEST 0.7265000009536743
epoch: 87
 [LOSS] TRAIN 0.43638418302087134 / TEST 0.4739433057308197
 [ACC] TRAIN 0.8038504814144849 / TEST 0.7804999995231628
epoch: 88
 [LOSS] TRAIN 0.4759365771096682 / TEST 0.5072857148647308
 [ACC] TRAIN 0.7665958243588356 / TEST 0.7474999990463257
epoch: 89
 [LOSS] TRAIN 0.41891434168365543 / TEST 0.46461340618133545
 [ACC] TRAIN 0.815039379758557 / TEST 0.7844999995231628
epoch: 90
 [LOSS] TRAIN 0.4252246376618339 / TEST 0.4722896008491516
 [ACC] TRAIN 0.8074759343576843 / TEST 0.7775
Best test accurcy is (0.4929198567867279, 0.761)
Net(
  (model): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): ReLU(inplace)
    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): ReLU(inplace)
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))
    (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (10): ReLU(inplace)
    (11): Flatten()
    (12): Linear(in_features=1152, out_features=256, bias=True)
    (13): ReLU(inplace)
    (14): Linear(in_features=256, out_features=2, bias=True)
  )
) 0.05 64
epoch: 1
 [LOSS] TRAIN 0.6926035092597992 / TEST 0.6926141357421876
 [ACC] TRAIN 0.5364420553686798 / TEST 0.5345
epoch: 2
 [LOSS] TRAIN 0.6922355091471958 / TEST 0.6932818241119385
 [ACC] TRAIN 0.5012501562732594 / TEST 0.485
epoch: 3
 [LOSS] TRAIN 0.6906824136453951 / TEST 0.69094016456604
 [ACC] TRAIN 0.5415676959470922 / TEST 0.5395
epoch: 4
 [LOSS] TRAIN 0.688463460633063 / TEST 0.6902840905189515
 [ACC] TRAIN 0.54519314912874 / TEST 0.5485
epoch: 5
 [LOSS] TRAIN 0.6852995564914045 / TEST 0.6867567415237427
 [ACC] TRAIN 0.5590073760337629 / TEST 0.5665
epoch: 6
 [LOSS] TRAIN 0.6804309969083088 / TEST 0.682439453125
 [ACC] TRAIN 0.5773846731213931 / TEST 0.5775
epoch: 7
 [LOSS] TRAIN 0.6756194747154497 / TEST 0.6787460918426513
 [ACC] TRAIN 0.5747593449628239 / TEST 0.5705
epoch: 8
 [LOSS] TRAIN 0.6917634920517136 / TEST 0.6988385152816773
 [ACC] TRAIN 0.5355044380398538 / TEST 0.521
epoch: 9
 [LOSS] TRAIN 0.6790085722243939 / TEST 0.6864025688171387
 [ACC] TRAIN 0.5714464309156232 / TEST 0.554
epoch: 10
 [LOSS] TRAIN 0.6629912271948513 / TEST 0.6649568791389465
 [ACC] TRAIN 0.5955119391041467 / TEST 0.5935
epoch: 11
 [LOSS] TRAIN 0.662440794328553 / TEST 0.6655679569244385
 [ACC] TRAIN 0.6020127516461098 / TEST 0.601
epoch: 12
 [LOSS] TRAIN 0.6821284431310755 / TEST 0.6779554224014283
 [ACC] TRAIN 0.5621952745061708 / TEST 0.562
epoch: 13
 [LOSS] TRAIN 0.6569901356579051 / TEST 0.6582819719314575
 [ACC] TRAIN 0.6059507438429804 / TEST 0.6025
epoch: 14
 [LOSS] TRAIN 0.6564128502620311 / TEST 0.6589913020133972
 [ACC] TRAIN 0.6108263533314193 / TEST 0.6025
epoch: 15
 [LOSS] TRAIN 0.6587527275592152 / TEST 0.6632676033973693
 [ACC] TRAIN 0.6099512440023579 / TEST 0.608
epoch: 16
 [LOSS] TRAIN 0.6546459666400093 / TEST 0.6567738804817199
 [ACC] TRAIN 0.6124515564892646 / TEST 0.603
epoch: 17
 [LOSS] TRAIN 0.6562245020957005 / TEST 0.6580878806114197
 [ACC] TRAIN 0.6052006501855813 / TEST 0.5985
epoch: 18
 [LOSS] TRAIN 0.6503831160964184 / TEST 0.6523179812431336
 [ACC] TRAIN 0.6174521815003358 / TEST 0.6125
epoch: 19
 [LOSS] TRAIN 0.6553152612424341 / TEST 0.6637790923118592
 [ACC] TRAIN 0.6161395173651648 / TEST 0.6045
epoch: 20
 [LOSS] TRAIN 0.6532359426282975 / TEST 0.6540614957809449
 [ACC] TRAIN 0.621952744025948 / TEST 0.614
epoch: 21
 [LOSS] TRAIN 0.6536938948457816 / TEST 0.6602289142608643
 [ACC] TRAIN 0.6097637205768308 / TEST 0.608
epoch: 22
 [LOSS] TRAIN 0.6794126763211472 / TEST 0.6911258964538575
 [ACC] TRAIN 0.5629453681039578 / TEST 0.5455
epoch: 23
 [LOSS] TRAIN 0.6453622556623928 / TEST 0.653099889755249
 [ACC] TRAIN 0.6263907988796623 / TEST 0.612
epoch: 24
 [LOSS] TRAIN 0.6632801090080838 / TEST 0.673413471698761
 [ACC] TRAIN 0.5956994625147707 / TEST 0.59
epoch: 25
 [LOSS] TRAIN 0.6756933354812795 / TEST 0.6824237856864929
 [ACC] TRAIN 0.5935741967596938 / TEST 0.597
epoch: 26
 [LOSS] TRAIN 0.6393305676581637 / TEST 0.6419500231742858
 [ACC] TRAIN 0.6320790098613315 / TEST 0.6245
epoch: 27
 [LOSS] TRAIN 0.6390177645688058 / TEST 0.6465116553306579
 [ACC] TRAIN 0.6333291660638016 / TEST 0.6305
epoch: 28
 [LOSS] TRAIN 0.6469947913390783 / TEST 0.6567913842201233
 [ACC] TRAIN 0.6202650331663987 / TEST 0.617
epoch: 29
 [LOSS] TRAIN 0.6312835164957753 / TEST 0.6366537518501282
 [ACC] TRAIN 0.6521440179277351 / TEST 0.6485
epoch: 30
 [LOSS] TRAIN 0.6450922507347949 / TEST 0.6471309361457824
 [ACC] TRAIN 0.6253281661176222 / TEST 0.6145
epoch: 31
 [LOSS] TRAIN 0.6269691652738388 / TEST 0.6363900108337402
 [ACC] TRAIN 0.6558319789675686 / TEST 0.659
epoch: 32
 [LOSS] TRAIN 0.6241719631690326 / TEST 0.6327911744117737
 [ACC] TRAIN 0.6537067133168128 / TEST 0.65
epoch: 33
 [LOSS] TRAIN 0.6748379702895324 / TEST 0.687283459186554
 [ACC] TRAIN 0.5740717588953561 / TEST 0.5715
epoch: 34
 [LOSS] TRAIN 0.6200261477724226 / TEST 0.6276686649322509
 [ACC] TRAIN 0.6565195649307152 / TEST 0.637
epoch: 35
 [LOSS] TRAIN 0.6036927304367435 / TEST 0.612861310005188
 [ACC] TRAIN 0.6747093385928183 / TEST 0.6675
epoch: 36
 [LOSS] TRAIN 0.6171740800578202 / TEST 0.6229487652778626
 [ACC] TRAIN 0.653769221093032 / TEST 0.6395
epoch: 37
 [LOSS] TRAIN 0.6060970730819707 / TEST 0.6136983675956726
 [ACC] TRAIN 0.6727090885541129 / TEST 0.661
epoch: 38
 [LOSS] TRAIN 0.5967347040923331 / TEST 0.6055800094604492
 [ACC] TRAIN 0.6814601824855578 / TEST 0.6765
epoch: 39
 [LOSS] TRAIN 0.5997842747817294 / TEST 0.6032080049514771
 [ACC] TRAIN 0.6726465807927968 / TEST 0.6555
epoch: 40
 [LOSS] TRAIN 0.5846684263682184 / TEST 0.5926953482627869
 [ACC] TRAIN 0.6908988624025038 / TEST 0.676
epoch: 41
 [LOSS] TRAIN 0.6170509304496881 / TEST 0.6216377272605896
 [ACC] TRAIN 0.6585823227083821 / TEST 0.648
epoch: 42
 [LOSS] TRAIN 0.5899644920581251 / TEST 0.5964471483230591
 [ACC] TRAIN 0.6893361670059746 / TEST 0.679
epoch: 43
 [LOSS] TRAIN 0.5732048593665499 / TEST 0.5831949448585511
 [ACC] TRAIN 0.7007125890959888 / TEST 0.6995
epoch: 44
 [LOSS] TRAIN 0.5793967992682086 / TEST 0.5848114867210388
 [ACC] TRAIN 0.6917114640224098 / TEST 0.681
epoch: 45
 [LOSS] TRAIN 0.564380910027279 / TEST 0.5757913947105407
 [ACC] TRAIN 0.713339167433182 / TEST 0.7115
epoch: 46
 [LOSS] TRAIN 0.5680660980986809 / TEST 0.5848936700820923
 [ACC] TRAIN 0.7054631829276683 / TEST 0.6955
epoch: 47
 [LOSS] TRAIN 0.5680426509771694 / TEST 0.5782128067016602
 [ACC] TRAIN 0.6977122140565594 / TEST 0.6885
epoch: 48
 [LOSS] TRAIN 0.561968073023455 / TEST 0.5719959549903869
 [ACC] TRAIN 0.70952619069188 / TEST 0.6995
epoch: 49
 [LOSS] TRAIN 0.537038826081049 / TEST 0.5543700375556946
 [ACC] TRAIN 0.7320915115283481 / TEST 0.722
epoch: 50
 [LOSS] TRAIN 0.5606344932764079 / TEST 0.5783567175865173
 [ACC] TRAIN 0.7040255031580924 / TEST 0.6935
epoch: 51
 [LOSS] TRAIN 0.5131391556967287 / TEST 0.5354913735389709
 [ACC] TRAIN 0.749593699234756 / TEST 0.7435
epoch: 52
 [LOSS] TRAIN 0.53822208753391 / TEST 0.5469176063537597
 [ACC] TRAIN 0.7317789723491919 / TEST 0.735
epoch: 53
 [LOSS] TRAIN 0.49512297780547443 / TEST 0.5150759897232056
 [ACC] TRAIN 0.7639079884613048 / TEST 0.7585
epoch: 54
 [LOSS] TRAIN 0.5003706117073645 / TEST 0.5252641649246216
 [ACC] TRAIN 0.7636579572148495 / TEST 0.744
epoch: 55
 [LOSS] TRAIN 0.47377542026386604 / TEST 0.5022452273368836
 [ACC] TRAIN 0.7800975120996055 / TEST 0.769
epoch: 56
 [LOSS] TRAIN 0.47059177126582225 / TEST 0.5002688212394715
 [ACC] TRAIN 0.7845355669086107 / TEST 0.767
epoch: 57
 [LOSS] TRAIN 0.4592357919594395 / TEST 0.4889560194015503
 [ACC] TRAIN 0.7854731842299851 / TEST 0.7715
epoch: 58
 [LOSS] TRAIN 0.4580366465393819 / TEST 0.48893572950363157
 [ACC] TRAIN 0.7835354418408231 / TEST 0.7685
epoch: 59
 [LOSS] TRAIN 0.4126395984342179 / TEST 0.46349024391174315
 [ACC] TRAIN 0.8178522314320714 / TEST 0.791
epoch: 60
 [LOSS] TRAIN 0.392692661263791 / TEST 0.44578338861465455
 [ACC] TRAIN 0.8371046381617266 / TEST 0.802
epoch: 61
 [LOSS] TRAIN 0.3703401564158325 / TEST 0.4407791080474853
 [ACC] TRAIN 0.8417927241650265 / TEST 0.811
epoch: 62
 [LOSS] TRAIN 0.35453831892055876 / TEST 0.4211382176876068
 [ACC] TRAIN 0.8545443179950459 / TEST 0.82
epoch: 63
 [LOSS] TRAIN 0.3498423098884444 / TEST 0.41790657544136045
 [ACC] TRAIN 0.8532941617925758 / TEST 0.8145
epoch: 64
 [LOSS] TRAIN 0.3444969717681907 / TEST 0.43636398363113404
 [ACC] TRAIN 0.8507313413655166 / TEST 0.818
epoch: 65
 [LOSS] TRAIN 0.28670292473320724 / TEST 0.39842764973640443
 [ACC] TRAIN 0.8882985373842283 / TEST 0.8325
epoch: 66
 [LOSS] TRAIN 0.25332210070342626 / TEST 0.3715582623481751
 [ACC] TRAIN 0.9026128266107769 / TEST 0.8485
epoch: 67
 [LOSS] TRAIN 0.21741550778922386 / TEST 0.3511747174263001
 [ACC] TRAIN 0.9199899987051346 / TEST 0.86
epoch: 68
 [LOSS] TRAIN 0.23650034218151014 / TEST 0.4001797432899475
 [ACC] TRAIN 0.8990498811308332 / TEST 0.8395
epoch: 69
 [LOSS] TRAIN 0.2603088468406361 / TEST 0.38334754037857055
 [ACC] TRAIN 0.8946118264336007 / TEST 0.846
epoch: 70
 [LOSS] TRAIN 0.23364752077999704 / TEST 0.38256943941116334
 [ACC] TRAIN 0.901862732737284 / TEST 0.8575
epoch: 71
 [LOSS] TRAIN 0.2126429423583658 / TEST 0.38936987257003786
 [ACC] TRAIN 0.9136767096557622 / TEST 0.8645
epoch: 72
 [LOSS] TRAIN 0.1688738992559506 / TEST 0.3815175096988678
 [ACC] TRAIN 0.9329291160873568 / TEST 0.8705
epoch: 73
 [LOSS] TRAIN 0.28381934948475124 / TEST 0.4762384419441223
 [ACC] TRAIN 0.8735466933441186 / TEST 0.811
epoch: 74
 [LOSS] TRAIN 0.2060899195678235 / TEST 0.43420048809051515
 [ACC] TRAIN 0.9124265532744559 / TEST 0.8465
epoch: 75
 [LOSS] TRAIN 0.6599405219978445 / TEST 0.9846402020454407
 [ACC] TRAIN 0.7610326289817652 / TEST 0.7155
epoch: 76
 [LOSS] TRAIN 0.08448738208922435 / TEST 0.35925914549827576
 [ACC] TRAIN 0.9704963121060685 / TEST 0.9075
epoch: 77
 [LOSS] TRAIN 0.14965814081545636 / TEST 0.41957414197921755
 [ACC] TRAIN 0.940805100525807 / TEST 0.8875
epoch: 78
 [LOSS] TRAIN 0.22813355273485988 / TEST 0.5430373272895813
 [ACC] TRAIN 0.9069258658002802 / TEST 0.841
epoch: 79
 [LOSS] TRAIN 0.27482118928770766 / TEST 0.4922786211967468
 [ACC] TRAIN 0.8809226153418189 / TEST 0.82
epoch: 80
 [LOSS] TRAIN 0.09256359242095637 / TEST 0.3993301043510437
 [ACC] TRAIN 0.9652456555951907 / TEST 0.893
epoch: 81
 [LOSS] TRAIN 0.08022795985219389 / TEST 0.3923144164085388
 [ACC] TRAIN 0.9702462806733254 / TEST 0.8985
epoch: 82
 [LOSS] TRAIN 0.18612447929264592 / TEST 0.373602446436882
 [ACC] TRAIN 0.9266158270454359 / TEST 0.864
epoch: 83
 [LOSS] TRAIN 0.14433244980824175 / TEST 0.3656697573661804
 [ACC] TRAIN 0.9453681709170565 / TEST 0.8745
epoch: 84
 [LOSS] TRAIN 0.032134988286641554 / TEST 0.39096662020683287
 [ACC] TRAIN 0.9900612577168193 / TEST 0.9075
epoch: 85
 [LOSS] TRAIN 0.07121278218909165 / TEST 0.3588640764951706
 [ACC] TRAIN 0.9742467807954454 / TEST 0.9005
epoch: 86
 [LOSS] TRAIN 0.05502131258935418 / TEST 0.3940218970775604
 [ACC] TRAIN 0.9808726090239739 / TEST 0.909
epoch: 87
 [LOSS] TRAIN 0.04111477954946305 / TEST 0.4499317800998688
 [ACC] TRAIN 0.9851231403925491 / TEST 0.9145
Best test accurcy is (0.42091396498680117, 0.9055)
Net(
  (model): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): ReLU(inplace)
    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): ReLU(inplace)
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))
    (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (10): ReLU(inplace)
    (11): Flatten()
    (12): Linear(in_features=1152, out_features=256, bias=True)
    (13): ReLU(inplace)
    (14): Linear(in_features=256, out_features=2, bias=True)
  )
) 0.05 128
epoch: 1
 [LOSS] TRAIN 0.692979491379935 / TEST 0.6929935464859008
 [ACC] TRAIN 0.5296287037965909 / TEST 0.5300000009536743
epoch: 2
 [LOSS] TRAIN 0.6928368932918573 / TEST 0.6929674792289734
 [ACC] TRAIN 0.5004375549029791 / TEST 0.4969999995231628
epoch: 3
 [LOSS] TRAIN 0.6929849912366475 / TEST 0.6932985906600952
 [ACC] TRAIN 0.5007500937728975 / TEST 0.49650000023841856
epoch: 4
 [LOSS] TRAIN 0.6924946154038717 / TEST 0.6928421220779419
 [ACC] TRAIN 0.5007500937393656 / TEST 0.4975000009536743
epoch: 5
 [LOSS] TRAIN 0.6920366195503332 / TEST 0.6924410448074341
 [ACC] TRAIN 0.5463182899799626 / TEST 0.539
epoch: 6
 [LOSS] TRAIN 0.6914706858996675 / TEST 0.6920628771781921
 [ACC] TRAIN 0.5439429928517547 / TEST 0.5355
epoch: 7
 [LOSS] TRAIN 0.6904989972324994 / TEST 0.6915812826156617
 [ACC] TRAIN 0.5324415554253962 / TEST 0.5144999990463257
epoch: 8
 [LOSS] TRAIN 0.6890589219731887 / TEST 0.6905445261001587
 [ACC] TRAIN 0.5487560945192654 / TEST 0.542
epoch: 9
 [LOSS] TRAIN 0.6873914192864143 / TEST 0.6892476005554199
 [ACC] TRAIN 0.5500062507589931 / TEST 0.5439999995231628
epoch: 10
 [LOSS] TRAIN 0.6883259802285485 / TEST 0.6907364649772644
 [ACC] TRAIN 0.5384423052658065 / TEST 0.5305
epoch: 11
 [LOSS] TRAIN 0.682880883798672 / TEST 0.6866473903656006
 [ACC] TRAIN 0.5660707588001466 / TEST 0.5585000004768371
epoch: 12
 [LOSS] TRAIN 0.6837366164319291 / TEST 0.6881264944076538
 [ACC] TRAIN 0.5646330793509857 / TEST 0.5570000009536743
epoch: 13
 [LOSS] TRAIN 0.6780076676241262 / TEST 0.6826672043800354
 [ACC] TRAIN 0.5781347667862436 / TEST 0.5705
epoch: 14
 [LOSS] TRAIN 0.676773016781252 / TEST 0.6826472578048706
 [ACC] TRAIN 0.5771346420239681 / TEST 0.5634999990463256
epoch: 15
 [LOSS] TRAIN 0.6751749853310488 / TEST 0.6794706239700318
 [ACC] TRAIN 0.5810726342506447 / TEST 0.5785000009536743
epoch: 16
 [LOSS] TRAIN 0.6770784359586911 / TEST 0.6847593727111816
 [ACC] TRAIN 0.5724465558045744 / TEST 0.5539999990463257
epoch: 17
 [LOSS] TRAIN 0.6708689918069783 / TEST 0.6773927431106568
 [ACC] TRAIN 0.58369796243902 / TEST 0.5649999995231628
epoch: 18
 [LOSS] TRAIN 0.672796770660173 / TEST 0.675165904045105
 [ACC] TRAIN 0.5820102514602464 / TEST 0.5775000009536743
epoch: 19
 [LOSS] TRAIN 0.6683412311836874 / TEST 0.6745782237052917
 [ACC] TRAIN 0.5885735718678469 / TEST 0.5764999990463257
epoch: 20
 [LOSS] TRAIN 0.6756466598656196 / TEST 0.6794116010665894
 [ACC] TRAIN 0.5721965245432161 / TEST 0.5669999990463257
epoch: 21
 [LOSS] TRAIN 0.6652399558606096 / TEST 0.669616039276123
 [ACC] TRAIN 0.5966370798286936 / TEST 0.5925000009536743
epoch: 22
 [LOSS] TRAIN 0.6693783598939305 / TEST 0.6740742897987366
 [ACC] TRAIN 0.5886360794801327 / TEST 0.5860000009536743
epoch: 23
 [LOSS] TRAIN 0.6773913294125354 / TEST 0.6824863090515136
 [ACC] TRAIN 0.566383297882433 / TEST 0.5614999990463256
epoch: 24
 [LOSS] TRAIN 0.6619673363341885 / TEST 0.6649445176124573
 [ACC] TRAIN 0.6013876736678248 / TEST 0.5975
epoch: 25
 [LOSS] TRAIN 0.6605245178007219 / TEST 0.6632524189949036
 [ACC] TRAIN 0.6042630331026553 / TEST 0.5984999995231628
epoch: 26
 [LOSS] TRAIN 0.6599964178015343 / TEST 0.6626883969306946
 [ACC] TRAIN 0.6025753218854334 / TEST 0.597
epoch: 27
 [LOSS] TRAIN 0.6602823802464782 / TEST 0.6632390966415406
 [ACC] TRAIN 0.6064508065370816 / TEST 0.605
epoch: 28
 [LOSS] TRAIN 0.658790773295629 / TEST 0.6612548575401306
 [ACC] TRAIN 0.6061382672461528 / TEST 0.599
epoch: 29
 [LOSS] TRAIN 0.6982138152568992 / TEST 0.6999447069168091
 [ACC] TRAIN 0.5395674461393837 / TEST 0.5505
epoch: 30
 [LOSS] TRAIN 0.6567876690670108 / TEST 0.6595962438583374
 [ACC] TRAIN 0.6081385172550522 / TEST 0.6035000009536743
epoch: 31
 [LOSS] TRAIN 0.6562537349586354 / TEST 0.6590715589523315
 [ACC] TRAIN 0.6111388925254785 / TEST 0.6155
epoch: 32
 [LOSS] TRAIN 0.6603063872149921 / TEST 0.6631952991485596
 [ACC] TRAIN 0.603700462766462 / TEST 0.6045
epoch: 33
 [LOSS] TRAIN 0.6578577837954165 / TEST 0.6605043168067932
 [ACC] TRAIN 0.6035129390279715 / TEST 0.5995000009536743
epoch: 34
 [LOSS] TRAIN 0.6529285291877892 / TEST 0.6551357684135437
 [ACC] TRAIN 0.6135766972883268 / TEST 0.613
epoch: 35
 [LOSS] TRAIN 0.6572973857687211 / TEST 0.6602810821533203
 [ACC] TRAIN 0.6068258531794933 / TEST 0.6009999990463257
epoch: 36
 [LOSS] TRAIN 0.6631259370601271 / TEST 0.6653552141189575
 [ACC] TRAIN 0.5883860482597577 / TEST 0.581
epoch: 37
 [LOSS] TRAIN 0.6490256258332293 / TEST 0.651935170173645
 [ACC] TRAIN 0.6232654083623098 / TEST 0.619
epoch: 38
 [LOSS] TRAIN 0.6500591155081514 / TEST 0.6534146280288696
 [ACC] TRAIN 0.6176397051568597 / TEST 0.6074999990463257
epoch: 39
 [LOSS] TRAIN 0.6520142788469143 / TEST 0.656591477394104
 [ACC] TRAIN 0.6170146267687414 / TEST 0.6174999995231628
epoch: 40
 [LOSS] TRAIN 0.6623709060084986 / TEST 0.6672363500595093
 [ACC] TRAIN 0.5993249155920972 / TEST 0.6044999995231628
epoch: 41
 [LOSS] TRAIN 0.6703439873000178 / TEST 0.6761908240318298
 [ACC] TRAIN 0.5940117514242246 / TEST 0.588
epoch: 42
 [LOSS] TRAIN 0.640686832251944 / TEST 0.6464127249717713
 [ACC] TRAIN 0.6313289160399992 / TEST 0.6245000004768372
epoch: 43
 [LOSS] TRAIN 0.6519670698073137 / TEST 0.6596898865699768
 [ACC] TRAIN 0.6176397049035083 / TEST 0.611
epoch: 44
 [LOSS] TRAIN 0.6348295114400729 / TEST 0.642047661781311
 [ACC] TRAIN 0.6436429555333545 / TEST 0.6380000004768371
epoch: 45
 [LOSS] TRAIN 0.6365970666072625 / TEST 0.6423640832901001
 [ACC] TRAIN 0.6367045882374425 / TEST 0.6329999990463256
epoch: 46
 [LOSS] TRAIN 0.641922444369677 / TEST 0.6491414785385132
 [ACC] TRAIN 0.6213901736897548 / TEST 0.6119999990463257
epoch: 47
 [LOSS] TRAIN 0.6276893943961761 / TEST 0.636977445602417
 [ACC] TRAIN 0.6484560569251593 / TEST 0.6440000009536743
epoch: 48
 [LOSS] TRAIN 0.6220868498567552 / TEST 0.6316545596122741
 [ACC] TRAIN 0.6497687212242634 / TEST 0.6399999990463257
epoch: 49
 [LOSS] TRAIN 0.6251985597035217 / TEST 0.6336404004096985
 [ACC] TRAIN 0.6446430805489815 / TEST 0.6394999995231628
epoch: 50
 [LOSS] TRAIN 0.6219133636045044 / TEST 0.6292944874763489
 [ACC] TRAIN 0.6544568072797239 / TEST 0.639
epoch: 51
 [LOSS] TRAIN 0.6204189574037408 / TEST 0.6289837861061096
 [ACC] TRAIN 0.655206901011638 / TEST 0.6354999995231628
epoch: 52
 [LOSS] TRAIN 0.6147289184991055 / TEST 0.6228815813064575
 [ACC] TRAIN 0.6610826352549011 / TEST 0.6524999990463257
epoch: 53
 [LOSS] TRAIN 0.6107590209470568 / TEST 0.6201269068717956
 [ACC] TRAIN 0.6650206277647351 / TEST 0.6680000004768372
epoch: 54
 [LOSS] TRAIN 0.6168753497450631 / TEST 0.6254220247268677
 [ACC] TRAIN 0.6533941742047203 / TEST 0.6480000004768371
epoch: 55
 [LOSS] TRAIN 0.6217130980263323 / TEST 0.6321204442977906
 [ACC] TRAIN 0.6577072135656085 / TEST 0.6469999995231629
epoch: 56
 [LOSS] TRAIN 0.6685397933238535 / TEST 0.6794507417678833
 [ACC] TRAIN 0.5963870485524324 / TEST 0.5869999995231628
epoch: 57
 [LOSS] TRAIN 0.6095756436008292 / TEST 0.61900355052948
 [ACC] TRAIN 0.6633329165400617 / TEST 0.654
epoch: 58
 [LOSS] TRAIN 0.6043043415208714 / TEST 0.6124818997383118
 [ACC] TRAIN 0.6703337918655442 / TEST 0.661
epoch: 59
 [LOSS] TRAIN 0.6022164074536159 / TEST 0.611800091266632
 [ACC] TRAIN 0.6727090885615644 / TEST 0.6594999995231628
epoch: 60
 [LOSS] TRAIN 0.5987276119252327 / TEST 0.6089209270477295
 [ACC] TRAIN 0.677334666743936 / TEST 0.6729999995231628
epoch: 61
 [LOSS] TRAIN 0.6042098655359702 / TEST 0.6125088810920716
 [ACC] TRAIN 0.6685835731105516 / TEST 0.6625
epoch: 62
 [LOSS] TRAIN 0.6005608601888458 / TEST 0.6100875625610351
 [ACC] TRAIN 0.673584197935335 / TEST 0.6675000009536743
epoch: 63
 [LOSS] TRAIN 0.5957203625306321 / TEST 0.605349289894104
 [ACC] TRAIN 0.6772721589379108 / TEST 0.6720000004768372
epoch: 64
 [LOSS] TRAIN 0.5957585512243043 / TEST 0.6054547533988953
 [ACC] TRAIN 0.6793974245961182 / TEST 0.6779999990463257
epoch: 65
 [LOSS] TRAIN 0.6016080392302685 / TEST 0.611062071800232
 [ACC] TRAIN 0.6725215651136828 / TEST 0.6684999995231629
epoch: 66
 [LOSS] TRAIN 0.586228244147281 / TEST 0.5963392343521118
 [ACC] TRAIN 0.6890861356701012 / TEST 0.6845
epoch: 67
 [LOSS] TRAIN 0.587420579507539 / TEST 0.5978901700973511
 [ACC] TRAIN 0.6907738468798716 / TEST 0.6850000004768372
epoch: 68
 [LOSS] TRAIN 0.585838461349958 / TEST 0.5991655168533325
 [ACC] TRAIN 0.6896487062223883 / TEST 0.6820000009536743
epoch: 69
 [LOSS] TRAIN 0.5887895012396636 / TEST 0.5992813196182251
 [ACC] TRAIN 0.6848981124130632 / TEST 0.6860000004768372
epoch: 70
 [LOSS] TRAIN 0.58583530671508 / TEST 0.5976208772659302
 [ACC] TRAIN 0.6858982371678872 / TEST 0.6760000004768372
epoch: 71
 [LOSS] TRAIN 0.5910140593389613 / TEST 0.6035468363761902
 [ACC] TRAIN 0.684835604577232 / TEST 0.6705000009536743
epoch: 72
 [LOSS] TRAIN 0.5775556503601231 / TEST 0.5902703680992126
 [ACC] TRAIN 0.6988998623635861 / TEST 0.6935000004768371
epoch: 73
 [LOSS] TRAIN 0.5918440307165804 / TEST 0.6017833757400513
 [ACC] TRAIN 0.6798349795214518 / TEST 0.68
epoch: 74
 [LOSS] TRAIN 0.5742085693195204 / TEST 0.585069504737854
 [ACC] TRAIN 0.7040255030984803 / TEST 0.7019999995231628
epoch: 75
 [LOSS] TRAIN 0.5731389907870178 / TEST 0.5867173290252685
 [ACC] TRAIN 0.701587698596435 / TEST 0.7010000004768372
epoch: 76
 [LOSS] TRAIN 0.5707524260709786 / TEST 0.5819741907119751
 [ACC] TRAIN 0.7098387298039726 / TEST 0.7135000004768371
epoch: 77
 [LOSS] TRAIN 0.5847051130531579 / TEST 0.5979069051742554
 [ACC] TRAIN 0.6875859484074637 / TEST 0.6794999990463256
epoch: 78
 [LOSS] TRAIN 0.639948548704613 / TEST 0.6463506870269775
 [ACC] TRAIN 0.6378922366934995 / TEST 0.6285000004768372
epoch: 79
 [LOSS] TRAIN 0.5982481738167534 / TEST 0.6118128843307495
 [ACC] TRAIN 0.6733966744949049 / TEST 0.6649999990463257
epoch: 80
 [LOSS] TRAIN 0.5656400032007094 / TEST 0.5822212057113647
 [ACC] TRAIN 0.7082135266088697 / TEST 0.6994999990463256
epoch: 81
 [LOSS] TRAIN 0.5671153784707302 / TEST 0.582636360168457
 [ACC] TRAIN 0.7034629327548356 / TEST 0.6940000009536743
epoch: 82
 [LOSS] TRAIN 0.6125167925546491 / TEST 0.6274138951301574
 [ACC] TRAIN 0.6552694088251148 / TEST 0.6460000009536743
epoch: 83
 [LOSS] TRAIN 0.5687891031849577 / TEST 0.5882585885524749
 [ACC] TRAIN 0.7040880108896025 / TEST 0.6990000009536743
epoch: 84
 [LOSS] TRAIN 0.6091637999389392 / TEST 0.6262474856376647
 [ACC] TRAIN 0.6601450182911992 / TEST 0.6539999995231628
epoch: 85
 [LOSS] TRAIN 0.5451957196395895 / TEST 0.5614549150466919
 [ACC] TRAIN 0.7212151518120201 / TEST 0.7155
epoch: 86
 [LOSS] TRAIN 0.5423493795744224 / TEST 0.5572848443984986
 [ACC] TRAIN 0.726778347151833 / TEST 0.7174999990463257
epoch: 87
 [LOSS] TRAIN 0.5746541353803468 / TEST 0.5933458294868469
 [ACC] TRAIN 0.6942117763900923 / TEST 0.6834999990463256
epoch: 88
 [LOSS] TRAIN 0.5322996281149804 / TEST 0.5525542578697205
 [ACC] TRAIN 0.7308413553035233 / TEST 0.7184999995231628
epoch: 89
 [LOSS] TRAIN 0.5962070152601282 / TEST 0.6141206007003784
 [ACC] TRAIN 0.6778972370503231 / TEST 0.6685000009536743
epoch: 90
 [LOSS] TRAIN 0.5485982118598937 / TEST 0.569784439086914
 [ACC] TRAIN 0.7174021753985846 / TEST 0.7075000009536743
epoch: 91
 [LOSS] TRAIN 0.5718776954160748 / TEST 0.5933422396183013
 [ACC] TRAIN 0.6977122139447867 / TEST 0.6855
epoch: 92
 [LOSS] TRAIN 0.5195314018469123 / TEST 0.5444244508743286
 [ACC] TRAIN 0.7404050504897501 / TEST 0.7245000009536743
epoch: 93
 [LOSS] TRAIN 0.5882965566471438 / TEST 0.6008721685409546
 [ACC] TRAIN 0.6778347294827464 / TEST 0.671
epoch: 94
 [LOSS] TRAIN 0.5141417472820637 / TEST 0.5351245760917663
 [ACC] TRAIN 0.7479684959651381 / TEST 0.7364999990463257
epoch: 95
 [LOSS] TRAIN 0.5603414880944753 / TEST 0.5891177182197571
 [ACC] TRAIN 0.7019627452686528 / TEST 0.6894999995231629
epoch: 96
 [LOSS] TRAIN 0.4948394089799357 / TEST 0.5236207444667816
 [ACC] TRAIN 0.7598449804884506 / TEST 0.7375
epoch: 97
 [LOSS] TRAIN 0.49672144808267293 / TEST 0.5231627080440521
 [ACC] TRAIN 0.7695961996069073 / TEST 0.7420000004768371
epoch: 98
 [LOSS] TRAIN 0.5775125686236211 / TEST 0.6090033254623413
 [ACC] TRAIN 0.6916489562759967 / TEST 0.6845000009536744
Best test accurcy is (0.6064301958084106, 0.6690000009536743)
Net(
  (model): Sequential(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): ReLU(inplace)
    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): ReLU(inplace)
    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
    (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (10): ReLU(inplace)
    (11): Flatten()
    (12): Linear(in_features=576, out_features=256, bias=True)
    (13): ReLU(inplace)
    (14): Linear(in_features=256, out_features=2, bias=True)
  )
) 0.05 64
epoch: 1
 [LOSS] TRAIN 0.6934669651393817 / TEST 0.6941644597053528
 [ACC] TRAIN 0.49931241404430493 / TEST 0.486
epoch: 2
 [LOSS] TRAIN 0.6929873687011746 / TEST 0.6931054925918579
 [ACC] TRAIN 0.49931241406293375 / TEST 0.486
epoch: 3
 [LOSS] TRAIN 0.6928299477672947 / TEST 0.6924952278137207
 [ACC] TRAIN 0.5006875859855011 / TEST 0.514
epoch: 4
 [LOSS] TRAIN 0.6927408354180145 / TEST 0.6919687628746033
 [ACC] TRAIN 0.5006875860525647 / TEST 0.514
epoch: 5
 [LOSS] TRAIN 0.6918803548750273 / TEST 0.6919664340019226
 [ACC] TRAIN 0.5217527190228226 / TEST 0.521
epoch: 6
 [LOSS] TRAIN 0.6907054844879034 / TEST 0.6893123111724854
 [ACC] TRAIN 0.5261282659810935 / TEST 0.534
epoch: 7
 [LOSS] TRAIN 0.6855872653546758 / TEST 0.6834812960624694
 [ACC] TRAIN 0.5556319539420888 / TEST 0.575
epoch: 8
 [LOSS] TRAIN 0.681321676603957 / TEST 0.6823242092132569
 [ACC] TRAIN 0.5611951494458348 / TEST 0.5605
epoch: 9
 [LOSS] TRAIN 0.6810581289554987 / TEST 0.681108952999115
 [ACC] TRAIN 0.5568821103159436 / TEST 0.563
epoch: 10
 [LOSS] TRAIN 0.6697506122714892 / TEST 0.669418288230896
 [ACC] TRAIN 0.5933866733341667 / TEST 0.598
epoch: 11
 [LOSS] TRAIN 0.6681593869951221 / TEST 0.6699210720062256
 [ACC] TRAIN 0.5926990873561172 / TEST 0.5985
epoch: 12
 [LOSS] TRAIN 0.6675678439655368 / TEST 0.6711928663253784
 [ACC] TRAIN 0.5951368920444503 / TEST 0.6005
epoch: 13
 [LOSS] TRAIN 0.6699972640411423 / TEST 0.6735297079086304
 [ACC] TRAIN 0.590761345153243 / TEST 0.599
epoch: 14
 [LOSS] TRAIN 0.6661929400477771 / TEST 0.6654358086585999
 [ACC] TRAIN 0.5875734466063199 / TEST 0.592
epoch: 15
 [LOSS] TRAIN 0.6648145464229978 / TEST 0.6697708916664123
 [ACC] TRAIN 0.6004500562421291 / TEST 0.61
epoch: 16
 [LOSS] TRAIN 0.6646801146630541 / TEST 0.661432774066925
 [ACC] TRAIN 0.5961370172240106 / TEST 0.6045
epoch: 17
 [LOSS] TRAIN 0.6647023739315805 / TEST 0.6654717268943786
 [ACC] TRAIN 0.5915739468551156 / TEST 0.589
epoch: 18
 [LOSS] TRAIN 0.6676824133103155 / TEST 0.672025815486908
 [ACC] TRAIN 0.5915739467470686 / TEST 0.5975
epoch: 19
 [LOSS] TRAIN 0.6620553493171889 / TEST 0.6642979650497437
 [ACC] TRAIN 0.6000750093091084 / TEST 0.605
epoch: 20
 [LOSS] TRAIN 0.6567579635397645 / TEST 0.6556923537254333
 [ACC] TRAIN 0.6099512440023579 / TEST 0.607
epoch: 21
 [LOSS] TRAIN 0.6558064220100361 / TEST 0.6572877697944641
 [ACC] TRAIN 0.6143267908861136 / TEST 0.6085
epoch: 22
 [LOSS] TRAIN 0.6528179982346675 / TEST 0.6562321133613587
 [ACC] TRAIN 0.6175771971533695 / TEST 0.609
epoch: 23
 [LOSS] TRAIN 0.6545557568991001 / TEST 0.6589705333709717
 [ACC] TRAIN 0.612951618937466 / TEST 0.5965
epoch: 24
 [LOSS] TRAIN 0.6607279708451339 / TEST 0.6690541658401489
 [ACC] TRAIN 0.6023877985269699 / TEST 0.602
epoch: 25
 [LOSS] TRAIN 0.6606378755818041 / TEST 0.6645199222564697
 [ACC] TRAIN 0.5956369547236486 / TEST 0.58
epoch: 26
 [LOSS] TRAIN 0.6449990014923201 / TEST 0.6497190012931824
 [ACC] TRAIN 0.6282660332392538 / TEST 0.6185
epoch: 27
 [LOSS] TRAIN 0.6500605797898785 / TEST 0.6531272087097167
 [ACC] TRAIN 0.6178272284482595 / TEST 0.613
epoch: 28
 [LOSS] TRAIN 0.6414737702533743 / TEST 0.6481131720542908
 [ACC] TRAIN 0.6327665959362507 / TEST 0.6185
epoch: 29
 [LOSS] TRAIN 0.6514396265396879 / TEST 0.6559492545127869
 [ACC] TRAIN 0.6150143768418087 / TEST 0.5985
epoch: 30
 [LOSS] TRAIN 0.6501006385299143 / TEST 0.660139753818512
 [ACC] TRAIN 0.6181397673964187 / TEST 0.61
epoch: 31
 [LOSS] TRAIN 0.6350501181856067 / TEST 0.6438047847747803
 [ACC] TRAIN 0.6403300412402538 / TEST 0.6335
epoch: 32
 [LOSS] TRAIN 0.6315779565706717 / TEST 0.6406435985565185
 [ACC] TRAIN 0.6416427053307158 / TEST 0.632
epoch: 33
 [LOSS] TRAIN 0.6341357616308794 / TEST 0.6441424832344055
 [ACC] TRAIN 0.641767720898057 / TEST 0.629
epoch: 34
 [LOSS] TRAIN 0.6568123177299352 / TEST 0.6720254254341126
 [ACC] TRAIN 0.6048881109542646 / TEST 0.5915
epoch: 35
 [LOSS] TRAIN 0.6274964647794429 / TEST 0.6368110146522522
 [ACC] TRAIN 0.64270533821198 / TEST 0.624
epoch: 36
 [LOSS] TRAIN 0.6222824328227973 / TEST 0.6366377148628235
 [ACC] TRAIN 0.6551443930267766 / TEST 0.637
epoch: 37
 [LOSS] TRAIN 0.6543344849049263 / TEST 0.663059220790863
 [ACC] TRAIN 0.600762595257352 / TEST 0.5975
epoch: 38
 [LOSS] TRAIN 0.6184936857757038 / TEST 0.6320397086143493
 [ACC] TRAIN 0.6543942992799594 / TEST 0.6435
epoch: 39
 [LOSS] TRAIN 0.6184288205497189 / TEST 0.6271123261451721
 [ACC] TRAIN 0.6518939867930527 / TEST 0.645
epoch: 40
 [LOSS] TRAIN 0.6307507429380449 / TEST 0.643947096824646
 [ACC] TRAIN 0.6338917364521554 / TEST 0.62
epoch: 41
 [LOSS] TRAIN 0.6259359481230663 / TEST 0.6455339684486389
 [ACC] TRAIN 0.6428928617045706 / TEST 0.6265
epoch: 42
 [LOSS] TRAIN 0.6056219011429683 / TEST 0.6266785407066345
 [ACC] TRAIN 0.6688961121183229 / TEST 0.643
epoch: 43
 [LOSS] TRAIN 0.598823100853777 / TEST 0.6175662097930908
 [ACC] TRAIN 0.6770221277510677 / TEST 0.6625
epoch: 44
 [LOSS] TRAIN 0.5944941266206879 / TEST 0.6157974314689636
 [ACC] TRAIN 0.6817102138735918 / TEST 0.6595
epoch: 45
 [LOSS] TRAIN 0.5898260565038949 / TEST 0.6112235555648804
 [ACC] TRAIN 0.686773346645979 / TEST 0.675
epoch: 46
 [LOSS] TRAIN 0.5928977684075124 / TEST 0.612433648109436
 [ACC] TRAIN 0.6889611201698236 / TEST 0.6625
epoch: 47
 [LOSS] TRAIN 0.5998934740304261 / TEST 0.6259706325531006
 [ACC] TRAIN 0.672334041852089 / TEST 0.653
epoch: 48
 [LOSS] TRAIN 0.588955075729786 / TEST 0.6120711174011231
 [ACC] TRAIN 0.6818977372544097 / TEST 0.663
epoch: 49
 [LOSS] TRAIN 0.5840157477434523 / TEST 0.6127713642120362
 [ACC] TRAIN 0.6883360420350567 / TEST 0.6665
epoch: 50
 [LOSS] TRAIN 0.5924993458502381 / TEST 0.6239375133514404
 [ACC] TRAIN 0.6795849481036118 / TEST 0.653
epoch: 51
 [LOSS] TRAIN 0.5809651187456076 / TEST 0.6106966662406922
 [ACC] TRAIN 0.6968996123770413 / TEST 0.6665
epoch: 52
 [LOSS] TRAIN 0.5641417953055685 / TEST 0.5931157350540162
 [ACC] TRAIN 0.7088386048107002 / TEST 0.684
epoch: 53
 [LOSS] TRAIN 0.5809084999813171 / TEST 0.6132568056583405
 [ACC] TRAIN 0.6896487061180671 / TEST 0.6675
epoch: 54
 [LOSS] TRAIN 0.5599678661215527 / TEST 0.5919488039016724
 [ACC] TRAIN 0.7083385424221109 / TEST 0.6855
epoch: 55
 [LOSS] TRAIN 0.5707187586343948 / TEST 0.5999267921447754
 [ACC] TRAIN 0.6976497061238586 / TEST 0.6795
epoch: 56
 [LOSS] TRAIN 0.5494253302659224 / TEST 0.5841685547828674
 [ACC] TRAIN 0.7220277534915381 / TEST 0.6945
epoch: 57
 [LOSS] TRAIN 0.5456008771342447 / TEST 0.5800160365104675
 [ACC] TRAIN 0.7215901987375893 / TEST 0.692
epoch: 58
 [LOSS] TRAIN 0.6084704349556331 / TEST 0.6497229089736939
 [ACC] TRAIN 0.6775221903110418 / TEST 0.65
epoch: 59
 [LOSS] TRAIN 0.5562523957348895 / TEST 0.5977062845230102
 [ACC] TRAIN 0.7092761594826824 / TEST 0.6825
epoch: 60
 [LOSS] TRAIN 0.5291920979219104 / TEST 0.5701177635192871
 [ACC] TRAIN 0.7317789723417404 / TEST 0.7065
epoch: 61
 [LOSS] TRAIN 0.5260052818673181 / TEST 0.5700568871498108
 [ACC] TRAIN 0.7345293162017781 / TEST 0.7055
epoch: 62
 [LOSS] TRAIN 0.5462370645867272 / TEST 0.5902238140106201
 [ACC] TRAIN 0.7167770971743997 / TEST 0.6875
epoch: 63
 [LOSS] TRAIN 0.5187009810387961 / TEST 0.5622491645812988
 [ACC] TRAIN 0.755656957149446 / TEST 0.715
epoch: 64
 [LOSS] TRAIN 0.5171303147598421 / TEST 0.5643122076988221
 [ACC] TRAIN 0.7419052380578997 / TEST 0.706
epoch: 65
 [LOSS] TRAIN 0.6159066245889407 / TEST 0.6576273965835572
 [ACC] TRAIN 0.6600825103510468 / TEST 0.645
epoch: 66
 [LOSS] TRAIN 0.4884889956145961 / TEST 0.5410135746002197
 [ACC] TRAIN 0.7700962620625601 / TEST 0.7235
epoch: 67
 [LOSS] TRAIN 0.4730464295866132 / TEST 0.5371378164291382
 [ACC] TRAIN 0.7751593948871079 / TEST 0.7305
epoch: 68
 [LOSS] TRAIN 0.4836059403368824 / TEST 0.5357333636283874
 [ACC] TRAIN 0.764283035401777 / TEST 0.7345
epoch: 69
 [LOSS] TRAIN 0.46504894619525144 / TEST 0.5290644121170044
 [ACC] TRAIN 0.7717839729593671 / TEST 0.7305
epoch: 70
 [LOSS] TRAIN 0.4670715837430054 / TEST 0.5402019882202148
 [ACC] TRAIN 0.7815351918617298 / TEST 0.728
epoch: 71
 [LOSS] TRAIN 0.44206463824899395 / TEST 0.5185709362030029
 [ACC] TRAIN 0.7947868482666264 / TEST 0.7465
epoch: 72
 [LOSS] TRAIN 0.411206245228624 / TEST 0.48594869899749754
 [ACC] TRAIN 0.820915114292429 / TEST 0.776
epoch: 73
 [LOSS] TRAIN 0.42753233576077254 / TEST 0.5046568117141723
 [ACC] TRAIN 0.8082885360893629 / TEST 0.756
epoch: 74
 [LOSS] TRAIN 0.3971072592717705 / TEST 0.49653794384002686
 [ACC] TRAIN 0.8212276533598124 / TEST 0.7625
epoch: 75
 [LOSS] TRAIN 0.36279707290870217 / TEST 0.4643412935733795
 [ACC] TRAIN 0.8434179272707112 / TEST 0.785
epoch: 76
 [LOSS] TRAIN 0.4859038015010432 / TEST 0.5924093079566956
 [ACC] TRAIN 0.7540317538872795 / TEST 0.7095
epoch: 77
 [LOSS] TRAIN 0.38128166396419083 / TEST 0.4928141603469849
 [ACC] TRAIN 0.8284160519096312 / TEST 0.764
epoch: 78
 [LOSS] TRAIN 0.48617269859371787 / TEST 0.586066385269165
 [ACC] TRAIN 0.7543442929472114 / TEST 0.714
epoch: 79
 [LOSS] TRAIN 0.29907400147149465 / TEST 0.4064799220561981
 [ACC] TRAIN 0.8826728339999419 / TEST 0.8235
epoch: 80
 [LOSS] TRAIN 0.311453421572802 / TEST 0.428010272026062
 [ACC] TRAIN 0.8717964745742229 / TEST 0.821
epoch: 81
 [LOSS] TRAIN 0.3319704848250712 / TEST 0.4709007863998413
 [ACC] TRAIN 0.8452306538391805 / TEST 0.8
epoch: 82
 [LOSS] TRAIN 0.2853338983911681 / TEST 0.4433419151306152
 [ACC] TRAIN 0.8744843104419477 / TEST 0.817
epoch: 83
 [LOSS] TRAIN 0.26870019391322525 / TEST 0.4192145276069641
 [ACC] TRAIN 0.8898612326615333 / TEST 0.8255
epoch: 84
 [LOSS] TRAIN 0.3328420872397088 / TEST 0.4816527032852173
 [ACC] TRAIN 0.8462307788697104 / TEST 0.791
epoch: 85
 [LOSS] TRAIN 0.21107468261973888 / TEST 0.3709497501850128
 [ACC] TRAIN 0.9219277409750725 / TEST 0.858
epoch: 86
 [LOSS] TRAIN 0.21308202570804224 / TEST 0.3778631639480591
 [ACC] TRAIN 0.9193649205703678 / TEST 0.848
epoch: 87
 [LOSS] TRAIN 0.24488063840467283 / TEST 0.41002985572814943
 [ACC] TRAIN 0.898112263988295 / TEST 0.836
epoch: 88
 [LOSS] TRAIN 0.19050053985383544 / TEST 0.40040488773584365
 [ACC] TRAIN 0.9248031003353878 / TEST 0.8485
epoch: 89
 [LOSS] TRAIN 0.23427597577422243 / TEST 0.42059365367889406
 [ACC] TRAIN 0.9026128266107769 / TEST 0.8365
epoch: 90
 [LOSS] TRAIN 0.2084644518057724 / TEST 0.42515933084487917
 [ACC] TRAIN 0.9123015376027934 / TEST 0.8565
epoch: 91
 [LOSS] TRAIN 0.15561173794969707 / TEST 0.38373561906814574
 [ACC] TRAIN 0.9431178896840564 / TEST 0.8575
epoch: 92
 [LOSS] TRAIN 0.18268774584511366 / TEST 0.4326258487701416
 [ACC] TRAIN 0.9252406550893367 / TEST 0.846
Best test accurcy is (0.39915917444229126, 0.8585)
Net(
  (model): Sequential(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): ReLU(inplace)
    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): ReLU(inplace)
    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
    (9): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (10): ReLU(inplace)
    (11): Flatten()
    (12): Linear(in_features=576, out_features=256, bias=True)
    (13): ReLU(inplace)
    (14): Linear(in_features=256, out_features=2, bias=True)
  )
) 0.05 128
epoch: 1
 [LOSS] TRAIN 0.6931818452070975 / TEST 0.6928222131729126
 [ACC] TRAIN 0.49643705466536076 / TEST 0.5084999995231628
epoch: 2
 [LOSS] TRAIN 0.6928345382861875 / TEST 0.6927474126815796
 [ACC] TRAIN 0.5050006250557803 / TEST 0.5159999997615814
epoch: 3
 [LOSS] TRAIN 0.6927650931746173 / TEST 0.6934499382972718
 [ACC] TRAIN 0.5035629453458165 / TEST 0.4915000009536743
epoch: 4
 [LOSS] TRAIN 0.6923400040477019 / TEST 0.6922638478279114
 [ACC] TRAIN 0.5333166645867986 / TEST 0.5400000004768372
epoch: 5
 [LOSS] TRAIN 0.69198737882617 / TEST 0.6917681112289429
 [ACC] TRAIN 0.5271908990635487 / TEST 0.5389999990463257
epoch: 6
 [LOSS] TRAIN 0.691139710785553 / TEST 0.6919032258987426
 [ACC] TRAIN 0.5158769846230778 / TEST 0.5060000004768371
epoch: 7
 [LOSS] TRAIN 0.6896153041565026 / TEST 0.6900556807518006
 [ACC] TRAIN 0.5515689461108133 / TEST 0.5364999990463257
epoch: 8
 [LOSS] TRAIN 0.688394352650252 / TEST 0.688720202922821
 [ACC] TRAIN 0.5498812353630367 / TEST 0.5484999995231629
epoch: 9
 [LOSS] TRAIN 0.6868627787396406 / TEST 0.6873816094398498
 [ACC] TRAIN 0.5514439307074053 / TEST 0.5449999995231628
epoch: 10
 [LOSS] TRAIN 0.684484494523803 / TEST 0.6857967400550842
 [ACC] TRAIN 0.5583197899439407 / TEST 0.5479999990463257
epoch: 11
 [LOSS] TRAIN 0.6811357058052838 / TEST 0.6826440796852112
 [ACC] TRAIN 0.5778222277039572 / TEST 0.5679999990463257
epoch: 12
 [LOSS] TRAIN 0.6802100791962746 / TEST 0.6833360366821289
 [ACC] TRAIN 0.5614451806103233 / TEST 0.553
epoch: 13
 [LOSS] TRAIN 0.6735598475042768 / TEST 0.6743812112808227
 [ACC] TRAIN 0.5883235406139401 / TEST 0.5890000009536743
epoch: 14
 [LOSS] TRAIN 0.6802984465880906 / TEST 0.6786634154319763
 [ACC] TRAIN 0.5641955246193914 / TEST 0.5679999990463257
epoch: 15
 [LOSS] TRAIN 0.6749906513017033 / TEST 0.6741124167442322
 [ACC] TRAIN 0.5743217904175173 / TEST 0.5765
epoch: 16
 [LOSS] TRAIN 0.6962856760411311 / TEST 0.693065716266632
 [ACC] TRAIN 0.5374421804886279 / TEST 0.543
epoch: 17
 [LOSS] TRAIN 0.6653708219304653 / TEST 0.6664523138999939
 [ACC] TRAIN 0.6047005877299284 / TEST 0.6050000009536743
epoch: 18
 [LOSS] TRAIN 0.6728121376302871 / TEST 0.6770406355857849
 [ACC] TRAIN 0.57844730611443 / TEST 0.5685
epoch: 19
 [LOSS] TRAIN 0.6680144784167076 / TEST 0.6676245951652526
 [ACC] TRAIN 0.5878859859345064 / TEST 0.5909999990463257
epoch: 20
 [LOSS] TRAIN 0.665706053877312 / TEST 0.6650702886581421
 [ACC] TRAIN 0.5925115639305901 / TEST 0.592
epoch: 21
 [LOSS] TRAIN 0.6765765243805204 / TEST 0.6749270982742309
 [ACC] TRAIN 0.5743842980298032 / TEST 0.5784999990463257
epoch: 22
 [LOSS] TRAIN 0.6687793577219608 / TEST 0.6682114057540893
 [ACC] TRAIN 0.5834479311851133 / TEST 0.5865000009536743
epoch: 23
 [LOSS] TRAIN 0.6614306924014944 / TEST 0.6651728644371032
 [ACC] TRAIN 0.6025753218556273 / TEST 0.6075000009536743
epoch: 24
 [LOSS] TRAIN 0.659740620537808 / TEST 0.664700213432312
 [ACC] TRAIN 0.6044505565132793 / TEST 0.6039999990463257
epoch: 25
 [LOSS] TRAIN 0.6642062952703559 / TEST 0.6704808096885682
 [ACC] TRAIN 0.5957619702313778 / TEST 0.5955000009536743
epoch: 26
 [LOSS] TRAIN 0.6547809246480875 / TEST 0.6576379389762879
 [ACC] TRAIN 0.609263657919987 / TEST 0.6125
epoch: 27
 [LOSS] TRAIN 0.6746487729861478 / TEST 0.6735732946395874
 [ACC] TRAIN 0.5758219777583957 / TEST 0.5775000009536743
epoch: 28
 [LOSS] TRAIN 0.654277576299172 / TEST 0.6595578322410584
 [ACC] TRAIN 0.6155144394986525 / TEST 0.6135
epoch: 29
 [LOSS] TRAIN 0.6911318918543616 / TEST 0.6888422865867615
 [ACC] TRAIN 0.5505063132966127 / TEST 0.5589999995231628
epoch: 30
 [LOSS] TRAIN 0.648591748616564 / TEST 0.6524558458328247
 [ACC] TRAIN 0.6244530565575639 / TEST 0.6214999995231628
epoch: 31
 [LOSS] TRAIN 0.6489974325754476 / TEST 0.6536771726608276
 [ACC] TRAIN 0.619952494225691 / TEST 0.6145000004768372
epoch: 32
 [LOSS] TRAIN 0.6544019707308246 / TEST 0.6608430886268616
 [ACC] TRAIN 0.6213276658986326 / TEST 0.6135000009536743
epoch: 33
 [LOSS] TRAIN 0.6715341715801357 / TEST 0.6729401330947876
 [ACC] TRAIN 0.575196899575194 / TEST 0.5764999990463257
epoch: 34
 [LOSS] TRAIN 0.643867373324913 / TEST 0.6491992845535278
 [ACC] TRAIN 0.6294536819337592 / TEST 0.6315000004768372
epoch: 35
 [LOSS] TRAIN 0.6486564293282079 / TEST 0.6522256288528442
 [ACC] TRAIN 0.6168271035742113 / TEST 0.605
epoch: 36
 [LOSS] TRAIN 0.6420294815472535 / TEST 0.6486125707626342
 [ACC] TRAIN 0.6359544942745314 / TEST 0.6270000004768371
epoch: 37
 [LOSS] TRAIN 0.6438154493038141 / TEST 0.651208833694458
 [ACC] TRAIN 0.6338917364223493 / TEST 0.6220000009536744
epoch: 38
 [LOSS] TRAIN 0.6503883912229794 / TEST 0.6544629979133606
 [ACC] TRAIN 0.612951618892757 / TEST 0.6085
epoch: 39
 [LOSS] TRAIN 0.6453186844584197 / TEST 0.6511397528648376
 [ACC] TRAIN 0.6308288537929886 / TEST 0.6249999990463256
epoch: 40
 [LOSS] TRAIN 0.6426544167545679 / TEST 0.6503846526145936
 [ACC] TRAIN 0.6320790100550708 / TEST 0.6225000004768372
epoch: 41
 [LOSS] TRAIN 0.6417272801040962 / TEST 0.6493722114562989
 [ACC] TRAIN 0.633329166332056 / TEST 0.6194999990463257
epoch: 42
 [LOSS] TRAIN 0.6398436030248863 / TEST 0.6490331711769104
 [ACC] TRAIN 0.6376422054246897 / TEST 0.63
epoch: 43
 [LOSS] TRAIN 0.631602607692595 / TEST 0.6384575223922729
 [ACC] TRAIN 0.643580447503784 / TEST 0.6385000009536743
epoch: 44
 [LOSS] TRAIN 0.6448819937445489 / TEST 0.6554183039665222
 [ACC] TRAIN 0.6292036506202403 / TEST 0.6250000004768371
epoch: 45
 [LOSS] TRAIN 0.6363876337095385 / TEST 0.6452684359550476
 [ACC] TRAIN 0.6412676585988859 / TEST 0.6309999990463256
epoch: 46
 [LOSS] TRAIN 0.6309479011239253 / TEST 0.6374416012763977
 [ACC] TRAIN 0.646205775908253 / TEST 0.6359999995231629
epoch: 47
 [LOSS] TRAIN 0.6351235186044746 / TEST 0.6408330283164978
 [ACC] TRAIN 0.6363920489390622 / TEST 0.6175
epoch: 48
 [LOSS] TRAIN 0.630929329280839 / TEST 0.6394297294616699
 [ACC] TRAIN 0.6435804474963324 / TEST 0.635
epoch: 49
 [LOSS] TRAIN 0.7118293460063121 / TEST 0.722573573589325
 [ACC] TRAIN 0.5436929618139419 / TEST 0.5434999995231629
epoch: 50
 [LOSS] TRAIN 0.6858971694630822 / TEST 0.6991912660598755
 [ACC] TRAIN 0.5698837354371273 / TEST 0.5614999995231629
epoch: 51
 [LOSS] TRAIN 0.6331834056210796 / TEST 0.6445766658782959
 [ACC] TRAIN 0.6435179399436586 / TEST 0.6335
epoch: 52
 [LOSS] TRAIN 0.6319230009889824 / TEST 0.6419314608573914
 [ACC] TRAIN 0.648518564753539 / TEST 0.6379999990463256
epoch: 53
 [LOSS] TRAIN 0.6469057407628329 / TEST 0.6515301623344422
 [ACC] TRAIN 0.6200775098600959 / TEST 0.6184999995231628
epoch: 54
 [LOSS] TRAIN 0.6346832518280111 / TEST 0.6404784655570984
 [ACC] TRAIN 0.632141517861096 / TEST 0.6215000009536743
epoch: 55
 [LOSS] TRAIN 0.6189575114240049 / TEST 0.628858027458191
 [ACC] TRAIN 0.655706963526903 / TEST 0.6410000009536743
epoch: 56
 [LOSS] TRAIN 0.6297434192774429 / TEST 0.6391220602989197
 [ACC] TRAIN 0.6547068382728277 / TEST 0.648
epoch: 57
 [LOSS] TRAIN 0.6166229676434302 / TEST 0.6265069994926452
 [ACC] TRAIN 0.6662707838107235 / TEST 0.6519999990463257
epoch: 58
 [LOSS] TRAIN 0.6542158243968824 / TEST 0.6672085556983948
 [ACC] TRAIN 0.6060757594028702 / TEST 0.5945
epoch: 59
 [LOSS] TRAIN 0.6121333875437351 / TEST 0.6213488187789917
 [ACC] TRAIN 0.6708338543733577 / TEST 0.6590000009536743
epoch: 60
 [LOSS] TRAIN 0.6158076813629618 / TEST 0.6281435122489929
 [ACC] TRAIN 0.6648956121079757 / TEST 0.6499999990463257
epoch: 61
 [LOSS] TRAIN 0.6172236433579394 / TEST 0.6335913248062134
 [ACC] TRAIN 0.660270033925604 / TEST 0.643
epoch: 62
 [LOSS] TRAIN 0.6421229578969121 / TEST 0.6596796255111694
 [ACC] TRAIN 0.6263282909767675 / TEST 0.6180000004768371
epoch: 63
 [LOSS] TRAIN 0.615252755294518 / TEST 0.6242954244613648
 [ACC] TRAIN 0.6601450182762961 / TEST 0.6445000004768372
epoch: 64
 [LOSS] TRAIN 0.6137320887209371 / TEST 0.623924008846283
 [ACC] TRAIN 0.6602700336797042 / TEST 0.6414999995231628
epoch: 65
 [LOSS] TRAIN 0.6278172673277742 / TEST 0.636151807308197
 [ACC] TRAIN 0.645205650847917 / TEST 0.631
epoch: 66
 [LOSS] TRAIN 0.6356369827610059 / TEST 0.6425818095207214
 [ACC] TRAIN 0.6348293536170481 / TEST 0.632
epoch: 67
 [LOSS] TRAIN 0.6096524306126931 / TEST 0.6234135284423828
 [ACC] TRAIN 0.665833229339932 / TEST 0.6535000004768372
epoch: 68
 [LOSS] TRAIN 0.6212076438652127 / TEST 0.6288544187545776
 [ACC] TRAIN 0.645830728751687 / TEST 0.6389999990463257
epoch: 69
 [LOSS] TRAIN 0.604214853518515 / TEST 0.6155740294456482
 [ACC] TRAIN 0.671208901053027 / TEST 0.6565
epoch: 70
 [LOSS] TRAIN 0.600457368395987 / TEST 0.6121089639663696
 [ACC] TRAIN 0.6768971120346962 / TEST 0.6564999995231628
epoch: 71
 [LOSS] TRAIN 0.6155748742791262 / TEST 0.6232319588661194
 [ACC] TRAIN 0.6535816978612443 / TEST 0.6454999990463257
epoch: 72
 [LOSS] TRAIN 0.5945222419803627 / TEST 0.6058964047431946
 [ACC] TRAIN 0.680397549827839 / TEST 0.6614999990463257
epoch: 73
 [LOSS] TRAIN 0.5928509033371588 / TEST 0.6039078450202942
 [ACC] TRAIN 0.6838979871589879 / TEST 0.6804999990463256
epoch: 74
 [LOSS] TRAIN 0.6029368325656228 / TEST 0.6110890860557556
 [ACC] TRAIN 0.6686460809612859 / TEST 0.6580000009536743
epoch: 75
 [LOSS] TRAIN 0.5981787933843078 / TEST 0.6097924408912658
 [ACC] TRAIN 0.6742717841369299 / TEST 0.6605
epoch: 76
 [LOSS] TRAIN 0.5891374253246066 / TEST 0.6035475778579712
 [ACC] TRAIN 0.686523315563457 / TEST 0.673
epoch: 77
 [LOSS] TRAIN 0.588789360301765 / TEST 0.6023188710212708
 [ACC] TRAIN 0.688836104438549 / TEST 0.6744999990463257
epoch: 78
 [LOSS] TRAIN 0.6066051779024034 / TEST 0.6195484499931335
 [ACC] TRAIN 0.6667083384752542 / TEST 0.6545
epoch: 79
 [LOSS] TRAIN 0.5875048661682066 / TEST 0.5987475104331971
 [ACC] TRAIN 0.6863982999216006 / TEST 0.6814999990463256
epoch: 80
 [LOSS] TRAIN 0.5816291836384372 / TEST 0.5949563512802124
 [ACC] TRAIN 0.6895236906028864 / TEST 0.6820000009536743
epoch: 81
 [LOSS] TRAIN 0.5843651639042623 / TEST 0.5962686853408814
 [ACC] TRAIN 0.6896487062149368 / TEST 0.684
Best test accurcy is (0.5699529104232788, 0.6979999990463257)
[1m[7m%[27m[1m[0m                                                                                                          ]2;arthur@DESKTOP-42069: ~/git/IFT6135_assignment_1]1;.._assignment_1[0m[27m[24m[J(dl) [01;32marthur@DESKTOP-42069 [01;34m~/git/IFT6135_assignment_1 (master*) $[00m [K[?1h=[?2004heexcit   it[?1l>[?2004l
]2;exit]1;exit
Script done on 2019-02-16 09:45:08-05:00 [COMMAND_EXIT_CODE="0"]
